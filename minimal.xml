<?xml version="1.0" encoding="UTF-8" ?>

<!--********************************************************************
Copyright 2015 Robert A. Beezer

This file is part of MathBook XML.

MathBook XML is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 2 or version 3 of the
License (at your option).

MathBook XML is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with MathBook XML.  If not, see <http://www.gnu.org/licenses/>.
*********************************************************************-->

<!-- To process this file do                                                                      -->
<!--                                                                                              -->
<!-- (1) LaTeX/PDF:                                                                               -->
<!--     xsltproc -o minimal.tex mathbook/xsl/mathbook-latex.xsl minimal.xml                      -->
<!--     pdflatex minimal.tex                                                                     -->
<!--     xelatex minimal.tex                                                                      -->
<!--                                                                                              -->
<!-- (2) HTML:                                                                                    -->
<!--xsltproc mathbook/xsl/pretext-html.xsl minimal.xml-->
<!--     <browser>  minimal.html                                                                  -->
<!--                                                                                              -->
<!-- (3) CoCalc worksheet (parameter causes a single file for output)                             -->
<!--     REMOVE the "X" in the double dash (which is not legal in an XML comment)                 -->
<!--     xsltproc -X-stringparam chunk.level 0 mathbook/xsl/mathbook-smc.xsl minimal.xml          -->
<!--     <CoCalc> minimal.sagews                                                                  -->
<!--                                                                                              -->
<!-- (4) Sage doctesting                                                                          -->
<!--     REMOVE the "X" in the double dash (which is not legal in an XML comment)                 -->
<!--     xsltproc -X-stringparam chunk.level 0 mathbook/xsl/mathbook-sage-doctest.xsl minimal.xml -->
<!--     <read further instructions in> minimal.py                                                -->

<pretext>

    <docinfo>
        <latex-image-preamble>
            \usepackage{tikz}
        </latex-image-preamble>
        <macros>
            \newcommand{\doubler}[1]{2#1}
        </macros>
    </docinfo>

    <article xml:id="minimal">
        <title>Álgebra Linear com python</title>

        <frontmatter>

            <titlepage>
                <author>
                    <personname>Márcio Rostirolla Adames  </personname>
                    <institution>Universidade Technológica Federal do Paraná</institution>
                </author>
                <date><today /></date>
            </titlepage>

            <abstract>
                <p>Notas de aula de um curso de Álgebra Linear com python. Trabalho em progresso...</p>
                <p>Todos os direitos reservados. All rights reserved.</p>
            </abstract>

        </frontmatter>


        <!--  *********************************************************
        ***************************************************************
        ***************************************************************
        *************************************************************** -->

        <section xml:id="sistemas-lineares">
            <title>Sistemas de Equações Lineares </title>

            <intro>
               <p>Nessa seção introduzimos sistemas lineares e áplicações práticas. Sistemas lineares são, provavelmente, o tipo de problema matemático mais frequênte em aplicações práticas. Algumas razões para essa afirmação são:
               </p>
               <ol>
                <li>Muitos problemas práticos são lineares por natureza.</li>
                <li>A teoria de sistemas lineares permite compreender tais problemas e resolvê-los (equações diferencias, em contra-partida, podem não ser solúveis diretamente).</li>
                <li>Métodos computacionais funcionam bem para a solução de problemas lineares.</li>
                <li>Problemas mais complexos (como equações diferenciais) podem ser reduzidos a problemas lineares em vários casos de interesse.</li>
                <li>Para problemas não lineares, muitas vezes utilizamos aproximações lineares ou métodos que envolvem problemas lineares em diversas etapas de suas soluções.</li>
               </ol>



            </intro>


                <!--  *********************************************************
                *************************************************************** -->
                    

                <subsection xml:id="sis-lin-sub">
                    <title>Sistemas Lineares</title>
                    <definition>
                        <notation>
                          <!--<usage><m>V</m></usage>-->
                          <description>sistemas lineares</description>
                        </notation>
                      
                        <statement>
                          Uma <it>equação linear</it> em <m>n</m> variáveis <m>x_1, x_2, \ldots, x_n</m> é uma equação da forma
                          <me>
                            a_1x_1+a_2x_2+\cdots+a_nx_n = b,
                          </me>
                          onde <m>a_1, a_2, \cdots, a_n, b</m> são constantes reais (ou complexas) chamadas de <it>coeficientes do sistema</it>.
                          Um <it>sistema <m>m \times n</m> de equações lineares</it> é um conjunto de <m>equações lineares</m> em <m>n</m> variáveis.
                          <md>
                            <mrow>a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n \amp= b_1,</mrow>
                            <mrow>a_{21}x_1+a_{22}x_2+\cdots+a_{2n}x_n \amp= b_2,</mrow>
                            <mrow> \vdots  \amp = \vdots</mrow>
                            <mrow>a_{m1}x_1+a_{m2}x_2+\cdots+a_{mn}x_n \amp= b_m.</mrow>
                          </md>
                          Encontrar uma <it>solução</it> do sistema (ou <it>resolver</it> o sistema) é determinar um conjunto de valores para as variáveis, de modo que todas as equações sejam satisfeitas simultaneamente.
                        </statement>
                    </definition>

                    <example>
                        O sistema <m>2 \times 2</m>
                        <md>
                            <mrow>x_1+2x_2 \amp= 1,</mrow>
                            <mrow>2x_1+5x_2 \amp= 7,</mrow>
                        </md>
                        pode ser resolvido somando ou subtraindo múltiplos de uma equação nas outras linhas eliminando variáveis (denotando <m>L_1</m> para a primeira equação e <m>L_2</m> para a segunda) e substituindo valores encontrados.
                        <md>
                            <mrow>\begin{array}{c} x_1+2x_2 \amp= 1,\\ 2x_1+5x_2 \amp= 7,\end{array} \,\,\, \overset{L_2 \to L_2 - 2 L_1}{\Longleftrightarrow} \,\,\, \begin{array}{c} x_1+2x_2 \amp= 1,\\ x_2 \amp= 5,\end{array} \,\,\, \overset{x_2 \to 5}{\Longleftrightarrow} \,\,\, \begin{array}{c} x_1 \amp= -9,\\ x_2 \amp= 5.\end{array}</mrow>
                        </md>
                    </example>

                    <example>
                        Podemos tentar resolver o sistema <m>3 \times 2</m>
                        <md>
                            <mrow>x_1+2x_2 \amp= 1,</mrow>
                            <mrow>2x_1+5x_2 \amp= 7,</mrow>
                            <mrow>2x_1+5x_2 \amp= 4,</mrow>
                        </md>
                        encontrando
                        <md>
                            <mrow>\begin{array}{c} x_1+2x_2 \amp= 1,\\ 2x_1+5x_2 \amp= 7, \\ 2x_1+5x_2 \amp= 4, \end{array} \,\,\, \underset{L_3 \to L_3 - 2 L_1}{\overset{L_2 \to L_2 - 2 L_1}{\Longleftrightarrow}} \,\,\, \begin{array}{r} x_1+2x_2 \amp= 1,\\ x_2 \amp= 5, \\ x_2 \amp= 2.\end{array}</mrow>
                        </md>
                        Chegando a uma contradição. De modo que o sistema não tem solução.
                    </example>

                    <example>
                        O sistema <m>2 \times 3</m>
                        <md>
                            <mrow>x_1+2x_2 - x_3\amp= 1,</mrow>
                            <mrow>2x_1+5x_2 + x_3\amp= 7,</mrow>
                        </md>
                        pode ser resolvido somando ou subtraindo múltiplos de uma equação nas outras linhas eliminando variáveis e substituindo valores encontrados.
                        <md>
                            <mrow>\begin{array}{r} x_1+2x_2 -x_3 \amp= 1,\\ 2x_1+5x_2 + x_3\amp= 7,\end{array} \,\,\, \overset{L_2 \to L_2 - 2 L_1}{\Longleftrightarrow} \,\,\, \begin{array}{r} x_1+2x_2 -x_3\amp= 1,\\ x_2 +3x_3 \amp= 5,\end{array} \,\,\, \overset{x_2 \to 5 - 3x_3}{\Longleftrightarrow} \,\,\, \begin{array}{r} x_1 \amp= -9+7x_3,\\ x_2 \amp= 5- 3x_3,\end{array}</mrow>
                        </md>
                        de modo que para cada valor de <m>x_3</m> uma solução distinta e, assim, infinitas soluções.
                    </example>

                    <remark>
                        Um sistema linear é dito <it>compatível</it> se admite soluções. Sistemas compatíveis podem ter solução única ou infinitas soluções (Não é possível que um sistema linear tenha <m>n</m> soluções <m>n=2, 3, 4, \ldots </m> soluções). Um sistema linear é dito <it>incompatível</it> se não admite soluções.
                    </remark>

                    <p>Exemplos geométicos são importantes, por exemplo, em computação gráfica. para determinar se algo movendo-se em linha reta (como um projétil em um jogo ou um raio de luz em uma animação *ray tracing) precisamos calcular o ponto de interseção de uma reta com um triângulo (pedaço de plano).</p>

                    <exercise xml:id="line_inters">
                        <p>Considere as retas dadas pelas equações:
                        <ol>
                            <li>2y-3x =1,</li>
                            <li>y + 2x =2,</li>
                            <li>-2y-4x =a,</li>
                        </ol>
                        encontre os pontos de interseção dos pares de retas 1. e 2.; 2. e 3. para <m>a = 0</m> e 2. e 3. para <m>a = -4</m>.</p>
                    </exercise>

                    <exercise>
                        <p>Utilize o código abaixo para plotar as retas do exercício <xref ref="line_inters"></xref>.</p>
                    </exercise>

                    <sage>
                        <input>
                            import matplotlib.pyplot as plt

                            def linePoints(a=0,b=0,c=0,ref = [-1.,1.]):
                                """given a,b,c for straight line as ax+by+c=0, 
                                return a pair of points based on ref values
                                e.g linePoints(-1,1,2) == [(-1.0, -3.0), (1.0, -1.0)]
                                """
                                if (a==0 and b==0):
                                    raise Exception("linePoints: a and b cannot both be zero")
                                return [(-c/a,p) if b==0 else (p,(-c-a*p)/b) for p in ref]
                            
                            # test linePoints function: 
                            assert linePoints(-1,1,2) == [(-1.0, -3.0), (1.0, -1.0)], "linePoints error"
                            
                            # draw a test chart with matplotlib:
                            fig,ax = plt.subplots()
                            ax.axline(*linePoints(a=2,b=1,c=1),color="red",label="1.")   
                            ax.axline(*linePoints(a=1,b=2,c=3),color="blue",label="2.")
                            ax.set_aspect('equal')
                            plt.xlim([-6,6])
                            plt.ylim([-6,6])
                            plt.grid()
                            plt.legend()
                            #plt.savefig('linePoints.png')
                            plt.show()
                        </input>
                        <output>
                            plots
                        </output>
                    </sage>


                    <exercise>
                        <p>Utilize o código abaixo para verificar se as soluções encontradas no <xref ref="line_inters"></xref> estão corretas.</p>
                    </exercise>


                    <sage>
                        <input>
                            from sympy import *
                            x, y = symbols(['x', 'y'])
                            system = [Eq(3*x + 4*y, 7), Eq(5*x + 6*y, 8)]
                            soln = solve(system, [x, y])
                            print(soln)                            
                        </input>
                        <output>
                            solutions
                        </output>
                    </sage>

                    <p>Os pontos <m>(x,y,z) \in \mathbb{R}^3</m> que estão em um plano no espaço pode ser determinado pelo vetor normal ao plano <m>\vec{n} = (n_1, n_2, n_3)</m> e por um ponto <m>P = (p_1, p_2, p_3)</m> satisfazem a equação:</p>
                    <me>
                        n_1(x-p_1) + n_2(y-p_2) + n_3(z-p_3) = 0
                    </me>

                    <example>
                        A equação cartesiana do plano com normal <m>\vec{n} = (1,-1,2)</m> e que passa pelo ponto <m>P = (1,2,3)</m> é 
                        <me>
                            1(x-1)-1(y-2)+2(z-3) = 0 \Leftrightarrow x-y+2z = 5.
                        </me>
                    </example>


                    <sage>
                        <input>
                            n1 = vector([1,-1,2]) #A normal vector for the first plane
                            p1 = vector([1,1,1]) #A point on the first plane
                            n2 = vector([2,1,1]) #A normal vector for the second plane
                            p2 = vector([-2,1,0]) #A point on the second plane
                            var('x y z')
                            r = vector([x,y,z])
                            eq1= n1.dot_product(r-p1)==0 #Equation of the first plane
                            eq2= n2.dot_product(r-p2)==0 #Equation of the second plane
                            pl1 = implicit_plot3d(eq1, (x,-5,5), (y,-5,5), (z,-5,5), color='red')
                            pl2 = implicit_plot3d(eq2, (x,-5,5), (y,-5,5), (z,-5,5), color='blue')
                            sol = solve([eq1,eq2], x, y)[0]
                            vecsol = vector([sol[0].rhs(), sol[1].rhs(), z]) #The line of intersection, using z as parameter
                            inter = parametric_plot3d(vecsol, (z,-5,5), color='magenta', thickness=8)
                            #show(pl1+pl2+inter, axes=True, aspect_ratio=1)
                            show(pl1, axes=True, aspect_ratio=1)
                        </input>
                        <output>
                            plot
                        </output>
                    </sage>

                    <p>
                        Podemos tentar o processo contrário: dada uma equação como determinar o plano que contém todas as soluções? Considerando uma equação da forma
                        <me>
                            ax+by+cz =d,
                        </me>
                        sabemos que o vetor normal é <m>\vec{n} = (a,b,c)</m> e podemos usar como ponto do plano qualquer valores <m>x,y,z</m> que satisfaçam a equação acima. Se <m>c\neq 0</m>, por exemplo, podemos tomar <m>P = (0,0,-d/c)</m>.
                    </p>

                    <p> As soluções de sistemas lineares de três variáveis correspondem a interseções de planos no espaço, podendo ser um plano todo, uma reta, um ponto ou vazio.</p>

                    <exercise>
                        <p>Resolva o sistema a seguir manualmente. Em seguida utilize os códigos acima verificar se sua solução está correta e plotar o plano que contém as soluções.</p>
                        <md>
                            <mrow>x - 2y - 3z\amp= 1,</mrow>
                            <mrow>2x + 5y - z \amp= 7,</mrow>
                            <mrow>2x + 3y - 4z \amp= 8,</mrow>
                        </md>
                    </exercise>

                    <exercise>
                        <p>Resolva o sistema a seguir manualmente. Em seguida utilize os códigos acima verificar se sua solução está correta e plotar o plano que contém as soluções.</p>
                        <md>
                            <mrow>x - 2y - 3z\amp= 1,</mrow>
                            <mrow>2x + 5y - z \amp= 7,</mrow>
                            <mrow>3x + 3y - 4z \amp= 8,</mrow>
                        </md>
                    </exercise>

                    <remark>
                        Dois sistemas lineares são ditos equivalentes se possuem as mesmas soluções. Dado um sistema linear, podemos realizar três tipos de operações em suas linhas para obter sistemas equivalentes:
                        <ol>
                            <li>Trocar duas equações de lugar.</li>
                            <li>Multiplicar uma equação por um número real não nulo.</li>
                            <li>Substituir uma equação pela soma dela com um múltiplo não nulo de outra equação.</li>
                        </ol>
                    </remark>

                    <example>
                        <p>Todos os sistemas a seguir são equivalentes.</p>
                        <md>
                            <mrow>\amp \begin{array}{rl} x_1+2x_2 + x_3 \amp= 1,\\ 2x_1+5x_2 + 3x_3\amp= 7, \\ 2x_1+5x_2 + 4x_3\amp= 7,\end{array} \,\,\, \overset{L_2 \to L_2 - 2 L_1}{\Longleftrightarrow} \,\,\, \begin{array}{rl} x_1+2x_2 +x_3\amp= 1,\\ x_2 +x_3 \amp= 5, \\ 2x_1+5x_2 + 4x_3\amp= 7, \end{array} \,\,\, \overset{L_3 \to L_3 - 2 L_1}{\Longleftrightarrow}</mrow>
                            <mrow>\amp \begin{array}{rl} x_1+2x_2 +x_3\amp= 1,\\ x_2 +x_3 \amp= 5, \\ x_2 + 2x_3\amp= 5, \end{array} \,\,\,\overset{L_3 \to L_3 - L_2}{\Longleftrightarrow} \,\,\, \begin{array}{rl} x_1+2x_2 +x_3\amp= 1,\\ x_2 +x_3 \amp= 5, \\ x_3\amp= 0. \end{array}</mrow>
                        </md>
                        <p>O último sistema está na <term>forma triangular</term>. Quando um sistema está na forma triângular, podemos determinar determinar o valor de uma variável e substituir seu valor nas outras equações para reduzir o número de variáveis. Repetimos esse processo até resolver o sistema.</p>
                    </example>

                    <p>Ao resolver um sistema, utilizamos uma variável com coeficiente não nulo em uma equação para remover essa mesma variável das demais equações. Repetimos o processo até ter uma única variável restante em uma das equações. Assim precisamos de pelo menos <m>n</m> equações para eliminar <m>n</m> variáveis. Se tivermos mais do que <m>n</m> equações, podemos chegar a sistemas sem solução. Em muitos problemas reais o foco está em sistemas <m>n \times n</m>. </p>





                </subsection>


                <!--  *********************************************************
                *************************************************************** -->
                    

                <subsection xml:id="matrix-sis-lin">
                    <title>Matrizes representando sistemas lineares</title>

                    <!--INICIAR COM EXEMPLO! ADICIONAR-->

                    <p> Considere um sistema de equações lineares:</p>
                      <md>
                        <mrow>a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n \amp= b_1,</mrow>
                        <mrow>a_{21}x_1+a_{22}x_2+\cdots+a_{2n}x_n \amp= b_2,</mrow>
                        <mrow> \vdots  \amp = \vdots</mrow>
                        <mrow>a_{m1}x_1+a_{m2}x_2+\cdots+a_{mn}x_n \amp= b_m.</mrow>
                      </md>
                      <p>Para resolver o sistema precisamos dos coeficientes de cada variável. As variáveis <m>x_1, x_2, \ldots, x_n</m> são apenas nomes. Podemos deixar esses nomes de lado e formar matrizes associadas ao sistema.</p>
                      <ol>
                        <li>A <term>matriz de coeficientes do sistema</term>:
                        <me>
                            A = \begin{pmatrix}
                            a_{11} \amp a_{12} \amp \cdots \amp a_{1n}\\
                            a_{21} \amp a_{22} \amp \cdots \amp a_{2n}\\
                            \vdots  \amp \vdots  \amp \ddots \amp \vdots\\
                            a_{m1} \amp a_{m2} \amp \cdots \amp a_{mn}
                            \end{pmatrix}
                        </me></li>
                        <li>O <term>vetor coluna de constantes</term>:
                            <me>
                                \vec{b} = \begin{pmatrix}
                                b_{1}\\
                                b_{2}\\
                                \vdots\\
                                b_{m}
                                \end{pmatrix}
                            </me></li>
                            <li>A <term>matriz ampliada do sistema</term>:
                                <me>
                                    (A | \vec{b}) = \left(\begin{array}{cccc|c}
                                    a_{11} \amp a_{12} \amp \cdots \amp a_{1n} \amp b_1\\
                                    a_{21} \amp a_{22} \amp \cdots \amp a_{2n} \amp b_2\\
                                    \vdots  \amp \vdots  \amp \ddots \amp \vdots \amp \vdots\\
                                    a_{m1} \amp a_{m2} \amp \cdots \amp a_{mn} \amp b_m
                                    \end{array} \right)
                                </me></li>
                      </ol>

                      <remark>
                        Podemos agregar quaisquer duas matrizes com o mesmo número de linhas. Dadas
                        <me>
                            A = \begin{pmatrix}
                            a_{11} \amp a_{12} \amp \cdots \amp a_{1n}\\
                            a_{21} \amp a_{22} \amp \cdots \amp a_{2n}\\
                            \vdots  \amp \vdots  \amp \ddots \amp \vdots\\
                            a_{m1} \amp a_{m2} \amp \cdots \amp a_{mn}
                            \end{pmatrix}  \,\,\, \mbox{e} \,\,\, B = \begin{pmatrix}
                            b_{11} \amp b_{12} \amp \cdots \amp b_{1r}\\
                            b_{21} \amp b_{22} \amp \cdots \amp b_{2r}\\
                            \vdots  \amp \vdots  \amp \ddots \amp \vdots\\
                            b_{m1} \amp b_{m2} \amp \cdots \amp b_{mr}
                            \end{pmatrix},
                        </me>
                        A matriz <term>agregada</term> <m>\, (A | B)</m> é a matriz <m>m \times (n+r)</m>
                        <me>
                            (A | B) = \left(\begin{array}{cccc|cccc}
                            a_{11} \amp a_{12} \amp \cdots \amp a_{1n} \amp b_{11} \amp b_{12} \amp \cdots \amp b_{1r}\\
                            a_{21} \amp a_{22} \amp \cdots \amp a_{2n} \amp b_{21} \amp b_{22} \amp \cdots \amp b_{2r}\\
                            \vdots  \amp \vdots  \amp \ddots \amp \vdots \amp \vdots  \amp \vdots  \amp \ddots \amp \vdots\\
                            a_{m1} \amp a_{m2} \amp \cdots \amp a_{mn} \amp b_{m1} \amp b_{m2} \amp \cdots \amp b_{mr}
                            \end{array} \right).
                        </me>
                      </remark>


                      <example xml:id = "gauss_example">
                        <p>No sistema</p>
                        <md>
                            <mrow>x - 2y - 3z\amp= 1,</mrow>
                            <mrow>2x + 5y - z \amp= 7,</mrow>
                            <mrow>2x + 3y - 4z \amp= 8,</mrow>
                        </md>
                        <p> A matriz de coeficientes do sistema:</p>
                        <me>
                            A = \begin{pmatrix}
                            1 \amp -2 \amp -3\\
                            2 \amp 5 \amp -1\\
                            2 \amp 3 \amp -4
                            \end{pmatrix}
                        </me>
                        <p>O vetor coluna de constantes:</p>
                            <me>
                                \vec{b} = \begin{pmatrix}
                                1\\
                                7\\
                                8
                                \end{pmatrix}
                            </me>
                            <p>A matriz ampliada do sistema:</p>
                                <me>
                                    (A | \vec{b}) = \left(\begin{array}{ccc|c}
                                    1 \amp -2 \amp -3 \amp 1\\
                                    2 \amp 5 \amp -1\amp 7\\
                                    2 \amp 3 \amp -4 \amp 8
                                    \end{array} \right)
                                </me>
                      </example>

                      <p>Para resolver o sistema linear podemos operar nas linhas da matriz ampliada. Os coeficientes da <m>i</m>-ésima coluna correspondem aos coeficientes de <m>x_i</m> nas respectivas equações. Podemos realizar três tipos de operações (<term>operações elementares</term>) nas linhas da matriz ampliada:</p>
                      <ol>
                        <li>Trocar duas linhas de lugar.</li>
                        <li>Multiplicar uma linha por um número real não nulo.</li>
                        <li>Substituir uma linha pela soma dela com um múltiplo não nulo de outra linha.</li>
                      </ol>

                      <p>O objetivo dessas operações é colocar a matriz ampliada na forma escada.</p>

                      <definition>
                        <notation>
                          <!-- <usage><m>V</m></usage> -->
                          <description>forma escada</description>
                        </notation>
                      
                        <statement>
                          <p>Uma matriz está na <term>forma escada</term> se:</p>
                          <ol>
                            <li>o primeiro elemento não nulo de cada linha é 1;</li>
                            <li>se a linha <m>k</m> não é nula, o número de zeros no início da linha é menor do que o número de zeros no início da linha <m>k-1</m>, <m>k \geq 2</m>;</li>
                            <li>as linhas nulas estão abaixo das demais.</li>
                          </ol>
                        </statement>
                    </definition>

                    <p>O código a seguir pode ser utilizado para colocar a matriz do <xref ref="gauss_example"></xref> na forma escada utilizando as operações elementares.</p>

                      <sage>
                          <input>
                            # Write an array representing the augmented matrix
                            import numpy as np
                            import fractions
                            A= np.array([[1, -2, -3, 1], [2, 5, -1, 7], [2, 3, -4, 8]], dtype=float)
                            np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})


                            #Step by step Gaussian Elimination:

                            def Gaussian_elimination(A,prin=True):
                                a=0
                                if prin==True:
                                    print('A='+str(A))
                                for j in range(A.shape[1]-1): #search pivot in each column
                                    b=0
                                    for i in range(a,A.shape[0]):
                                        if A[i,j] != 0: #choose row with not null pivot
                                            if a !=i:
                                                A[[a,i]]=A[[i,a]]
                                                if prin==True:
                                                    print('~'+str(A))
                                            if A[a,j]!=1:
                                                A[a]=A[a]/A[a,j]
                                                if prin==True:
                                                    print('~'+str(A))
                                            a=a+1
                                            b=1
                                            break
                                    if b==1:
                                        for i in range(a,A.shape[0]):
                                            if A[i,j] != 0:
                                                A[i]=A[i]-A[a-1]*A[i,j]
                                            if prin==True:
                                                print('~'+str(A))
                                return A
                            B=Gaussian_elimination(A)
                          </input>
                          <output>
                          solution
                          </output>
                      </sage>
                      
                        <remark>
                          <p>A estratégia utilizada para colocar uma matriz na forma escada consiste trocar linhas para ter um elemento não nulo no canto superior esquerdo. Depois dividimoa a linha por esse elemento para que o elemento no canto superior esquerdo seja 1. Em seguida, utilizamos operações elementares do tipo 3. para zerar os elementos das outras linhas naquela coluna.</p>
                          <p>Em seguida tentamos repetir esse processo para a segunda coluna. Caso todos os elementos da segunda coluna tenham zerado na primeira etapa, partimos para a terceira coluna. Repetimos isso até chegar à última coluna. Esse processo é chamado de <term>eliminação Gaussiana</term> ou de <term>colocar a matriz na forma escada reduzida por linhas</term>.</p>
                        </remark>
                        <p> Ao colocarmos uma matriz na forma escada reduzida por linhas, a posição do primeiro elemento não nulo obtido em uma linha é chamado de <term>pivô</term> daquela linha se todos os elementos na mesma coluna abaixo dele são nulos.</p>

                        <example>
                            <p>Pivôs em diversas linhas:</p>
                            <me>
                                \begin{pmatrix}
                                \boxed{ 1} \amp  2    \amp   -2 \amp 2 \\
                                3 \amp  4    \amp   -2 \amp 2 \\
                                2 \amp  4    \amp  -4  \amp 2 \\
                                2 \amp  4    \amp   -4 \amp 4 
                                \end{pmatrix}
                                \begin{pmatrix}
                                \boxed{1} \amp  2    \amp   -2 \amp 2 \\
                                0 \amp  \boxed{-2}    \amp   4 \amp -4 \\
                                0 \amp  0    \amp  0  \amp \boxed{-2} \\
                                0 \amp  0    \amp   0 \amp 0 
                                \end{pmatrix}
                            </me>
                        </example>


                        <p>Após realizarmos a eliminação Gaussiana, podemos fazer a <term>substituição reversa</term> para encontrar os valores das variáveis (podem depender de algumas variáveis livres), iniciando pela última equação e substituindo os valores encontrados nas demais equações. O código abaixo permite fazer isso para uma matriz que já tenha passado pela eliminação Gaussiana.</p>



                      <sage>
                          <input>
                            # PRECISA RODAR A ELIMINAÇÃO GAUSSIANA PRIMEIRO
                            import sympy
                            import sys
                            np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
                            
                            def back_subs(B):
                                m,n = B.shape
                                x = []
                                y=[]
                                for i in range(n):
                                    x.append(['x'+str(i+1)])
                                    y.append(['x'+str(i+1)])
                                
                                for i in range(m):
                                    w=0
                                    for j in range(n-1):
                                        if B[m-i-1,j] != 0:
                                            w+=1
                                            x[m-i-1] = str(B[m-i-1,n-1])
                                            for k in range(j+1, n-1):
                                                x[m-i-1] = '('+x[m-i-1] +'-'+ str(B[m-i-1,k])+'*'+str(x[k])+')'
                                            break
                                    if w ==0 and B[m-i-1,n-1] !=0:
                                        print('sistema inconsistente')
                                        sys.exit()
                                for i in range(m):
                                    try:
                                        x[i]=sympy.sympify(x[i])
                                    except:
                                        pass
                                    try:
                                        x[i]=fractions.Fraction(str(x[i])).limit_denominator()
                                    except:
                                        pass
                                    print(y[i][0]+'='+str(x[i]))
                                return
                            back_subs(B)
                          </input>
                          <output>
                          solution
                          </output>
                      </sage>

                      <example>
                        <p>O sistema</p>
                        <md>
                            <mrow>x - 2y - 3z\amp= 1,</mrow>
                            <mrow>2x + 5y - z \amp= 7,</mrow>
                            <mrow>2x + 3y - 4z \amp= 8,</mrow>
                        </md>
                        tem matriz ampliada
                        <me>
                            \left(\begin{array}{ccc|c}
                                    1 \amp -2 \amp -3 \amp 1\\
                                    2 \amp 5 \amp -1\amp 7\\
                                    2 \amp 3 \amp -4 \amp 8
                                    \end{array} \right) \sim \cdots \sim \left(\begin{array}{ccc|c}
                                    1 \amp -2 \amp -3 \amp 1\\
                                    0 \amp 1 \amp 5/9\amp 5/9\\
                                    0 \amp 0 \amp 1 \amp -19/17
                                    \end{array} \right)
                        </me>
                        de modo que <m>x_3 = -19/17</m>, <m>x_2 = 5/9 +19/17 \times 5/9 = 20/17</m> e <m>x_1 = 1 + 2\times 20/17 - 3 \times 19/17 = 0.</m>

                      </example>

                    <exercise>
                        <p>Utilize a eliminação Gaussiana seguida da substituição reversa para resolver os sistemas a seguir. Mostre os passos das contas que realizar. Em seguida compare os resultados obtidos com os resultados apresentados pelo computador nos códigos acima.</p>
                        <ol>
                            <li>Sistema 1
                                <md>
                                    <mrow>2x - 2y - 6z\amp= 8,</mrow>
                                    <mrow>3x -5y - z \amp= 0.</mrow>
                                </md>
                            </li>
                            <li>Sistema 2
                                <md>
                                    <mrow>x - y \amp= 1,</mrow>
                                    <mrow>-x -y - z \amp= -1,</mrow>
                                    <mrow> -y + z \amp= 1.</mrow>
                                </md>
                            </li>
                            <li>Sistema 3
                                <md>
                                    <mrow>x - y + z\amp= 1,</mrow>
                                    <mrow>-x -y - z \amp= -1,</mrow>
                                    <mrow> -y + z \amp= 1,</mrow>
                                    <mrow> -2y + z \amp= 2.</mrow>
                                </md>
                            </li>
                            <li>Sistema 4
                                <md>
                                    <mrow>x - y + z\amp= 1,</mrow>
                                    <mrow>-x -y - z \amp= -1,</mrow>
                                    <mrow> -y + z \amp= 1,</mrow>
                                    <mrow> -2y  \amp= 0.</mrow>
                                </md>
                            </li>
                        </ol>
                    </exercise>



                    <example>
                        Circuitos elétricos. Livro do Leon, pág. 18.
                    </example>

                    <exercise>
                        <p>Encontre as correntes <m>i_1, i_2, \ldots, i_6</m> no circuito da imagem.</p>
                        <figure>
                            <caption>Circuito RC (fonte Leon)</caption>
                            <image source="images/RC_circuit.png"/>
                        </figure>
                    </exercise>




                </subsection>


                <!--  *********************************************************
                *************************************************************** -->
               
               
               <subsection xml:id="Gauss-Jordan-red">
                <title>Redução de Gauss Jordan</title>

                <p> Na seção enterior vimos como utilizar a eliminação Gaussiana na matriz ampliada de um sistema para colocá-la na forma escada e, em seguida resolver o sistema utilizando substituição reversa. Alternativamente, poderíamos seguir fazendo operações elementares nas linhas da matriz ampliada para zerar coeficientes acima de um pivô.</p>
                
                <example>
                    <p>O sistema</p>
                    <md>
                        <mrow>x - 2y - 3z\amp= 1,</mrow>
                        <mrow>2x -2y - 2z \amp= 6,</mrow>
                        <mrow>2x - 4z \amp= 8,</mrow>
                        <mrow>5x -7y + 4z \amp= 46/3,</mrow>
                    </md>
                    tem matriz ampliada
                    <me>
                        \left(\begin{array}{ccc|c}
                                1 \amp -2 \amp -3 \amp 1\\
                                2 \amp -2 \amp -2\amp 6\\
                                2 \amp 0 \amp -4 \amp 8\\
                                5 \amp -7 \amp 4 \amp 46/3
                                \end{array} \right) \sim \cdots \sim \left(\begin{array}{ccc|c}
                                1 \amp 0 \amp 0 \amp 14/3\\
                                0 \amp 1 \amp 0\amp 4/3\\
                                0 \amp 0 \amp 1 \amp 1/3\\
                                0 \amp 0 \amp 0 \amp 0
                                \end{array} \right)
                    </me>
                    assim o sistema tem solução única <m>x=14/3,\,\, y= 4/3, \,\, z = 1/3</m>.
                </example>

                <sage>
                    <input>
                      # Write an array representing the augmented matrix
                      import numpy as np
                      import fractions
                      A= np.array([[1, -2, -3, 1], [2, -2, -2, 6], [2, 0, -4, 8], [5, -7, 4, 46/3]], dtype=float)
                      np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})


                      #Step by step Gaussian Elimination:

                      def Gaussian_elimination(A,prin=True):
                          a=0
                          if prin==True:
                              print('A='+str(A))
                          for j in range(A.shape[1]-1): #search pivot in each column
                              b=0
                              for i in range(a,A.shape[0]):
                                  if A[i,j] != 0: #choose row with not null pivot
                                      if a !=i:
                                          A[[a,i]]=A[[i,a]]
                                          if prin==True:
                                              print('~'+str(A))
                                      if A[a,j]!=1:
                                          A[a]=A[a]/A[a,j]
                                          if prin==True:
                                              print('~'+str(A))
                                      a=a+1
                                      b=1
                                      break
                              if b==1:
                                  for i in range(a,A.shape[0]):
                                      if A[i,j] != 0:
                                          A[i]=A[i]-A[a-1]*A[i,j]
                                      if prin==True:
                                          print('~'+str(A))
                          return A
                      B=Gaussian_elimination(A)
                    </input>
                    <output>
                    solution
                    </output>
                </sage>

                <sage>
                    <input>
                        def Gauss_Jordan(A,prin=True):
                            np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
                            B=Gaussian_elimination(A,prin)
                            #print('jordan')
                            a=0
                            for i in range(A.shape[0]): #search pivot in each line
                                b=0
                                for j in range(A.shape[1]):
                                    if B[B.shape[0]-i-1,j] == 1 and b==0: #choose column with a '1' pivot
                                        b=j
                                        for k in range(B.shape[0]-i-1):
                                            B[B.shape[0]-i-2-k]=B[B.shape[0]-i-2-k]- B[B.shape[0]-i-2-k,j]*B[B.shape[0]-i-1]
                                            if prin==True:
                                                    print('~'+str(B))                
                            return B
                        Gauss_Jordan(B)
                    </input>
                    <output>
                    solution
                    </output>
                </sage>

                <example>
                    <p>O sistema</p>
                    <md>
                        <mrow>x - 2y - 3z\amp= 1,</mrow>
                        <mrow>2x -2y - 2z \amp= 6,</mrow>
                    </md>
                    tem matriz ampliada
                    <me>
                        \left(\begin{array}{ccc|c}
                                1 \amp -2 \amp -3 \amp 1\\
                                2 \amp -2 \amp -2\amp 6
                                \end{array} \right) \sim \cdots \sim \left(\begin{array}{ccc|c}
                                1 \amp 0 \amp 1 \amp 5\\
                                0 \amp 1 \amp 2\amp 2
                                \end{array} \right)
                    </me>
                    assim o sistema tem infinitas soluções <m>y=2-2\alpha,\,\, x= 5 - \alpha, \,\, z = \alpha.</m>.
                </example>

                <example>
                    <p>O sistema</p>
                    <md>
                        <mrow>x - 2y - 3z\amp= 1,</mrow>
                        <mrow>2x -2y - 2z \amp= 6,</mrow>
                        <mrow>2x - 4z \amp= 8,</mrow>
                        <mrow>5x -7y + 4z \amp= 46/3,</mrow>
                    </md>
                    tem matriz ampliada
                    <me>
                        \left(\begin{array}{ccc|c}
                                1 \amp -2 \amp -3 \amp 1\\
                                2 \amp -2 \amp -2\amp 6\\
                                2 \amp 0 \amp -4 \amp 8\\
                                5 \amp -7 \amp 4 \amp 1
                                \end{array} \right) \sim \cdots \sim \left(\begin{array}{ccc|c}
                                1 \amp -2 \amp -3 \amp 1\\
                                0 \amp 1 \amp 2\amp 2\\
                                0 \amp 0 \amp 1 \amp 1/3\\
                                0 \amp 0 \amp 0 \amp -43/3
                                \end{array} \right)
                    </me>
                    assim o sistema não tem solução, pois a última equação implica em <m>0x+0y+0z = -43/3</m>.
                </example>

                <definition>
                    <notation>
                    <!-- usage><m>S</m></usage -->
                    <description>forma escada reduzidq</description>
                    </notation>
                
                    <statement>
                    <p>
                        A matriz <m>A</m> está na <term>forma escada reduzida por linhas</term> se:
                    </p>
                    <ol>
                        <li><m>A</m> está na forma escada;</li>
                        <li>o único elemento não nulo de uma coluna com um pivô é o elemento na posição do pivô.</li>
                    </ol>
                    </statement>
                </definition>

                <remark>
                    Chamamos de <term>redução de Gauss-Jordan</term> o processo de usar operações elementares nas linhas de uma matriz para encontrar uma matriz equivalente por linhas na forma escada reduzida por linhas.
                </remark>

                <example>
                    <p>As matrizes a seguir estão na forma escada reduzida por linhas:</p>
                    <me>
                        A = \left(\begin{array}{cccc}
                                1 \amp 0 \amp 0 \amp 14/3\\
                                0 \amp 1 \amp 0\amp 4/3\\
                                0 \amp 0 \amp 1 \amp 1/3\\
                                0 \amp 0 \amp 0 \amp 0
                                \end{array} \right), \,\,\,
                        B = \left(\begin{array}{cccc}
                        1 \amp 0 \amp 3 \amp 0\\
                        0 \amp 1 \amp 2 \amp 0\\
                        0 \amp 0 \amp 0 \amp 1\\
                        0 \amp 0 \amp 0 \amp 0
                        \end{array} \right), \,\,\,
                        C = \left(\begin{array}{cccc}
                        1 \amp 2 \amp 0 \amp -5 \amp 3\\
                        0 \amp 0 \amp 1 \amp 2 \amp 2\\
                        0 \amp 0 \amp 0 \amp 0 \amp 0
                        \end{array} \right),
                    </me>
                </example>

                <example>
                    <p>As matrizes a seguir não estão na forma escada reduzida por linhas:</p>
                    <me>
                        A = \left(\begin{array}{cccc}
                                1 \amp 2 \amp 0 \amp 14/3\\
                                0 \amp 1 \amp 0\amp 4/3\\
                                0 \amp 0 \amp 1 \amp 1/3\\
                                0 \amp 0 \amp 0 \amp 0
                                \end{array} \right), \,\,\,
                        B = \left(\begin{array}{cccc}
                        1 \amp 0 \amp 3 \amp 0\\
                        0 \amp -2 \amp 2 \amp 0\\
                        0 \amp 0 \amp 0 \amp 1\\
                        0 \amp 0 \amp 0 \amp 0
                        \end{array} \right), \,\,\,
                        C = \left(\begin{array}{cccc}
                        1 \amp 0 \amp 0 \amp -5 \amp 3\\
                        0 \amp 0 \amp 1 \amp 2 \amp 2\\
                        0 \amp 1 \amp 0 \amp -2 \amp 0
                        \end{array} \right).
                    </me>
                </example>


                <exercise>
                    <p>O diagrama abaixo representa o fluxo de veículos em algumas ruas de uma cidade. Os círculos azuis representam cruzamentos. Os números e variáveis (<m>x_1, \ldots, x_5</m>) representam a quantidade de carros entrando e saindo dos cruzamentos mostrados (em carros por hora). O número de carros que entra (por hora) em cada cruzamento é igual ao número de carros que sai. </p>
                    <figure>
                        <caption>Diagrama de tráfego.</caption>
                        <image source="images/traffic_flow.png"/>
                    </figure>
                    <ol>
                        <li>Escreva um sistema que represente o diagrama.</li>
                        <li>Resolva o sistema encontrado utilizando a redução de Gauss-Jordan.</li>
                        <li>Determine o fluxo em cada rua para <m>x_3 = x_5 =50</m>.</li>
                        <li>Se a entrade de carros no cruzamento inferior esquerdo mudar para 200 carros por hora, qual o valor dos demais fluxos.</li>
                        <li>Refaça os cálculos anteriores para o caso de revertermos a direção de <m>x_3</m>.</li>
                    </ol>
                </exercise>

                <exercise>
                    <p>Encontre matrizes equivalentes por linha às matrizes seguintes, que estejam na forma escada reduzida por linhas.</p>
                    <me>
                        A = \left(\begin{array}{cccc}
                                1 \amp 1 \amp 2 \amp -1\\
                                2 \amp -1 \amp 1\amp 1\\
                                -1 \amp 1 \amp 1 \amp 2\\
                                1 \amp 2 \amp 1 \amp -2
                                \end{array} \right), \,\,\,
                        B = \left(\begin{array}{cccc}
                        1 \amp 0 \amp 3\\
                        1 \amp 1 \amp 2\\
                        -1 \amp 3 \amp 2\\
                        1 \amp 1 \amp 1
                        \end{array} \right), \,\,\,
                        C = \left(\begin{array}{cccc}
                        1 \amp 2 \amp 0 \amp -5 \amp 3\\
                        2 \amp -1 \amp 1 \amp 2 \amp 2\\
                        4 \amp 2 \amp 1 \amp 3 \amp 5
                        \end{array} \right),
                    </me>
                </exercise>
               
                </subsection>

                <!--  *********************************************************
                *************************************************************** -->
               
               
                <subsection xml:id="matrizes_operacoes">
                    <title>Matrizes e operações</title>

                    <p>Nessa seção formalizamos o conceito de matriz (que já temos utilizados) e como realizar operações aritméticas com elas.</p>


                    <definition>
                        <notation>
                        <usage><m>A</m></usage>
                        <description>matriz</description>
                        </notation>
                    
                        <statement>
                        <p>
                            Uma <term>matriz</term> <m>A = (a_{ij})</m> <m>m \times n</m> é um arranjo de <m>mn</m> números (reais ou complexos, usualmente) em <m>m</m> linhas com <m>n</m> números cada.
                        </p>
                        <me>
                            A = \begin{pmatrix}
                            a_{11} \amp a_{12} \amp \cdots \amp a_{1n}\\
                            a_{21} \amp a_{22} \amp \cdots \amp a_{2n}\\
                            \vdots \amp \vdots \amp \ddots \amp \vdots\\
                            a_{m1} \amp a_{m2} \amp \cdots \amp a_{mn}
                            \end{pmatrix}
                        </me>
                        <p>Denotamos de <m>a_{ij}</m> o número que está na <m>i</m>-ésima linha e <m>j</m>-ésima coluna e dizemos o <term>elemento</term> <m>ij</m> da matriz <m>A</m>.</p>
                        <p>As matrizes <m>m \times 1</m> são chamadas de <term>vetores</term> (coluna) e denotadas <m>\vec{a}</m>:</p>
                        <me>
                            \vec{a} = \begin{pmatrix}
                            a_{1}\\
                            a_{2}\\
                            \vdots\\
                            a_{m1}
                            \end{pmatrix}
                        </me>
                        <p>Uma matriz <m>1 \times n</m> é um <term>vetor linha</term>: <m>\vec{a}^T = (a_1, a_2, \ldots, a_n)</m>.</p>
                        </statement>
                    </definition>


                    <definition>
                        <notation>
                        <!--usage><m>A</m></usage-->
                        <description>operações elementares</description>
                        </notation>
                    
                        <statement>
                        <p>
                            Duas matrizes <m>A = (a_{ij})</m> e <m>B = (b_{ij})</m>, ambas <m>m \times n</m>, são <term>iguais</term> se <m>a_{ij} = b_{ij}</m> para todo <m>i \in \{0,1,2,\ldots,m\}</m>, <m>j \in \{0,1,2,\ldots,n\}</m>. Por outro lado, <m>A \neq B</m> se existem <m>i,j</m> tais que <m>a_{ij} \neq b_{ij}</m> ou se as matrizes têm dimensões diferentes. 
                        </p>
                        <p>
                            A <term>soma</term> de duas matrizes <m>A = (a_{ij})</m> e <m>B = (b_{ij})</m>, ambas <m>m \times n</m>, é a matriz <m>C = (c_{ij})</m>, <m>m \times n</m>, definida por <m>c_{ij} = a_{ij} + b_{ij}</m>. (somamos apenas matrizes com o mesmo número de linhas e colunas) Análogo para subtração.
                        </p>
                        <p>
                            O <term>produto de um número real</term> <m>\alpha</m> e <term> uma matriz</term> <m>A = (a_{ij})</m>, <m>m \times n</m>, é a matriz <m>C = (c_{ij}),</m> <m>m \times n</m>, definida por <m>c_{ij} = \alpha a_{ij}</m>.
                        </p>
                        <p>
                            O <term>produto</term> de uma matriz <m>A = (a_{ij})</m>, <m>m \times n</m>, e outra matriz <m>B = (b_{ij})</m>,  <m>n \times r</m>, é a matriz <m>C = (c_{ij}),</m> <m>m \times r</m>, definida por <m>c_{ij} = a_{i1} b_{1j} + a_{i2} b_{2j} + \cdots + a_{in} b_{nj}</m>. (o número de colunas de <m>A</m> precisa ser igual ao número de linhas de <m>B</m>).
                        </p>
                        </statement>
                    </definition>


                    <example>
                        <p>Sejam</p>
                        <me>
                            \alpha = 7; \,\,\, \beta = 1/2; \,\, A = \begin{pmatrix}
                            2 \amp -1 \amp 0\\
                            1 \amp -1 \amp 1\\
                            2 \amp 0 \amp -2\\
                            3 \amp 1 \amp -1
                            \end{pmatrix}\,\,\,
                            B = \begin{pmatrix}
                            3 \amp -2 \amp 1\\
                            0 \amp 1 \amp -1\\
                            1 \amp 1 \amp -1
                            \end{pmatrix}
                        </me>
                        <me>
                            C = \begin{pmatrix}
                            1 \amp 1 \amp 1 \amp 0\\
                            0 \amp -1 \amp -1 \amp -1\\
                            2 \amp 0 \amp 2 \amp 1\\
                            2 \amp 1 \amp -1 \amp 0
                            \end{pmatrix}\,\,\,
                            D = \begin{pmatrix}
                            1 \amp -2 \amp 1 \\
                            1 \amp 1 \amp -1 \\
                            1 \amp 2 \amp 0 
                            \end{pmatrix}\,\,\,
                            \vec{v} = \begin{pmatrix}
                            2 \\
                            -2\\
                            -1
                            \end{pmatrix}\,\,\,
                            \vec{u} = \begin{pmatrix}
                            1 \\
                            -1\\
                            1
                            \end{pmatrix}
                        </me>
                        <p>
                            Determine se é possível realizar as seguintes operações. Caso seja, determine o resultado
                        </p>
                        <ol>
                            <li>\alpha B;</li>
                            <li>\beta \vec{v};</li>
                            <li>A + B;</li>
                            <li>B - D;</li>
                            <li>2\vec{v}-3\vec{u};</li>
                            <li>AB;</li>
                            <li>BA;</li>
                            <li>A\vec{u}</li>
                        </ol>
                    </example>

                    <p>Os códigos a seguir podem ser utilizados para realizar operações básicas com matrizes.</p>

                    <p>Matrizes no Python.</p> 

                    <sage>
                        <input>
                        import numpy as np
                        
                        A = np.array([[1, 2, 3], [3, 4, 5]])
                        print(A)
                        
                        A = np.array([[1.1, 2, 3], [3, 4, 5]]) # Array of floats
                        print(A)
                        
                        A = np.array([[1, 2, 3], [3, 4, 5]], dtype = complex) # Array of complex numbers
                        print(A)
                        </input>
                        <output>
                        solution
                        </output>
                    </sage>
                    
                    
                    <p>Matrizes de zeros e uns.</p> 
        
                    <sage>
                        <input>
                        import numpy as np
                        
                        zeors_array = np.zeros( (2, 3) )
                        print(zeors_array)
                        
                        
                        ones_array = np.ones( (1, 5), dtype=np.int32 ) # specifying dtype
                        print(ones_array)    
                        </input>
                        <output>
                        solution
                        </output>
                    </sage>       
                    
                    
                    <p>Mostrar linhas ou elementos.</p> 
        
                    <sage>
                        <input>
                        import numpy as np
                        
                        A = np.array([[1, 4, 5, 12],
                            [-5, 8, 9, 0],
                            [-6, 7, 11, 19]])
                        
                        #  Third element of second row
                        print("A[2][1] =", A[2][1])  
                        
                        # Third row
                        print("A[2] =", A[2])
                        
                        # First column
                        print("A[:,0] =", A[:,0])    
                        </input>
                        <output>
                        solution
                        </output>
                    </sage>            
                    
        
        
                    <p>Soma e produto.</p> 
        
                    <sage>
                        <input>
                        import numpy as np
                        
                        A = np.array([[3, 6, 7], [5, -3, 0]])
                        B = np.array([[1, 1], [2, 1], [3, -3]])
                        C = A.dot(B)
                        print(C)
                        D = np.array([[1, 2], [-2, 3]])
                        print(C+D)
                        print(D^3)
                        </input>
                        <output>
                        solution
                        </output>
                    </sage>


                    <exercise>
                        <p>Sejam</p>
                        <me>
                            \alpha = 2; \,\,\, \beta = 1/3; \,\, A = \begin{pmatrix}
                            5 \amp -1 \amp 1\\
                            2 \amp -1 \amp 1\\
                            2 \amp -2 \amp -1\\
                            0 \amp 1 \amp -1
                            \end{pmatrix}\,\,\,
                            B = \begin{pmatrix}
                            1 \amp -1 \amp 2\\
                            0 \amp 3 \amp -1\\
                            2 \amp 1 \amp -1
                            \end{pmatrix}
                        </me>
                        <me>
                            C = \begin{pmatrix}
                            2 \amp 1 \amp 1 \amp 0\\
                            0 \amp -4 \amp -1 \amp -2\\
                            3 \amp 1 \amp 3 \amp -1\\
                            -2 \amp -1 \amp 2 \amp 1
                            \end{pmatrix}\,\,\,
                            D = \begin{pmatrix}
                            -1 \amp 2 \amp -1 \\
                            -1 \amp -1 \amp 1 \\
                            -1 \amp 0 \amp 2 
                            \end{pmatrix}\,\,\,
                            \vec{v} = \begin{pmatrix}
                            -1\\
                            2\\
                            1
                            \end{pmatrix}\,\,\,
                            \vec{u} = \begin{pmatrix}
                            -1 \\
                            2\\
                            2
                            \end{pmatrix}
                        </me>
                        <p>
                            Determine se é possível realizar as seguintes operações. Caso seja, determine o resultado
                        </p>
                        <ol>
                            <li><m>\alpha B;</m></li>
                            <li><m>\beta \vec{v};</m></li>
                            <li><m>A + B;</m></li>
                            <li><m>B - D;</m></li>
                            <li><m>2\vec{v}-3\vec{u};</m></li>
                            <li><m>AB;</m></li>
                            <li><m>BA;</m></li>
                            <li><m>A\vec{u};</m></li>
                            <li><m>C\vec{u}.</m></li>
                        </ol>
                    </exercise>

                    <example>
                        <p>Para as matrizes</p>
                        <me>
                            A = \begin{pmatrix}
                            a_{11} \amp a_{12} \amp \cdots \amp a_{1n}\\
                            a_{21} \amp a_{22} \amp \cdots \amp a_{2n}\\
                            \vdots \amp \vdots \amp \ddots \amp \vdots\\
                            a_{m1} \amp a_{m2} \amp \cdots \amp a_{mn}
                            \end{pmatrix}, \,\,\, \vec{x} = \begin{pmatrix}
                            x_{1}\\
                            x_{2}\\
                            \vdots\\
                            x_{n}
                            \end{pmatrix}
                        </me>
                        <p>temos</p>
                        <me>A\vec{x} = \begin{pmatrix}
                            a_{11} x_1 + a_{12} x_2 + \cdots + \amp a_{1n} x_n\\
                            a_{21} x_1 + a_{22} x_2 + \cdots + \amp a_{2n} x_n\\
                            \vdots\\
                            a_{m1} x_1 + a_{m2} x_2 + \cdots + \amp a_{mn} x_n
                            \end{pmatrix}
                        </me>
                    </example>

                    <exercise>
                        <p>Para as matrizes</p>
                        <me>
                            A = \begin{pmatrix}
                            a_{11} \amp a_{12} \amp a_{13} \amp a_{14}\\
                            a_{21} \amp a_{22} \amp a_{23} \amp a_{24}\\
                            a_{31} \amp a_{32} \amp a_{33} \amp a_{34}
                            \end{pmatrix}, \,\,\, \vec{x} = \begin{pmatrix}
                            x_{1}\\
                            x_{2}\\
                            x_{3}\\
                            x_{4}
                            \end{pmatrix}
                        </me>
                        <p>calcule</p>
                        <me>A\vec{x}.
                        </me>
                    </exercise>

                    <example>
                        <p>
                            No estudo de uma doença consideramos as pessoas de uma determinada população divididas em 3 grupos: saudáveis (S), doentes (D) e resistentes (R). Suponha que temos uma população inicial de 90.000 S e 10.000 D. Além disso suponha que, a cada ciclo da doença, <m>10\%</m> das pessoas saudáveis ficam doentes, nenhuma adquire resistência antes de ficar doente, <m>10\%</m> das doentes morrem, <m>30\%</m> das doentes se recuperam e adquirem resistência, as outras doentes continuam doentes, <m>50\%</m> das pessoas com resistência permanece com a resistência e <m>50%</m> das pessoas com resistência, perde a resistência (mas continua saudável).
                        </p>
                        <p>
                            Qual o total de pessoas em cada categoria (SDR) após 1 ciclo, após 2 ciclos, após 10 ciclos e após 50 ciclos?
                        </p>
                    </example>

                    <exercise>
                        <p>
                            No estudo de uma doença consideramos as pessoas de uma determinada população divididas em 3 grupos: saudáveis (S), doentes (D) e resistentes (R). Suponha que temos uma população inicial de 90.000 S e 10.000 D. Além disso suponha que, a cada ciclo da doença, <m>20\%</m> das pessoas saudáveis ficam doentes, nenhuma adquire resistência antes de ficar doente, <m>5\%</m> das doentes morrem, <m>30\%</m> das doentes se recuperam, <m>30\%</m> das doentes se recuperam adquirem resistência, as outras doentes continuam doentes, <m>80\%</m> das pessoas com resistência permanece com a resistência e <m>50%</m> das pessoas com resistência, perde a resistência (mas continua saudável).
                        </p>
                        <p>
                            Qual o total de pessoas em cada categoria (SDR) após 1 ciclo, após 2 ciclos, após 10 ciclos e após 50 ciclos?
                        </p>
                    </exercise>








                </subsection>




            </section>






        <!--  *********************************************************
        ***************************************************************
        ***************************************************************
        *************************************************************** -->
        
        
            <section xml:id = "Projects">

                <title>Projetos</title>

                <intro>

                    <p>Essa seção reúne projetos utilizando álgebra linear. ** Em construção**</p>

                </intro>
                
                <subsection xml:id="Proj1">
                    <title>Projeto 1 - Criando uma dieta</title>
                    
                    <p>Imagine que você é um nutricionista, e precisa prescrever uma dieta para um paciente. Você pode optar por alimentos em uma lista fechada. Os valores nutricionais desses alimentos são conhecidos, e você deve determinar 
                    a quantidade de cada alimento a ser consumida diariamente, de modo que, ao fim do dia, o paciente consuma determinada quantidade de cada macronutriente ou substância química presente nos alimentos, como por exemplo gorduras, carboidratos, minerais, proteínas, dentre outros.
                    </p>
                    
                    <exercise>
                     <p>Encontre as quantides de fibra alimentar, carboidratos, sódio, proteínas e gorduras totais de 5 alimentos de sua escolha. Para isso, utilize o site <url href="https://tabnut.dis.epm.br/alimento">https://tabnut.dis.epm.br/alimento</url></p>
                     <solution>
                         Exemplo de solução (seus alimentos serão, provavelmente, diferentes):
                         <ol>
                             <li>Arroz, branco, grao longo, normal, cozido</li>
                             <li>Feijao, preto, semente madura, cozido, sem sal</li>
                             <li>Frango, carne branca, so carne, pronto para consumo, assado</li>
                             <li>Alface, crespa, crua</li>
                             <li>Tomate, vermelho, maduro, cru</li>
                         </ol>
                         <ol></ol>
                         Obs: As quantidades informadas se referem a uma porção de 100 gramas do alimento mencionado.
                         <table>
                         <tabular>
                             <row>
                             <cell halign="center">
                                 Alimento
                             </cell>
                             <cell>
                                 Fibra
                             </cell>
                             <cell>
                                 Carboidratos
                             </cell>
                             <cell>
                                 Sódio
                             </cell>
                             <cell>
                                 Proteínas
                             </cell>
                             <cell>
                                 Gorduras
                             </cell>
                             </row>
                             <row>
                             <cell>
                                 1
                             </cell>
                             <cell>
                                 0,4 g
                             </cell>
                             <cell>
                                 28,17 g
                             </cell>
                             <cell>
                                 1 mg
                             </cell>
                             <cell>
                                 2,69 g
                             </cell>
                             <cell>
                                 0,28 g
                             </cell>
                             </row>
                             <row>
                             <cell>
                                 2
                             </cell>
                             <cell>
                                 8,7 g
                             </cell>
                             <cell>
                                 23,71 g
                             </cell>
                             <cell>
                                 1 mg
                             </cell>
                             <cell>
                                 8,86 g
                             </cell>
                             <cell>
                                 0,54 g
                             </cell>
                             </row>
                             <row>
                             <cell>
                                 3
                             </cell>
                             <cell>
                                 0 g
                             </cell>
                             <cell>
                                 0 g
                             </cell>
                             <cell>
                                 51 mg
                             </cell>
                             <cell>
                                 27,13 g
                             </cell>
                             <cell>
                                 4,07 g
                             </cell>
                             </row>
                             <row>
                             <cell>
                                 4
                             </cell>
                             <cell>
                                 1,2 g
                             </cell>
                             <cell>
                                 2,97 g
                             </cell>
                             <cell>
                                 10 mg
                             </cell>
                             <cell>
                                 0,9 g
                             </cell>
                             <cell>
                                 0,14 g
                             </cell>
                             </row>
                             <row>
                             <cell>
                                 5
                             </cell>
                             <cell>
                                 1,2 g
                             </cell>
                             <cell>
                                 3,89 g
                             </cell>
                             <cell>
                                 5 mg
                             </cell>
                             <cell>
                                 0,88 g
                             </cell>
                             <cell>
                                 0,2 g
                             </cell>
                             </row>
                         </tabular>
                         </table>
                     </solution>
                    </exercise>
                    
                    <exercise>
                     <p>Determine uma quantidade-alvo para cada macronutriente citado e escreva um sistema linear que modele a dieta proposta.</p>
                     <solution>
                     Um exemplo de solução, utilizando os alimentos citados anteriormente, é:
                     <ol>
                         <li> Fibra alimentar: 20.6 g</li>
                         <li> Carboidratos: 110.62 g</li>
                         <li> Sódio: 172 mg</li>
                         <li> Proteínas: 106.27 g</li>
                         <li> Gorduras: 14.19 g</li>
                     </ol>
                      <md>  
                       <mrow> \amp 0,4\, x_1 + 8,7\, x_2 + 1,2\, x_4 + 1,2\, x_5 = 20,6 </mrow>
                       <mrow> \amp 28,17\, x_1 + 23,71\,x_2 + 2,97\, x_4 + 3,89\, x_5 = 110,62</mrow>
                       <mrow> \amp x_1 + x_2 + 51\, x_3 + 10\, x_4 + 5\, x_5 = 172</mrow>
                       <mrow> \amp 2,69\, x_1 + 8,86\, x_2 + 27,13\, x_3 + 0,9\, x_4 + 0,88\, x_5 = 106,27</mrow>
                       <mrow> \amp 0,28\, x_1 + 0,54\, x_2 + 4,07\, x_3 + 0,14\, x_4 + 0,2\, x_5 = 14,19</mrow>
                      </md>
                     </solution>
                    </exercise>
                    
                    <exercise>
                     <p>Utilize o código na <xref ref="sol_lin_sys"></xref>  para resolver o sistema linear e descobrir as quantidades de cada alimento que o paciente deve consumir.</p>
                     <solution>
                      Para o exemplo anterior, a solução devolvida pelo programa foi:
                      <ol></ol>
                      Você deverá consumir diariamente:
                      <ul>
                      <li>200.0 g de Arroz</li>
                      <li>200.0 g de Feijão</li>
                      <li>300.0 g de Frango</li>
                      <li>100.0 g de Alface</li>
                      <li>100.0 g de Tomate</li>
                      </ul>
                     </solution>
                    </exercise>
                    
                    <remark xml:id="sol_lin_sys">
                    <p>Código para a resolução de sistemas lineares utilizando o método de Gauss-Jordan.</p>
                     <sage>
                       <input>
                         import numpy as np
                         import fractions
     
                         # Aqui estão os rótulos do problema
                         und = "g"  # Unidade de massa
                         foods = ["Arroz", "Feijão", "Frango", "Alface", "Tomate"]  # Lista de alimentos (Em ordem)
                         quant = 100  # A cada quantos gramas/quilos/etc de comida temos a quantidade listada de nutrientes?
                         negSol = True  # Caso esteja setado como "False", o programa gerará um erro caso as soluções sejam negativas
     
                         # Esta variável define o número de casas decimais para arredondamento dos resultados
                         decPlaces = 2
     
                         # Coloque aqui a matriz AMPLIADA do sistema:
                         ampl = [[   0.4,    8.7,     0,   1.2,   1.2,    20.6],
                                 [ 28.17,  23.71,     0,  2.97,  3.89,  110.62],
                                 [     1,      1,    51,    10,     5,     172],
                                 [  2.69,   8.86, 27.13,   0.9,  0.88,  106.27],
                                 [  0.28,   0.54,  4.07,  0.14,   0.2,   14.19]]
     
                         # Estes códigos são referentes às funções que realizam a redução de Gauss-Jordan
     
                         def gaussianElimination(A,prin=True):
                             a=0
                             A = A + fractions.Fraction()
     
                             if prin==True:
                                 print('A='+str(A))
                             for j in range(np.shape(A)[1]-1):
                                 b=0
                                 for i in range(a,np.shape(A)[0]):
                                     if A[i,j] != 0:
                                         if a !=i:
                                             A[[a,i]]=A[[i,a]]
                                             if prin==True:
                                                 print('\n~'+str(A))
                                         if A[a,j]!=1:
                                             A[a]=A[a]/A[a,j]
                                             if prin==True:
                                                 print('\n~'+str(A))
                                         a=a+1
                                         b=1
                                         break
                                 if b==1:
                                     for i in range(a,np.shape(A)[0]):
                                         if A[i,j] != 0:
                                             A[i]=A[i]-A[a-1]*A[i,j]
                                         if prin==True:
                                             print('\n~'+str(A))
     
                                 i = 0
                                 for line in A:
                                     j = 0
                                     for elem in line:
                                         A[i][j] = float(elem)
                                         j += 1
                                     i += 1
     
                             np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
                             return A
     
                         def gaussJordan(A,prin=True):
                             B=gaussianElimination(A,prin)
                             #print('jordan')
                             a=0
                             for i in range(np.shape(A)[0]):
                                 b=0
                                 for j in range(np.shape(A)[1]):
                                     if B[np.shape(B)[0]-i-1,j] == 1 and b==0:
                                         b=j
                                         for k in range(np.shape(B)[0]-i-1):
                                             B[np.shape(B)[0]-i-2-k]=B[np.shape(B)[0]-i-2-k]- B[np.shape(B)[0]-i-2-k,j]*B[B.shape[0]-i-1]
                                             if prin==True:
                                                     print('\n~'+str(B))                
                             np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
                             return B
     
                         ampl = np.array(ampl)
                         done = False
     
                         # Dimensões da matriz de coeficientes A
                         m = np.shape(ampl)[0]
                         n = np.shape(ampl)[1] - 1
     
                         # Extraindo a matriz de coeficientes da matriz ampliada
                         A = ampl[0:m, 0:n]
                         A = np.array(A)
     
                         # Agora iremos verificar em qual caso o sistema se encaixa: Solução única, sem solução ou infinitas soluções
                         # Para isso, verificaremos o posto da matriz de coeficientes A e o posto da matriz ampliada
                         rankA = np.linalg.matrix_rank(A)
                         rankAmpl = np.linalg.matrix_rank(ampl)
     
                         # Para resolver o sistema linear, será feita a redução de Gauss-Jordan na matriz ampliada:
                         print("Escalonamento passo a passo da matriz ampliada do sistema:\n")
                         esc = gaussJordan(ampl)
     
                         # Devido ao truncamento em python, vamos filtrar valores infinitesimais para evitar que fiquem como "-0.0"
                         i = 0
                         changed = False
                         while i &lt; m:
                             if round(esc[i][n], decPlaces) == -0.0:
                                 esc[i][n] = 0
                                 changed = True
                             i+=1
     
                         if changed == True:
                             esc = gaussJordan(esc, prin=False)
     
                         # Imprimindo na tela a matriz ampliada escalonada reduzida
                         print("\nMatriz ampliada escalonada reduzida do sistema:")
                         print(esc, "\n")
     
                         # Aqui verificamos se o sistema é sem solução. De acordo com o teorema, se o posto da matriz ampliada
                         # for diferente do posto da matriz de coeficientes, o sistema não tem solução
                         if rankA != rankAmpl:
                             raise Exception("O sistema não possui soluções reais!")
     
                         # Aqui verificamos se o sistema é de solução única
                         sol = []
                         if rankA == n:
                             for i in range(rankA):
                                 sol.append((esc[i][n])*quant)
     
                             # Aqui filtramos os valores: Valores negativos não fazem sentido nesse contexto
                             if negSol == False:
                                 for elem in sol:
                                     if elem &lt; 0:
                                         raise Exception("O sistema linear possui solução negativa")
     
                             # Aqui vamos imprimir os resultados de maneira formatada
                             print("Você deverá consumir diariamente:")
                             for i in range(n):
                                 print(f'{round(sol[i], decPlaces)} {und} de {foods[i]}')
                             done = True
     
                         # Se a execução do programa chegar até aqui, temos várias soluções.
                         # Iremos trabalhar com otimização linear para interpretar os resultados.
     
                         if not done:
                             # inicialização de contadores
                             i = 0
                             j = 0
     
                             # Array que contem as linhas com as variaveis fixas
                             fixas = []
                             # Array que contem as variáveis fixas
                             varsFixas = []
                             # Array com as linhas que contém variáveis livres
                             livres = []
     
                             while i &lt; rankA:
                                 livres.append(i)
                                 i += 1
     
                             # Aqui filtramos valores negativos:
                             if negSol == False:
                                 for line in esc:
                                     if line[n] &lt; 0:
                                         raise Exception("O sistema linear possui solução negativa")
     
     
                             # Aqui verificaremos as linhas da matriz escalonada reduzida em busca
                             # de linhas que possuam apenas um número não nulo, em busca de variáveis
                             # cujo valor seja fixado
     
                             i = 0
                             while i &lt; rankA:
                                 notNullCount = 0
                                 j = 0
                                 while j &lt; n:
                                     if esc[i][j] != 0:
                                         notNullCount += 1
                                         k = j
                                     j += 1
                                 if notNullCount == 1:
                                     livres.remove(i)
                                     varsFixas.append(k)
                                     fixas.append(i)
                                 i += 1
     
     
                             # Já sabendo as relações entre variáveis fixas e livres, vamos imprimir
                             # na tela os resultados (por ora, sem otimização)
     
                             print("Você deverá consumir diariamente:")
                             for i in fixas:
                                     print(f'{round(esc[i][n]*quant, decPlaces)} {und} de {foods[varsFixas[i]]}')
     
                             for i in livres:
                                 varsLivres = []
                                 j = 0
                                 while j &lt; n:
                                     if esc[i][j] != 0:
                                         varsLivres.append(j)
                                         k=j
                                     j += 1
     
                                 print("Você pode escolher consumir diariamente:")
                                 for j in range(len(varsLivres) - 1):
                                     print(f'{foods[varsLivres[j]]},', end=" ")
                                 print(f'{foods[k]},', end=" ")
                                 print(f'De modo que:')
                                 for j in range(len(varsLivres) - 1):
                                     print(f'{esc[i][varsLivres[j]]} porção de {foods[varsLivres[j]]} +', end=" ")
                                 print(f'{esc[i][k]} porção de {foods[k]} totalize {round(esc[i][n]*quant, decPlaces)}{und}')
                       </input>
                       <output>
                         out
                       </output>
                     </sage>
                     </remark>
                    
                    
                    <exercise>
                     <p>A solução encontrada faz sentido? Há algo inconveniente ou inadequado na solução? Justifique sua resposta. </p>
                     <solution>
                     Reflita se, dentro do contexto da dieta, sua solução faz sentido. Nesse contexto, fazem sentido soluções negativas?
                     Mude o parâmetro "negSol" do código em <xref ref="sol_lin_sys"></xref> para "False". O programa irá bloquear automaticamente
                     qualquer solução negativa que aparecer!
                     </solution>
                    </exercise>
                    
                    <exercise>
                     <p>Remova um dos alimentos de sua lista e tente determinar as quantidedes ideais de cada alimento para atingir seus objetivos nutricionais. Qual o resulta obtido? O que você acha que ocorreu? </p>
                     <solution>Algum texto.</solution>
                    </exercise>
     
                    <exercise>
                     <p>Faça uma lista com um total de 7 alimentos e tente determinar as quantidedes ideais de cada alimento para atingir seus objetivos nutricionais. Qual o resulta obtido? O que você faria para obter uma resposta?</p>
                     <solution>Uma possibilidade é fixar os valores das variáveis livres a seu critério. Outra opção (mais utilizada em problemas práticos) é minimizar determinadas variáveis, como a seguir:</solution>
                    </exercise>
                    
                    <remark xml:id="minmax_lin_sys">
                    <p>Código para a resolução de sistemas lineares utilizando o método de Gauss-Jordan.</p>
                     <sage>
                       <input>
                         1+3
                       </input>
                       <output>
                         soma
                       </output>
                     </sage>
                     </remark>
     
                </subsection>
           </section>
           




        <!--  *********************************************************
        ***************************************************************
        ***************************************************************
        *************************************************************** -->

        <section xml:id="section-computation">
            <title>Solve symbolic system and  elementary operations</title>

            <p>Solve a linear system.</p> 

            <sage>
                <input>
#Python package for symbolic computation
from sympy import *
from sympy.solvers.solveset import linsolve

#defining variables
x, y, z = symbols('x, y, z')

#solving the system x  + z - 1=0, 2*x + y + 2*z - 3=0, y - 3*z - 5=0 
linsolve([x  + z - 1, 2*x + y + 2*z - 3, y - 3*z - 5 ], (x, y, z))
                </input>
                <output>
                solution
                </output>
            </sage>
            

			<p>Write a matrix using numpy.</p> 

            <sage>
                <input>
#Python package for numerical computation
import numpy as np

# Write an array representing the matrix
A= np.array([[1.,2.,1.,3.],[3.,-1.,-3.,-1.],[2.,3.,1.,4.]])

# Print the shape of the matrix and the matrix
print(str(A.shape)+' matrix')
print('A='+str(A))
                </input>
                <output>
                solution
                </output>
            </sage>
            
            <p>Define elementary operations on the rows of a matrix.</p> 

            <sage>
                <input>
#Elementary Row Operations:

# Interchanging rows
def InterchangeRows(A,i,j):
    A[[int(i), int(j)]] = A[[int(j), int(i)]]
    return A

# Multiply rows by scalar
def MultiplyRow(A,i,c):
    A[i] = c*A[i]
    return A

# Add a multiple (c) of another row [j] to a row [i]
def AddMultRow(A,i,j,c):
    A[i] = A[i]+c*A[j]
    return A
                </input>
                <output>
                solution
                </output>
            </sage>
            
            <sage>
                <input>
#Apply the row operations 

InterchangeRows(A,0,1)

#MultiplyRow(A,0,5)

#AddMultRow(A,2,1,4)
                </input>
                <output>
                solution
                </output>
            </sage>
            
        </section>
        
        <!--  *********************************************************
        ***************************************************************
        ***************************************************************
        *************************************************************** -->

            
        <section xml:id="section-Gaussian">
            <title>Gaussian Elimination</title>    
            <p>A method of Gaussian elimination.</p> 

            <sage>
                <input>
# Write an array representing the augmented matrix
import numpy as np
import fractions
A= np.array([[1.,2.,1.,3.],[3.,-1.,-3.,-1.],[2.,3.,1.,4.]])


#Step by step Gaussian Elimination:

def Gaussian_elimination(A,prin=True):
    a=0
    if prin==True:
        print('A='+str(A))
    for j in range(A.shape[1]-1): #search pivot in each column
        b=0
        for i in range(a,A.shape[0]):
            if A[i,j] != 0: #choose row with not null pivot
                if a !=i:
                    A[[a,i]]=A[[i,a]]
                    if prin==True:
                        print('~'+str(A))
                if A[a,j]!=1:
                    A[a]=A[a]/A[a,j]
                    if prin==True:
                        print('~'+str(A))
                a=a+1
                b=1
                break
        if b==1:
            for i in range(a,A.shape[0]):
                if A[i,j] != 0:
                    A[i]=A[i]-A[a-1]*A[i,j]
                if prin==True:
                    print('~'+str(A))
    np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
    return A
Gaussian_elimination(A)
                </input>
                <output>
                solution
                </output>
            </sage>
            
				<p>Reverse substitution in a row echelon form matrix (does not work always - use with caution).</p>             
            
            <sage>
                <input>
import sympy as sym
import numpy as np
import fractions

A= np.array([[1.,2.,1.,3.],[3.,-1.,-3.,-1.],[2.,3.,1.,4.],[2.,3.,1.,2.]])

B=Gaussian_elimination(A,prin=False)
n=B.shape[1]-1

a=list(sym.symbols('a0:%d'%n))



for i in range(B.shape[0]):
    eq=B[B.shape[0]-i-1,B.shape[1]-1]
    for j in range(B.shape[1]-1):
        eq = eq - B[B.shape[0]-i-1,j]*a[j]
    if np.abs(eq-B[B.shape[0]-i-1,B.shape[1]-1])==0 and B[B.shape[0]-i-1,B.shape[1]-1]!=0:
        print('incompatible')
        break
    print
    sol=None
    for j in range(B.shape[1]-1):
        try:
            sol=sym.solve(eq,a[j])
            if sol!=[]:
                print('a'+str(j)+'='+str(sol))
                a[j]=sol[0]
                break
        except:
            pass
                </input>
                <output>
                solution
                </output>
            </sage>
            
             <p><m>\int_0^3 x^2 dx</m>.</p>
               <me>x = \frac{3}{2}</me>
               
               <md>
                <mrow>a =\amp 3x^2 -9</mrow>
                <mrow> =\amp y^2 -1</mrow>
                </md>

                <table>
                  <title>A simple table</title>
                  <tabular halign="center">
                    <row header="yes" bottom="minor" >
                      <cell>Variable <m>x</m></cell>
                      <cell>Variable <m>y</m></cell>
                      <cell>Conjunction <m>x\wedge y</m></cell>
                      <cell>Disjunction <m>x\vee y</m></cell>
                    </row>
                    <row>
                      <cell>T</cell>
                      <cell>T</cell>
                      <cell>T</cell>
                      <cell>T</cell>
                    </row>
                    <row>
                      <cell>T</cell>
                      <cell>F</cell>
                      <cell>F</cell>
                      <cell>T</cell>
                    </row>
                    <row>
                      <cell>F</cell>
                      <cell>T</cell>
                      <cell>F</cell>
                      <cell>T</cell>
                    </row>
                    <row>
                      <cell>F</cell>
                      <cell>F</cell>
                      <cell>F</cell>
                      <cell>F</cell>
                    </row>
                  </tabular>

                </table>


        </section>
        
        
        <!--  *********************************************************
        ***************************************************************
        ***************************************************************
        *************************************************************** -->

            
        <section xml:id="section-Gauss-Jordan">
            <title>Gauss-Jordan reduction</title>    
            <p>A method of Gaussian elimination.</p> 

            <sage>
                <input>
                    # Write an array representing the augmented matrix
                import numpy as np
                import fractions
                A= np.array([[1.,1.,1.,0.,1],[1.,1.,-1.,1.,2],[1.,1.,1.,0.,-2.],[1.,1.,-1.,1.,2.]])


                #Step by step Gaussian Elimination:

                def Gaussian_elimination(A,prin=True):
                    a=0
                    if prin==True:
                        print('A='+str(A))
                    for j in range(A.shape[1]): #search pivot in each column
                        b=0
                        for i in range(a,A.shape[0]):
                            if A[i,j] != 0: #choose row with not null pivot
                                if a !=i:
                                    A[[a,i]]=A[[i,a]]
                                    if prin==True:
                                        print('~'+str(A))
                                if A[a,j]!=1:
                                    A[a]=A[a]/A[a,j]
                                    if prin==True:
                                        print('~'+str(A))
                                a=a+1
                                b=1
                                break
                        if b==1:
                            for i in range(a,A.shape[0]):
                                if A[i,j] != 0:
                                    A[i]=A[i]-A[a-1]*A[i,j]
                                if prin==True:
                                    print('~'+str(A))
                    np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
                    return A
                </input>
                <output>
                solution
                </output>
            </sage>
            
				<p>Follows from Gaussian elimination to complete the Gauss-Jordan reduction.</p>             
            
            <sage>
                <input>
A= np.array([[1.,-1.,1.,3.,3.,0.],[-1.,1.,-1.,3.,2.,0.],[4.,2.,0.,3.,-1.,8.],[0.,2.,5.,3.,-2.,9.]])

def Gauss_Jordan(A,prin=True):
    B=Gaussian_elimination(A,prin)
    #print('jordan')
    a=0
    for i in range(A.shape[0]): #search pivot in each line
        b=0
        for j in range(A.shape[1]):
            if B[B.shape[0]-i-1,j] == 1 and b==0: #choose column with a '1' pivot
                b=j
                for k in range(B.shape[0]-i-1):
                    B[B.shape[0]-i-2-k]=B[B.shape[0]-i-2-k]- B[B.shape[0]-i-2-k,j]*B[B.shape[0]-i-1]
                    if prin==True:
                            print('~'+str(B))                
    np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
    return B
Gauss_Jordan(A)
                </input>
                <output>
                solution
                </output>
            </sage>

        </section>
        
       <!--  *********************************************************
        ***************************************************************
        ***************************************************************
        *************************************************************** -->

            
        <section xml:id="section-Matrices">
            <title>Basic commands for matrices.</title>   
             
            <p>Matrices of different kinds.</p> 

            <sage>
                <input>
import numpy as np

A = np.array([[1, 2, 3], [3, 4, 5]])
print(A)

A = np.array([[1.1, 2, 3], [3, 4, 5]]) # Array of floats
print(A)

A = np.array([[1, 2, 3], [3, 4, 5]], dtype = complex) # Array of complex numbers
print(A)
                </input>
                <output>
                solution
                </output>
            </sage>
            
            
            <p>Matrices of zeros and ones.</p> 

            <sage>
                <input>
import numpy as np

zeors_array = np.zeros( (2, 3) )
print(zeors_array)


ones_array = np.ones( (1, 5), dtype=np.int32 ) # specifying dtype
print(ones_array)    
                </input>
                <output>
                solution
                </output>
            </sage>       
            
            
            <p>Print rows columns and elements.</p> 

            <sage>
                <input>
import numpy as np

A = np.array([[1, 4, 5, 12],
    [-5, 8, 9, 0],
    [-6, 7, 11, 19]])

#  Third element of second row
print("A[2][1] =", A[2][1])  

# Third row
print("A[2] =", A[2])

# First column
print("A[:,0] =", A[:,0])    
                </input>
                <output>
                solution
                </output>
            </sage>            
            


            <p>Basic operations.</p> 

            <sage>
                <input>
import numpy as np

A = np.array([[3, 6, 7], [5, -3, 0]])
B = np.array([[1, 1], [2, 1], [3, -3]])
C = A.dot(B)
print(C)
D = np.array([[1, 2], [-2, 3]])
print(C+D)
                </input>
                <output>
                solution
                </output>
            </sage>


            <p>Transpose of a matrix.</p> 

            <sage>
                <input>
import numpy as np

A = np.array([[1, 1], [2, 1], [3, -3]])
print(A.transpose())
                </input>
                <output>
                solution
                </output>
            </sage>

                 
            
				<p>Inverse of a matrix.</p>             
            
            <sage>
                <input>
# Python program to inverse
# a matrix using numpy
  
# Import required package
import numpy as np
import fractions #for fractions (comment the line below, for decimals)
np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
  
# Taking a 3 * 3 matrix
A = np.array([[6, 1, 1],
              [4, -2, 5],
              [2, 8, 7]])
  
# Calculating the inverse of the matrix
print(np.linalg.inv(A))
                </input>
                <output>
                solution
                </output>
            </sage>

        </section>        
        
        <!--  *********************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        *************************************************************** -->

            
        <section xml:id="ElDecomp">
            <title>Decompositions; Inverse finding</title>    
            
            <subsection xml:id="LU">
            <title>Decomposition PA = LU</title>
                            <p>Calculates the decomposition PA=LU. The matrix P only trades lines in A, if need be, then decomposes as LU.</p>             
                                
                                <sage>
                                    <input>
                    # PA=LU decomposition
                    # a matrix using numpy
                      
                    # Import required package
                    import numpy as np
                    import fractions #for fractions (comment the line below, for decimals)
                    np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
                      
                    import pprint
                    import scipy
                    import scipy.linalg   # SciPy Linear Algebra Library

                    A = np.array([ [7, 3, -1, 2], [3, 8, 1, -4], [-1, 1, 4, -1], [2, -4, -1, 6] ])
                    P, L, U = scipy.linalg.lu(A)

                    print('A:')
                    pprint.pprint(A)

                    print('P:')
                    pprint.pprint(P)

                    print('L:')
                    pprint.pprint(L)

                    print('U:')
                    pprint.pprint(U)
                                    </input>
                                    <output>
                                    solution
                                    </output>
                                </sage>            
            </subsection>
        
            
        <!--  *********************************************************
        *************************************************************** -->


            <subsection xml:id="InverseAI">
            <title>Finding the inverse through Gauss - Jordan reduction</title>


                        <p>If we apply Gauss-Jordan reduction in the matrix (A|I), A concatenated with I, we obtain the Identity, if possible, concatenated with the inverse of A. For that we need the method of Gaussian elimination.</p> 

                        <sage>
                            <input>
                                # Write an array representing the augmented matrix
                                import numpy as np
                                import fractions
                                A= np.array([[1.,1.,1.,0.,1],[1.,1.,-1.,1.,2],[1.,1.,1.,0.,-2.],[1.,1.,-1.,1.,2.]])


                                #Step by step Gaussian Elimination:

                                def Gaussian_elimination(A,prin=True):
                                a=0
                                if prin==True:
                                    print('A='+str(A))
                                for j in range(A.shape[1]): #search pivot in each column
                                    b=0
                                    for i in range(a,A.shape[0]):
                                        if A[i,j] != 0: #choose row with not null pivot
                                            if a !=i:
                                                A[[a,i]]=A[[i,a]]
                                                if prin==True:
                                                    print('~'+str(A))
                                            if A[a,j]!=1:
                                                A[a]=A[a]/A[a,j]
                                                if prin==True:
                                                    print('~'+str(A))
                                            a=a+1
                                            b=1
                                            break
                                    if b==1:
                                        for i in range(a,A.shape[0]):
                                            if A[i,j] != 0:
                                                A[i]=A[i]-A[a-1]*A[i,j]
                                            if prin==True:
                                                print('~'+str(A))
                                    np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
                                return A
                            </input>
                            <output>
                            solution
                            </output>
                        </sage>
                        
                    <p>Follows from Gaussian elimination to complete the Gauss-Jordan reduction and obtains (I|A^-1)) .</p>             
                        
                        <sage>
                            <input>
                                A = np.array([[1.,1.,3.,3.],[-1.,1.,-1.,3.],[4.,2.,0.,3.],[0.,2.,5.,3.]])
                                I = np.identity(4)
                                AI = np.concatenate((A, I), axis=1)

                                def Gauss_Jordan(A,prin=True):
                                    B=Gaussian_elimination(A,prin)
                                    #print('jordan')
                                    a=0
                                    for i in range(A.shape[0]): #search pivot in each line
                                        b=0
                                        for j in range(A.shape[1]):
                                            if B[B.shape[0]-i-1,j] == 1 and b==0: #choose column with a '1' pivot
                                                b=j
                                                for k in range(B.shape[0]-i-1):
                                                    B[B.shape[0]-i-2-k]=B[B.shape[0]-i-2-k]- B[B.shape[0]-i-2-k,j]*B[B.shape[0]-i-1]
                                                    if prin==True:
                                                            print('~'+str(B))                
                                    np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
                                    return B
                                B = Gauss_Jordan(AI)
                            </input>
                            <output>
                            solution
                            </output>
                        </sage>


                    <p>We can test the matrix B, found by computing the Gauss-Jordan reduction, by calculating A * B. The result should be (A|I).</p>             
                        <sage>
                            <input>
                              print(A)
                              print(A.dot(B))
                            </input>
                            <output>
                            solution
                            </output>
                        </sage>

                 </subsection>
        </section>        
        

        <!--  *********************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        *************************************************************** -->                                                                                                    



        <section xml:id="espacos-vetoriais">
            <title>Espaços Vetoriais</title>
           
            <intro>
               <p>O conceito de <term>Espaço Vetorial</term> trata de espaços que têm uma operação de multiplicação por escalar e uma operação de adição de <term>vetores</term>, assim como <m>\mathbb{R}^3</m> com as operações usuais, 
               e identifica as principais propriedades operacionais esperadas para seu uso, permitindo a aplicação em espaços muito diferentes de <m>\mathbb{R}^n</m> e nos mais diversos contextos. Essa seção inicia relembrando o que são vetores 
               em <m>\mathbb{R}^n</m> e segue apresentando o conceito de espaço vetorial e alguns dos exemplos não triviais importantes. Em seguida introduz-se o conceito de subespaço vetorial e como aplicá-lo, junto com uma aplicação para a 
               ilustração de subespaços de dimensão 1 ou 2 em <m>\mathbb{R}^3</m>.</p>
           </intro>
           
            <subsection xml:id="Rn_vecs">
               <title>Vetores em <m>\mathbb{R}^n</m></title>
               
                <p>Um <term>vetor</term> <m>\vec{x}</m> representa o conjunto de todos os segmentos orientados em <m>\mathbb{R}^3</m> com o mesmo comprimento, direção e sentido.</p>
                
                <sage>
                    <input>
                    import numpy as np
                    import matplotlib.pyplot as plt #library for plots
                    import random #library for random number generation

                    x_x = [2] #the x coordinates of a vector representant at the origin
                    x_y = [1] #the y coordinates of a vector representant at the origin

                    starting_points_x = [0]
                    starting_points_y = [0]

                    for i in range(10): #add other representatives of the same vector
                        sign = [-1,1][random.randrange(2)]
                        
                        starting_points_x.append(sign * random.randint(-8, 8))
                        starting_points_y.append(sign * random.randint(-8, 8))
                        x_x.append(starting_points_x[i+1]+x_x[0])
                        x_y.append(starting_points_y[i+1]+x_y[0])
                        
                        
                        
                        
                    #plotting the vectors
                    fig, ax = plt.subplots(figsize=(10,10))     
                    ax.set_xlim(xmin=-10, xmax=10)
                    ax.set_ylim(ymin=-10, ymax=10)
                    ax.xaxis.set_ticks([-9,-8,-7,-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9])
                    ax.yaxis.set_ticks([-9,-8,-7,-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9])
                    plt.grid()
                    ax.quiver(starting_points_x, starting_points_y, np.ones(len(x_x))*x_x[0], np.ones(len(x_y))*x_y[0], scale =1, units="xy")

                    for xy in zip(x_x[0:3], x_y[0:3]):
                       plt.annotate('(%.2f, %.2f)' % xy, xy=xy)
                    for xy in zip(starting_points_x[0:3], starting_points_y[0:3]):
                       plt.annotate('(%.2f, %.2f)' % xy, xy=xy, va='top', ha='left')

                    plt.show()
                    </input>
                    <output>
                    solution
                    </output>
                </sage>
                
                <p>
                    Usualmente representamos um vetor pelas coordenadas do ponto final do segmento orientado que inicia na origem.
                    Assim, no plot, temos o vetor <m>\vec{x} = \left(\begin{array}{c} 2 \\ 1 \end{array}\right)</m> e 
                    outros segmentos orientados gerados aleatoriamente, todos pertencentes ao mesmo vetor.
                </p>

                <p>
                    O <term>comprimento</term> ou a <term>norma</term> de um vetor <m>\vec{x} = \left(x_1, \ldots, x_n\right)^T</m> em <m>\mathbb{R}^n</m> pode ser calculado por <me>\|\vec{x}\| = \sqrt{x_1^2 + x^2+ \cdots + x_n^2}</me>. No exemplo acima <me>\|\vec{x}\| = \sqrt{1^2+2^2}=\sqrt{5}</me>. Qualquer segmento orientado em <m>\vec{x}</m> poderia ter sido utilizado para calcular o comprimento.
                </p>
                <sage>
                    <input>
                        import numpy as np
                        import matplotlib.pyplot as plt #library for plots
                        import random #library for random number generation

                        x_x = [2] #the x coordinates of a vector representant at the origin
                        x_y = [1] #the y coordinates of a vector representant at the origin

                        starting_points_x = [0]
                        starting_points_y = [0]

                        number_of_points = 3

                        for i in range(number_of_points -1): #add other representatives of the same vector
                            sign = [-1,1][random.randrange(2)]
                            
                            starting_points_x.append(sign * random.randint(-3, 3))
                            starting_points_y.append(sign * random.randint(-4, 4))
                            x_x.append(starting_points_x[i+1]+x_x[0])
                            x_y.append(starting_points_y[i+1]+x_y[0])
                            
                            
                            
                            
                        #plotting the vectors
                        fig, ax = plt.subplots(figsize=(10,10))     
                        ax.set_xlim(xmin=-5, xmax=5)
                        ax.set_ylim(ymin=-5, ymax=5)
                        ax.xaxis.set_ticks([-4,-3,-2,-1,0,1,2,3,4])
                        ax.yaxis.set_ticks([-4,-3,-2,-1,0,1,2,3,4])
                        plt.grid()
                        ax.quiver(starting_points_x, starting_points_y, np.ones(len(x_x))*x_x[0], np.ones(len(x_y))*x_y[0], scale =1, units="xy")

                        for i in range(number_of_points):
                            plt.plot((starting_points_x[i],x_x[i], x_x[i]),(starting_points_y[i],starting_points_y[i],x_y[i]))


                        for xy in zip(x_x[0:number_of_points ], x_y[0:number_of_points ]):
                            plt.annotate('(%.2f, %.2f)' % xy, xy=xy)
                        for xy in zip(starting_points_x[0:number_of_points], starting_points_y[0:number_of_points]):
                            plt.annotate('(%.2f, %.2f)' % xy, xy=xy, va='top', ha='left')
                        for xy in zip(x_x[0:number_of_points], starting_points_y[0:number_of_points]):
                            plt.annotate('(%.2f, %.2f)' % xy, xy=xy, va='top', ha='left')

                        plt.show()

                    </input>
                    <output>
                    solution
                    </output>
                </sage>

                <exercise>
                    <statement>
                        Calcule o comprimento de três representantes de um vetor <m>\vec{x} \in \mathbb{R}^2</m> gerados pelo códico acima.
                    </statement>
                </exercise>

                <p>
                    Para vetores <m>\vec{x}, \vec{y} \in \mathbb{R}^n</m>, <m>\vec{x} = (x_1, \ldots, x_n)^T</m> e <m>\vec{y} = (y_1, \ldots, y_n)^T</m>,e um escalar <m>\alpha \in \mathbb{R}</m>, definimos as operações fundamentais de <term>multiplicação por escalar</term> e <term>adição</term> de vetores por:
                    <me>
                        \alpha \cdot \vec{x} = \alpha\begin{pmatrix}x_1\\ \vdots \\ x_n\end{pmatrix} :=  \begin{pmatrix}\alpha x_1\\ \vdots \\ \alpha x_n\end{pmatrix}; \,\,\,\,\, \vec{x} + \vec{y} = \begin{pmatrix}x_1\\ \vdots \\ x_n\end{pmatrix} + \begin{pmatrix}y_1\\ \vdots \\ y_n\end{pmatrix} := \begin{pmatrix}x_1+y_1\\ \vdots \\ x_n+y_n\end{pmatrix}
                    </me>
                    A <term>subtração</term> de vetores é definida a partir da multiplicação por escalar e da adição como <m>\vec{x} - \vec{y} := \vec{x} +(-1) \vec{y}</m>.
                </p>


                <sage>
                    <input>
                        import matplotlib.pyplot as plt
                        import numpy as np
                        
                        zero = np.zeros(2)
                        
                        x = np.array([1,2])
                        y = np.array([-2, 1])
                        
                        alpha = 2
                        
                        
                        #plotting the vectors
                        fig, ax = plt.subplots(figsize=(5, 5))     
                        ax.set_xlim(xmin=-3, xmax=5)
                        ax.set_ylim(ymin=-3, ymax=5)
                        ax.xaxis.set_ticks([-2,-1,0,1,2,3,4])
                        ax.yaxis.set_ticks([-2,-1,0,1,2,3,4])
                        plt.grid()
                        
                        head_width =0.3
                        head_length = 1.5*head_width
                        
                        def cor(x):
                            x_new = x[0]/(head_length+np.sqrt(x[0]^2+x[1]^2))*np.sqrt(x[0]^2+x[1]^2)
                            y_new = x[1]/(head_length+np.sqrt(x[0]^2+x[1]^2))*np.sqrt(x[0]^2+x[1]^2)
                            return np.array([x_new,y_new])
                        
                        plt.arrow(0,0,cor(x)[0], cor(x)[1], head_width =head_width)
                        plt.annotate('x', cor(x)/2 + np.array([0.2,-0.2]))
                        
                        plt.arrow(0,0,cor(y)[0], cor(y)[1], head_width =head_width, color = 'blue')
                        plt.annotate('y', cor(y)/2 + np.array([-0.2,-0.3]))
                        
                        plt.arrow(x[0],x[1],cor(y)[0], cor(y)[1], head_width =head_width, color = 'blue')
                        plt.annotate('y', x/2+ cor(x+y)/2 + np.array([-0.2,-0.1]))
                        
                        plt.arrow(0,0,cor(x+y)[0], cor(x+y)[1], head_width =head_width, color = 'green')
                        plt.annotate('x+y', cor(x+y)/2 + np.array([-0.7,-0.1]))
                        
                        plt.arrow(x[0],x[1],-cor(y)[0], -cor(y)[1], head_width =head_width, color = 'red')
                        plt.annotate('-y', x/2+ cor(x-y)/2 + np.array([0.2,+0.1]))
                        
                        plt.arrow(0,0,cor(x-y)[0], cor(x-y)[1], head_width =head_width, color = 'pink')
                        plt.annotate('x-y', cor(x-y)/2 + np.array([0.1,-0.1]))
                        
                        plt.arrow(0,0,alpha*cor(x)[0], alpha*cor(x)[1], head_width =head_width, color = 'purple')
                        plt.annotate(r'$\alpha$ x', alpha*cor(x)/1.25 + np.array([0.2,-0.2]))
                        
                        plt.show() 
                    </input>
                    <output>
                    solution
                    </output>
                </sage>

            </subsection>


        <!--  *********************************************************
        *************************************************************** -->
            

            <subsection xml:id="Esp_vet">
                <title>Espaços Vetoriais</title>
                <p>
                    Definimos agora um espaço vetorial, construindo conjuntos de "vetores" para os quais eximtem operações de "adição" e "multiplicação" por "escalar" com as mesmas propriedades das operações em vetores do <m>\mathbb{R}^n</m>, de modo operarmos com eles de modo semelhante ao <m>\mathbb{R}^n</m>, todavia podemos ter objetos muito distintos dos usuais para cada um dos termos entre parênteses.
                </p>

                <definition>
                    <notation>
                      <usage><m>V</m></usage>
                      <description>espaço vetorial</description>
                    </notation>
                  
                    <statement>
                      <p>
                        Seja <m>E</m> um conjunto de escalares (usualmente <m>\mathbb{C}</m> ou <m>\mathbb{C}</m>, mas qualquer <it>corpo</it> serviria). Um <term>espaço vetorial</term> <m>(V,E,\oplus,\odot)</m> é um conjunto sobre o qual estão definidas duas operações:
                        <md>
                            <mrow>\oplus: \amp V \times V: \to V, </mrow>
                            <mrow>(C1) \hspace{9mm} \amp \vec{u}, \vec{v} \in V \Rightarrow \vec{u} \oplus \vec{v}</mrow>
                            <mrow>\odot: \amp E \times V: \to V, </mrow>
                            <mrow>(C2) \hspace{9mm} \amp \alpha \in E, \vec{v} \in V \Rightarrow \alpha\vec{u}</mrow>
                        </md>
                        e as operações satisfazem as seguintes propriedades para quaisquer <m>\vec{u}, \vec{v}, \vec{w} \in V</m> e <m>\alpha, \beta \in E</m>:
                        <dl>
                            <li>(A1)   <m>\hspace{5mm} \vec{u} + \vec{v} = \vec{v} + \vec{u},</m></li>
                            <li>(A2)   <m>\hspace{5mm} (\vec{u} + \vec{v}) +\vec{w} = \vec{u} + (\vec{v} + \vec{w}),</m></li>
                            <li>(A3)   <m>\hspace{5mm} \exists \,\,\, \vec{0} \in V; \vec{u} + \vec{0} = \vec{u} \,\, \forall \,\, \vec{u} \in V,</m> </li>
                            <li>(A4)   <m>\hspace{5mm} \forall \,\, \vec{u} \in V, \exists ! \,\,\, -\vec{u} \in V; \vec{x} + (-\vec{x}) = \vec{0}</m></li>
                            <li>(A5)   <m>\hspace{5mm} \alpha(\vec{u} + \vec{v}) = \alpha\vec{u} + \alpha\vec{v},</m></li>
                            <li>(A6)   <m>\hspace{5mm} (\alpha + \beta) \vec{u} = \alpha\vec{u} + \beta\vec{u},</m></li>
                            <li>(A7)   <m>\hspace{5mm} (\alpha\beta)\vec{u} = \alpha(\beta\vec{u}),</m></li>
                            <li>(A8)   <m>\hspace{5mm} 1\vec{u} = \vec{u}.</m></li>
                        </dl>
                        V é dito o <term>conjunto universal</term>, os elementos de V são ditos <term>vetores</term> e os elementos de E são ditos <term>escalares</term>. Muitas vezes, quando está claro quais as operações de adição e multiplicação por escalar e qual o conjunto E de escalares, Chamamos V de um espaço vetorial omitindo o corpo de escalares e as operações de adição e multiplicação por escalar.
                      </p>
                    </statement>
                </definition>


                <example>
                    O conjunto <m>V = \{ \vec{u} = (u_1, u_2)^T \in \mathbb{R}^2 | u_2 =1\}</m> não é um espaço vetorial com escalares reais e as operações de adição e multiplicação por escalar herdadas de <m>\mathbb{R}^2</m> pois, dados <m>\vec{u}, \vec{v} \in V</m>, <m>\vec{u} = (u_1, 1)^T</m> e <m>\vec{v} = (v_1, 1)^T</m> temos que
                    <me>
                        \vec{u} + \vec{v} = \left( \begin{array}{c} u_1\\ 1 \end{array} \right) + \left( \begin{array}{c} v_1\\ 1 \end{array} \right) = \left( \begin{array}{c} u_1 + v_1\\ 2 \end{array} \right) \notin V.
                    </me>
                    Deste modo C1 não é válida e <m>V</m> não é um espaço vetorial.
                </example>


                <exercise>
                    <statement>
                        Para mostrar que um conjunto <m>V</m> não é um espaço vetorial, basta mostrar que uma das propriedades não é válida. Todavia mais propriedades podem não ser válidas. Encontre mais duas das propriedades (entre C2 e) que não são válidas para <m>V</m> e justifique sua escolha.
                    </statement>
                </exercise>

                <example>
                     <m>\mathbb{R}^n</m> com escalares reais ou complexos e as operações de adição e multiplicação por escalar usuais é um espaço vetorial para qualquer <m>n \in \mathbb{N}</m>. Para verificar isso é necessário verificar a validade de <m>C1, \, C2, \, A1, \, \ldots, \, A8 </m>.
                </example>


                <example>
                    O conjunto  <m>V = \{ \vec{u} \in \mathbb{R}^3 | \vec{u} = \alpha_1(-1,0,1)^T + \alpha_2 (0, 1, 1)^T, \, \alpha_1, \alpha_2 \in \mathbb{R}\}</m>, com escalares reais e as operações de adição e multiplicação por escalar herdadas de <m>\mathbb{R}^3</m> é um espaço vetorial pois, dados <m>\vec{u}, \vec{v}, \vec{w} \in V</m>, <m>\vec{u} = \alpha_1(-1,0,1)^T + \alpha_2 (0, 1, 1)^T </m>, <m>\vec{v} = \beta_1(-1,0,1)^T + \beta_2 (0, 1, 1)^T </m> e <m>\vec{w} = \gamma_1(-1,0,1)^T + \gamma_2 (0, 1, 1)^T </m> e <m>\alpha, \beta \in \mathbb{R}</m>, verificamos a validade de cada uma das propriedades (alguns detalhes são omitidos por já conhecermos as propriedades da adição de vetores em <m>\mathbb{R}^3</m>):
                
                    <md>
                        <mrow>(C1) \hspace{5mm} \vec{u} + \vec{v} =\amp \alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) + \beta_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \beta_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) </mrow>
                        <mrow> =\amp (\alpha_1+\beta_1)\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + (\alpha_2+\beta_2)\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) \in V,</mrow>.
                    </md>
                    <p>de modo que a soma de dois elementos de V é um elemento de <m>V</m> </p>.
                    
                    <md>
                        <mrow>
                            (C2) \hspace{5mm} \alpha\vec{u} = \alpha\left(\alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right)\right) = \alpha\alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha\alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right),\in V,
                        </mrow>
                    </md>
                        <p>de modo que a multiplicação de um elemento de V por um escalar é um elemento de <m>V</m>.</p>

                    <md>
                        <mrow> (A1) \hspace{5mm} \vec{u} + \vec{v} =\amp \alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) + \beta_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \beta_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) </mrow>
                        <mrow> =\amp \beta_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \beta_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) + \alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) = \vec{v} + \vec{u}.</mrow>
                    </md>

                    <md>
                         <mrow> (A2) \hspace{5mm} (\vec{u} + \vec{v}) +\vec{w} =\amp \left( \alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) + \beta_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \beta_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right)\right) + \gamma_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \gamma_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right),</mrow>
                         <mrow>=\amp \alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) + \left(\beta_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \beta_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) + \gamma_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \gamma_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right)\right),</mrow>
                         <mrow>=\amp \vec{u} + (\vec{v} + \vec{w}).</mrow>
                    </md>
                    
                    <md>
                        <mrow>
                            (A3) \hspace{5mm} \vec{0} = 0\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + 0\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right)\in V e \vec{u} + \vec{0} = \vec{u} \,\, \forall \,\, \vec{u} \in V.
                        </mrow>
                    </md>

                    <md>
                        <mrow>
                            (A4) \hspace{5mm} \forall \amp \,\, \vec{u} = \alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right)\in V,  \,\, -\vec{u} = (-\alpha_1)\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + (-\alpha_2)\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right)\in V \Longrightarrow \vec{x} + (-\vec{x}) = \vec{0}
                        </mrow>
                        <mrow>
                            \vec{u} +\vec{-u} \amp  = \alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) + (-\alpha_1)\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + (-\alpha_2)\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right)
                        </mrow>
                        <mrow>
                            \amp = (\alpha_1-\alpha_1)\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + (\alpha_2-\alpha_2)\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) = \vec{0}
                        </mrow>

                    </md>

                    <md>
                        <mrow>
                            (A5) \hspace{5mm} \alpha(\vec{u} + \vec{v}) =\amp \alpha\left((\alpha_1+\beta_1)\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + (\alpha_2+\beta_2)\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right)\right) = (\alpha\alpha_1+\alpha\beta_1)\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + (\alpha\alpha_2+\alpha\beta_2)\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right)
                        </mrow>
                        <mrow>
                            =\amp \alpha\alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha\alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) left + \alpha\beta_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha\beta_2 \left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) =  \alpha\vec{u} + \alpha\vec{v}
                        </mrow>
                    </md>
                    <md>
                        <mrow>
                            (A6) \hspace{5mm} (\alpha + \beta) \vec{u} =\amp (\alpha + \beta)\alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + (\alpha + \beta)\alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) 
                        </mrow>
                        <mrow>
                            =\amp \alpha\alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha\alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) + \beta\alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \beta \alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) = \alpha\vec{u} + \beta\vec{u},
                        </mrow>
                    </md>
                    <md>
                        <mrow>
                            (A7) \hspace{5mm} (\alpha\beta) \vec{u} =\amp (\alpha \beta)\alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + (\alpha \beta)\alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) 
                        </mrow>
                        <mrow>
                            =\amp \alpha(\beta\alpha_1)\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha(\beta\alpha_2)\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) = \alpha(\beta\vec{u}),
                        </mrow>
                    </md>
                    <md>
                        <mrow>
                            (A8) \hspace{5mm} 1 \vec{u} = 1\alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + 1\alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) = \alpha_1\left( \begin{array}{c} -1\\ 0 \\ 1 \end{array} \right) + \alpha_2\left( \begin{array}{c} 0\\ 1 \\ 1 \end{array} \right) = \vec{u} 
                        </mrow>
                    </md>
                    <p>Portanto <m>V</m> é um espaço vetorial. </p>
                </example>

                <p>O código abaixo plota o plano gerado pelos vetores do exemplo anterior.</p>


                <sage>
                    <input>
                        import numpy as np
                        import matplotlib.pyplot as plt
                        from mpl_toolkits.mplot3d import Axes3D
                        
                        point  = np.array([1, 2, 3])
                        
                        u = np.array([-1,0,1])
                        v = np.array([0,1,1])
                        
                        normal = np.cross(u,v)
                        
                        # a plane is a*x+b*y+c*z+d=0
                        # [a,b,c] is the normal. Thus, we have to calculate
                        # d and we're set
                        d = -point.dot(normal)
                        
                        # create x,y
                        xx, yy = np.meshgrid(range(10), range(10))
                        
                        # calculate corresponding z
                        z = (-normal[0] * xx - normal[1] * yy - d) * 1. /normal[2]
                        
                        
                        # Create the figure
                        fig = plt.figure()
                        
                        # Add an axes
                        ax = fig.add_subplot(111,projection='3d')
                        
                        # plot the surface
                        ax.plot_surface(xx, yy, z, alpha=0.2)
                        
                        plt.show()
                    </input>
                    <output>
                    solution
                    </output>
                </sage>


                <theorem>
                    <!-- <title>Optional</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    <p>
                      Se <m>V</m> é um espaço vetorial e <m>\vec{x} \in V</m>, então:
                      <ol marker="A">
                        <li> <m> 0 \vec{x} = \vec{0}, </m> </li>
                        <li> <m> \vec{x}  + \vec{y} = \vec{0} \,\, \Longrightarrow \,\, \vec{y} = - \vec{x}, </m> </li>
                        <li> <m> (-1) \vec{x} = -\vec{x}, </m> </li>
                      </ol>
                    </p>
                  </statement>
                
                  <proof>
                    <ol marker="A">
                        <li> <m> \vec{x} = 1\vec{x} = (1+ 0 )\vec{x} = \vec{x} + 0\vec{x} \Longrightarrow  -\vec{x} + \vec{x} = -\vec{x} + \vec{x} + 0\vec{x} \Longrightarrow \vec{0} = 0\vec{x}, </m> </li>
                        <li> <m> \vec{0} = \vec{x} + \vec{y} \Longrightarrow  -\vec{x} + \vec{0} = -\vec{x} + \vec{x} + \vec{y} \Longrightarrow -\vec{x} = \vec{y}, </m> </li>
                        <li> <m> \vec{0} = (1-1) \vec{x} = \vec{x}+(-1)\vec{x} \Longrightarrow - \vec{x} + \vec{0} = - \vec{x} + \vec{x} +(-1) \vec{x} \Longrightarrow - \vec{x} = (-1) \vec{x} </m> </li>
                      </ol>
                  </proof>
                </theorem>


                <example>
                    O conjunto de todas as funções reais definidas no intervalo <m>(a,b)</m>, que têm derivada de ordem <m>n</m> contínua (com escalares reais e as operações usuais de adição e multiplicação por escalar) é um espaço vetorial, denominado <m>C^n(a,b)</m>. Deixamos a verificação das propriedades C1 e C2, A1 - A8 a cargo do leitor.
                </example>

                <example>
                    O conjunto de todas as matrizes reais <m>n\times m</m> (com escalares reais e as operações usuais de adição e multiplicação por escalar) é um espaço vetorial. Deixamos a verificação das propriedades C1 e C2, A1 - A8 a cargo do leitor.
                </example>


            </subsection>
           
        </section>

        <!--  *********************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        *************************************************************** -->                                                                                                    



        <section xml:id="subescos">
            <title>Subespaços Vetoriais</title>
           
            <intro>
               <p>Mostrar que um conjunto é um espaço vetorial é uma tarefa que pode ser longa e repetitiva, uma vez tenhamos compreendido bem o conceito. Essa tarefa fica muito mais fácil quando consideramos subconjuntos de um espaço vetorial</p>
           </intro>
           
            <subsection xml:id="subespacos-subsection">
               <title>Subespaço</title>

                <definition>
                    <notation>
                    <usage><m>S</m></usage>
                    <description>subespaço vetorial</description>
                    </notation>
                
                    <statement>
                    <p>
                        Sejam <m>(V, E, \oplus, \odot)</m> um espaço vetorial e <m>S \subset V</m> um subconjunto de <m>V</m>. <m>S</m> é dito um <term>subespaço (vetorial)</term> de <m>V</m> se, e somente se:
                        <ol>
                            <li><m>S \neq \emptyset,</m></li>
                            <li><m>\alpha \odot \vec{u} \in S, \,\, \forall   \,\, \vec{u} \in S, \,\, \alpha \in E,</m></li>
                            <li><m>\vec{u} \oplus \vec{v} \in S, \,\, \forall   \,\, \vec{u}, \vec{v} \in S.</m> </li>
                        </ol>
                    </p>
                    </statement>
                </definition>

                <p>A primeira condição diz que o subconjunto não é vazio, a segunda dis que a mutiplicação de um elemento de S por um escalar resulta em um elemento de S e a terceira diz que o resultado da soma de dois elementos de S é um elemento de S.</p>

                <lemma>
                    <!-- <title>Optional</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    <p>
                        Sejam <m>(V, E, \oplus, \odot)</m> um espaço vetorial e <m>S \subset V</m> um subespaço vetorial. Então <m>(S, E, \oplus, \odot)</m> é um espaço vetorial.
                    </p>
                  </statement>
                
                  <proof>
                    Como <m>S \subset V</m> e <m>S</m> tem o mesmo conjunto de escalares e operações, valem as propriedades <m>A1  - /A8</m> desde que <m>\alpha \odot \vec{x}</m> e <m>\vec{x} \oplus \vec{y}</m> sejam elementos de <m>S</m>, o que é requerido pela definição de subespaço vetorial. 
                  </proof>
                </lemma>

                <example>
                    O conjunto  <m>V = \{ \vec{u} \in \mathbb{R}^3 | \vec{u} = \alpha_1(-1,0,1)^T + \alpha_2 (0, 1, 1)^T, \, \alpha_1, \alpha_2 \in \mathbb{R}\}</m>, com escalares reais e as operações de adição e multiplicação por escalar herdadas de <m>\mathbb{R}^3</m> é um subespaço vetorial de <m>\mathbb{R}^3</m> pois, dados <m>\alpha \in \mathbb{R}</m> e  <m>\vec{u} =\alpha_1(-1,0,1)^T + \alpha_2 (0, 1, 1)^T </m>, <m>\vec{v} =\beta_1(-1,0,1)^T + \beta_2 (0, 1, 1)^T \in V</m>:
                    <ol>
                        <li><m>\vec{0} = 0 (-1,0,1)^T + 0 (0, 1, 1)^T \in V \Longrightarrow V \neq \emptyset,</m></li>
                        <li><m>\alpha\vec{u} = \alpha \alpha_1(-1,0,1)^T + \alpha \alpha_2 (0, 1, 1)^T \in V,</m></li>
                        <li><m>\vec{u} + \vec{v} = (\alpha_1+\beta_1)(-1,0,1)^T + (\alpha_2 +\beta_2) (0, 1, 1)^T \in V.</m></li>
                    </ol>
                    <p>Assim <m>V</m> é um subespaço de <m>\mathbb{R}^3</m> e automaticamente um espaço vetorial (não precisávamos verificar todas as propriedades, como feito no exemplo anterior).</p>
                </example>

                <exercise>
                    <statement>
                        Verifique que <m>S = \left\{ A \in \mathbb{R}^{2\times2} \left| A = \left(\begin{array}{cc} a_{11} \amp a_{12} \\ -a_{12} \amp a_{22} \end{array}\right) \right.\right\}</m> é um subespaço de <m>\mathbb{R}^{2\times2} </m>.
                    </statement>
                </exercise>

                <exercise>
                    <statement>
                        Verifique que <m>S = \left\{ f \in C^2(a,b) \left| f''(x) + f(x) =0 \,\, \forall \,\, x \in (a,b) \right.\right\}</m> é um subespaço de <m>C^2(a,b) </m>.
                    </statement>
                </exercise>

                <exercise>
                    <statement>
                        Utilize o código abaixo para esboçar o subespaço de <m>S = \{\vec{u} \in \mathbb{R}^3| \vec{u} = \alpha_1 (1,1,0)^T + \alpha_2 (-1,1,1)^T \}.</m>
                    </statement>
                </exercise>

                <sage>
                    <input>
                        import numpy as np
                        import matplotlib.pyplot as plt
                        from mpl_toolkits.mplot3d import Axes3D
                        
                        point  = np.array([1, 2, 3])
                        
                        u = np.array([-1,0,1])
                        v = np.array([0,1,1])
                        
                        normal = np.cross(u,v)
                        
                        # a plane is a*x+b*y+c*z+d=0
                        # [a,b,c] is the normal. Thus, we have to calculate
                        # d and we're set
                        d = -point.dot(normal)
                        
                        # create x,y
                        xx, yy = np.meshgrid(range(10), range(10))
                        
                        # calculate corresponding z
                        z = (-normal[0] * xx - normal[1] * yy - d) * 1. /normal[2]
                        
                        
                        # Create the figure
                        fig = plt.figure()
                        
                        # Add an axes
                        ax = fig.add_subplot(111,projection='3d')
                        
                        # plot the surface
                        ax.plot_surface(xx, yy, z, alpha=0.2)
                        
                        plt.show()
                    </input>
                    <output>
                    solution
                    </output>
                </sage>

                

            </subsection>

            <!--  *********************************************************
            *************************************************************** -->
                

            <subsection xml:id="Esp_nulo">
                <title>Espaço Nulo de uma matriz</title>

                <definition>
                    <notation>
                    <usage><m>N(A)</m></usage>
                    <description>espaço nulo</description>
                    </notation>
                
                    <statement>
                    <p>
                        Seja <m>A \in \mathbb{R}^{n \times m}</m>. O conjunto de todas as soluções de <m>A\vec{x} =\vec{0}</m> é chamado de <term>espaço nulo</term> de <m>A</m> e denotado <m>N(A)</m>: 
                        <me>
                            N(A) = \{\vec{x} \in \mathbb{R}^m | A\vec{x} = \vec{0}\}.
                        </me>
                    </p>
                    </statement>
                </definition>


                <example xml:id = "ex_esp_nulo">
                    <statement>
                        O espaço nulo da matriz
                        <me>
                            A = \left(\begin{array}{cccc} 1 \amp 1 \amp 1 \amp 0 \\ 2 \amp 1 \amp 0 \amp 1 \end{array} \right)
                        </me>
                        consiste das soluções de <m>A\vec{x} = \vec{0}</m>, ou seja, soluções do sistema

                        <md>
                            <mrow> \begin{array}{c} x_1 + x_2 + x_3 = 0\\ 2x_1 + x_2 + x_4 = 0\end{array} \Leftrightarrow \begin{array}{c} x_2 + 2x_3 -x_4 = 0\\ 2x_1 + x_2 + x_4 = 0\end{array} \Leftrightarrow \begin{array}{c} x_1 = x_3 - x_4 \\ x_2 =  2x_3 - x_4 \end{array}, </mrow>
                        </md>
                        <p>denotando <m>\alpha = x_3</m> e <m>\beta = x_4</m>, temos:</p>
                        <md>
                            <mrow>N(A) =\amp \{\vec{x} \in \mathbb{R}^4 | \vec{x} = (\alpha -\beta, -2\alpha + \beta, \alpha, \beta)^T \}</mrow>
                            <mrow> =\amp \{\vec{x} \in \mathbb{R}^4 | \alpha(1, -2, 1, 0)^T + \beta(-1, 1, 0, 1)^T, \,\, \alpha, \beta \in \mathbb{R}\}</mrow>
                        </md>

                    </statement>
                </example>


                



                <lemma>
                    <!-- <title>Optional</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    <p>
                        Para qualquer matriz <m>A \in \mathbb{R}^{n \times m}</m>, <m>N(A)</m> é um subespaço de <m>\mathbb{R}^m</m>.
                    </p>
                  </statement>
                
                  <proof>
                    Dados <m>\vec{x}, \vec{y} \in N(A)</m> e <m>\alpha \in \mathbb{R}</m>: 
                    <ol>
                        <li><m> A\vec{0} = \vec{0} \Longrightarrow  \vec{0} \in N(A) \Longrightarrow N(A) \neq \emptyset,</m></li>
                        <li><m>A(\alpha\vec{x}) = \alpha A \vec{x} = \vec{0} \Longrightarrow \alpha\vec{x} \in N(A),</m></li>
                        <li><m>A(\vec{x} + \vec{y}) = A\vec{x} + A\vec{y} = \vec{0} + \vec{0} = \vec{0} \Longrightarrow \vec{x}+\vec{y} \in N(A).</m></li>
                    </ol>
                  </proof>
                </lemma>


                <example>
                    <title>Matriz de uma projeção</title>
                    <statement>
                        Uma matriz <m>A \in \mathbb{R}^{3 \times 3}</m> representa uma projeção em um plano que passa pela origem se <m>A^2 = A</m> (esse fato será justificado quando estudarmos transformações lineares). Note (calcule) que a matriz <m>A</m> tem essa propriedade:
                        <me>
                            A = \left(\begin{array}{ccc} 5/6 \amp 1/6 \amp  1/3\\
                            1/6 \amp  5/6 \amp -1/3\\
                            1/3 \amp -1/3 \amp  1/3 \end{array} \right).
                        </me>
                        O núcleo de <m>A</m> dá a direção normal ao plano de projeção. Para encontrar <m>N(A)</m> precisamos resolver <m>A\vec{x} = \vec{0},</m> o que pode ser feito por eliminação Gaussiana: 
                        <md>
                            <mrow>\left(\begin{array}{ccc|c} 5/6 \amp 1/6 \amp  1/3 \amp 0\\
                            1/6 \amp  5/6 \amp -1/3 \amp 0\\
                            1/3 \amp -1/3 \amp  1/3 \amp 0 \end{array} \right) \sim \left(\begin{array}{ccc|c} 1 \amp 1/5 \amp  2/5 \amp 0\\
                            1 \amp  5 \amp -2 \amp 0\\
                            1 \amp -1 \amp  1 \amp 0 \end{array} \right)</mrow>
                            <mrow> \sim \left(\begin{array}{ccc|c} 1 \amp 1/5 \amp  2/5 \amp 0\\
                            0 \amp  24/5 \amp -12/5 \amp 0\\
                            0 \amp -6/5 \amp  -3/4 \amp 0 \end{array} \right) \sim \left(\begin{array}{ccc|c} 1 \amp 1/5 \amp  2/5 \amp 0\\
                            0 \amp  1 \amp -1/2 \amp 0\\
                            0 \amp 0 \amp  0 \amp 0 \end{array} \right).</mrow>
                        </md>
                        <p>de modo que <m>x_2 = x_3/2</m> e <m>x_1 = -x_3/2</m> e <m>N(A) = \{\vec{x} \in \mathbb{R}^3 | \vec{x} = \alpha (1/2, -1/2, 1)^T\}</m> e um vetor normal ao plano é <m>(1/2, -1/2, 1)^T</m>.</p>
                    </statement>
                </example>


                <p>O código plota um o plano que passa pela origem se dermos como imput o vetor normal a esse plano.</p>


                <sage>
                    <input>
                        import numpy as np
                        import matplotlib.pyplot as plt
                        from mpl_toolkits.mplot3d import Axes3D
                        
                        point  = np.array([0, 0, 0])
                        
                        normal = np.array([1/2, -1/2, 1])
                        
                        # a plane is a*x+b*y+c*z+d=0
                        # [a,b,c] is the normal. Thus, we have to calculate
                        # d and we're set
                        d = -point.dot(normal)
                        
                        # create x,y
                        xx, yy = np.meshgrid(range(10), range(10))
                        
                        # calculate corresponding z
                        z = (-normal[0] * xx - normal[1] * yy - d) * 1. /normal[2]
                        
                        
                        # Create the figure
                        fig = plt.figure()
                        
                        # Add an axes
                        ax = fig.add_subplot(111,projection='3d')
                        
                        # plot the surface
                        ax.plot_surface(xx, yy, z, alpha=0.2)
                        
                        plt.show()
                    </input>
                    <output>
                    solution
                    </output>
                </sage>


                <exercise>
                    <statement>
                        Verifique se a matriz
                        <me>
                            A = \left(\begin{array}{ccc} 0,5 \amp  0 \amp  0,5\\
                            0\amp  1\amp 0 \\
                            0,5\amp  0\amp  0,5 \end{array} \right).
                        </me>
                        representa uma projeção, em caso positivo encontre o seu núcleo e utilize o código acima para plotar o plano de projeção.
                    </statement>
                </exercise>


                <remark>
                    Note que <m>N(A)</m> não pode ser vazio, pois <m>\vec{0} \in N(A)</m> uma vez que <m>A\vec{0} = \vec{0}</m> para qualquer matriz.
                </remark>


                <lemma>
                    <!-- <title>Optional</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    <p>
                       Considere o sistema <m>A\vec{x} = \vec{b}</m>,  então a diferença entre duas soluções do sistema está em <m>N(A)</m>. Além disso, a soma de uma solução do sistema com um elemento do núcleo é também solução do sistema.
                    </p>
                  </statement>
                
                  <proof>
                    Dados <m>\vec{x}, \vec{y}</m> soluções de <m>A\vec{x} = \vec{b}</m>, temos:
                    <me>
                        A(\vec{x} - \vec{y}) = A\vec{x} - A\vec{y} = \vec{b} - \vec{b} = \vec{0}.
                    </me>
                    Se <m>\vec{x}</m> é solução de <m>A\vec{x} = \vec{b}</m> e <m>\vec{n} \in N(A)</m>, temos:
                    <me>
                        A(\vec{x} + \vec{n}) = A\vec{x} + A\vec{n} = \vec{b} + \vec{0} = \vec{b}.
                    </me> 
                  </proof>
                </lemma>
            </subsection>
           
        </section>


        <!--  *********************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        *************************************************************** -->                                                                                                    



        <section xml:id="bases">
            <title>Base de um Espaço Vetorial</title>
           
            <intro>
               <p>
                Muitas vezes representamos vetores de <m>\mathbb{R}^3</m> como <m>\vec{x} = x \vec{i} + y \vec{j} + z \vec{k}</m>. Os vetores <m>\{ \vec{i}, \vec{j}, \vec{k} \}</m> formam o que chamamos de uma <term>base</term> para <m>\mathbb{R}^3</m>. Nessa seção definimos bases para espaços vetoriais quaisquer. Para isso precisamos de um conjunto de vetores com os quais possamos escrever quaisquer vetores do espaço através de uma soma (para isso estudamos <term>spans</term> na primeira subseção) e queremos que não haja redundância no conjunto de vetores escolhidos (para isso estudamos <term>independância linear</term> na segunda subseção).
               </p>
           </intro>
           
            <subsection xml:id="coberturas">
               <title>Spans (Coberturas)</title>

                <definition>
                    <notation>
                    <usage><m>Span(\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n) \,\,\mtext{ ou }\,\, Cob(\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n)</m></usage>
                    <description>cobertura</description>
                    </notation>
                
                    <statement>
                    <p>
                        Sejam <m>V</m> um espaço vetorial e <m>\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n \in V</m>. Uma soma da forma
                        <me>
                            \alpha_1\vec{v}_1 + \alpha_2 \vec{v}_2 + \ldots + \alpha_n \vec{v}_n
                        </me>
                        é dita uma <term>combinação linear</term> de <m>\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n</m>. O conjunto de todas as combinações lineares de <m>\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n</m> é chamado de <term>Span de</term>  <m>\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n</m> (as nomenclaturas <term>cobertura de</term> ou <term>espaço vetorial gerado por</term> também são utilizadas na literatura): 
                        <me>
                            Span(\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n) = \{\vec{x} \in V | \vec{x} = \alpha_1\vec{v}_1 + \alpha_2\vec{v}_2+ \ldots + \alpha_n \vec{v}_n\}.
                        </me>
                    </p>
                    </statement>
                </definition>

                <example>
                    <statement>
                        No <xref ref="ex_esp_nulo"> </xref>, o espaço nulo da matriz
                        <me>
                            A = \left(\begin{array}{cccc} 1 \amp 1 \amp 1 \amp 0 \\ 2 \amp 1 \amp 0 \amp 1 \end{array} \right)
                        </me>
                        é igual ao <m>Span((1, -2, 1, 0)^T, (-1, 1, 0, 1)^T)</m>:

                        <md>
                            <mrow>
                                 N(A) = \amp \{\vec{x} \in \mathbb{R}^4 | \alpha(1, -2, 1, 0)^T + \beta(-1, 1, 0, 1)^T, \,\, \alpha, \beta\in \mathbb{R}\} 
                            </mrow>
                            <mrow>
                                =\amp Span((1, -2, 1, 0)^T, (-1, 1, 0, 1)^T).
                            </mrow>
                        </md>
                    </statement>
                </example>

                <example>
                    <statement>
                        Denotamos por <m>\vec{e}_i \in \mathbb{R}^n</m> o vetor cuja <m>i</m>-ésima entrada é igual a 1 e todas as demais são nulas 
                        <me>
                            \vec{e}_i = (0, \ldots, 0, 1, 0, \ldots, 0)
                        </me>
                        para <m>\vec{e}_1,\vec{e}_2,\vec{e}_3 \in \mathbb{R}^3</m>, <m>Span(\vec{e}_1,\vec{e}_2,\vec{e}_3)</m> é formado por todos os vetores da forma
                        <me>
                            \alpha\left(\begin{array}{c} 1 \\ 0 \\ 0 \end{array} \right) + \beta\left(\begin{array}{c} 0 \\ 1 \\ 0 \end{array} \right) + \gamma\left(\begin{array}{c} 0 \\ 0 \\ 1 \end{array} \right) = \left(\begin{array}{c} \alpha \\ \beta \\ \gamma \end{array} \right),
                        </me>
                        de modo que <m>Span(\vec{e}_1,\vec{e}_2,\vec{e}_3) = \mathbb{R}^3</m>.
                    </statement>
                </example>



                <theorem>
                    <!-- <title>Optional</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    <p>
                      Se <m>\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n \in V</m>, então <m>Span(\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n)</m> é um subespaço vetorial de V.
                    </p>
                  </statement>
                
                  <proof>
                    Se <m>\vec{v} = \alpha_1\vec{v}_1 + \alpha_2\vec{v}_2 +  \ldots + \alpha_n\vec{v}_n</m> e <m>\vec{w} = \beta_1\vec{v}_1 + \beta_2\vec{v}_2 +  \ldots + \beta_n\vec{v}_n</m> e <m>\alpha</m> é um escalar, então
                    <ol marker="A">
                        <li> <m> \vec{0} = 0\vec{v}_1 + 0\vec{v}_2 +  \ldots + 0\vec{v}_n \Longrightarrow \vec{0} \in Span(\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n) </m> e <m>Span(\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n) \neq \emptyset.</m></li>
                        <li> <m> \vec{v} + \vec{w} =  (\alpha_1+\beta_1)\vec{v}_1 + (\alpha_2+\beta_2)\vec{v}_2 +  \ldots + (\alpha_n+\beta_n)\vec{v}_n</m> <m> \Longrightarrow  \vec{v} + \vec{w} \in Span(\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n), </m> </li>
                        <li> <m> \alpha\vec{v} = (\alpha\alpha_1)\vec{v}_1 + (\alpha\alpha_2)\vec{v}_2 +  \ldots + (\alpha\alpha_n)\vec{v}_n \Longrightarrow  \alpha\vec{v} \in Span(\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n). </m> </li>
                      </ol>
                  </proof>
                </theorem>

                <exercise>
                    <statement>
                        Dados vetores <m>\vec{v}_1, \vec{v}_2 \in \mathbb{R}^3</m> não colineares, o <m>Span(\vec{v}_1, \vec{v}_2)</m> é um plano que passa pela origem e qualquer desses é um subespaço de <m>\mathbb{R}^3</m>. Os planos que não passam pela origem são subespaços de <m>\mathbb{R}^3</m>? Qual a justificativa?
                    </statement>
                </exercise>


                <definition>
                    <notation>
                    <usage><m>gera</m></usage>
                    <description>conjunto de geradores</description>
                    </notation>
                
                    <statement>
                    <p>
                        Sejam <m>(V, E, \oplus, \odot)</m> um espaço vetorial e <m>\vec{v}_1,\vec{v}_2,\ldots,\vec{v}_n \in V.</m> O conjunto <m>\{\vec{v}_1,\vec{v}_2,\ldots,\vec{v}_n\}</m> é um <term>conjunto de geradores</term> (ou <term>gera</term>) <m>V</m> se, e somente se, qualquer vetor de <m>\vec{v} \in V</m> pode ser escrito como uma combinação linear de <m>\vec{v}_1,\vec{v}_2,\ldots,\vec{v}_n</m>, ou seja,
                        <me>
                            \vec{v} \in V \Longrightarrow \exists \alpha_1, \alpha_2, \ldots, \alpha_n \in E \,\, \| \,\, \vec{v} = \alpha_1\vec{v}_1 + \alpha_2\vec{v}_2 +  \ldots + \alpha_n\vec{v}_n.
                        </me>
                    </p>
                    </statement>
                </definition>


                <p>
                    Para determinar se um conjunto <m>\vec{v}_1,\vec{v}_2,\ldots,\vec{v}_k \in \mathbb{R}^n</m> gera <m>\mathbb{R}^n</m>, devemos, para qualquer vetor <m>\vec{x} = (x_1, x_2, \ldots, x_n)^T \in \mathbb{R}^n</m>, mostrar que existem escalares <m>\alpha_1, \alpha_2, \ldots, \alpha_k </m> tais que <m>\vec{x} = \alpha_1\vec{v}_1 + \alpha_2\vec{v}_2 +  \ldots + \alpha_k\vec{v}_k</m>. Se escrevemos as coordenadas para cada um dos vetores do conjunto, <m>\vec{v}_i = ({v}_{1i},\ldots,{v}_{ni})^T</m>, obtemos o sistema linear (nas variáveis <m>\alpha_1, \alpha_2, \ldots, \alpha_k </m>):
                    <md>
                        <mrow>\alpha_1\vec{v}_1 +  \ldots + \alpha_k\vec{v}_k = \vec{x} \Leftrightarrow \left\{\begin{array}{c} \alpha_1{v}_{11} +  \ldots + \alpha_k {v}_{1k} \amp  =  x_1\\
                        \alpha_1{v}_{21} +  \ldots + \alpha_k {v}_{2k} \amp  =  x_2\\
                        \vdots \amp  =  \vdots\\
                        \alpha_1{v}_{n1} +  \ldots + \alpha_k {v}_{nk} \amp =  x_n \end{array}\right.</mrow>
                        <mrow>\Leftrightarrow \left(\begin{array}{c} {v}_{11} \amp  \ldots \amp {v}_{1k} \\
                        v_{21} \amp  \ldots \amp {v}_{2k}\\
                        \vdots \amp \vdots \amp \vdots\\
                        {v}_{n1} \amp  \ldots \amp {v}_{nk} \end{array}\right) \left(\begin{array}{c} \alpha_1\\
                        \alpha_2\\
                        \vdots\\
                        \alpha_k
                          \end{array}\right) = \left(\begin{array}{c} x_1\\
                          x_2\\
                          \vdots\\
                          x_n
                            \end{array}\right)</mrow>,
                    </md>
                    onde a última das equivalências está na forma <m>A\vec{\alpha}=\vec{x}</m>. Assim perguntar se um conjunto de vetores gera <m>\mathbb{R}^n</m>, é determinar se o sistema acima tem solução para qualquer <m>\vec{x} \in \mathbb{R}^n</m>.
                </p>


                <exercise xml:id="gera_r3">
                    <statement>
                        Quais dos seguintes conjuntos são coberturas de <m>\mathbb{R}^3</m> e justifique sua resposta analisando se o sistema associado tem solução única, infinitas soluções ou não tem solução?
                        <ol marker="A">
                            <li>
                                <m>\{ \vec{e}_1, \vec{e}_2, \vec{e}_3, (1,2,3)^T\}</m>
                            </li>
                            <li>
                                <m>\{ (1,1,1)^T, (1,1,0)^T, (1,0,0)^T\}</m>
                            </li>
                            <li>
                                <m>\{ (1,0,1)^T, (0,1,0)^T\}</m>
                            </li>
                            <li>
                                <m>\{ (1,2,4)^T, (3,-1,1)^T, (2,-3,-3)^T\}</m>
                            </li>
                        </ol>
                    </statement>
                </exercise>

            </subsection>

            <!--  *********************************************************
            *************************************************************** -->
                

            <subsection xml:id="dependencia_linear">
                <title>Dependência Linear</title>
            

                <p>No item 1. do <ref ref="gera_r3"></ref> cada <m>\vec{x} \in \mathbb{R}^3</m> pode ser escrito de infinitas maneiras. Isso não é coincidência e ocorre devido ao fato que <m>(1,2,3)^T = 1\vec{e}_1 + 2\vec{e}_2 +3\vec{e}_3</m>, como esclarece o lema a seguir.</p>

                <lemma>
                    <!-- <title>Optional</title> -->
                    <!-- <creator>I. Newton</creator> -->
                    <statement>
                        <p>
                        Sejam <m>V</m> um espaço vetorial e <m>\vec{x} \in V</m> um vetor. Suponha que <m>\vec{x}</m> possa ser escrito como uma combinação linear de <m>\vec{v}_1, \vec{v}_2,  \ldots, \vec{v}_k</m>. Existem infinitas formas de escrever <m>\vec{x}</m> como combinação linear de <m>\vec{v}_1, \vec{v}_2,  \ldots, \vec{v}_k</m> exatamente quando um desses vetores pode ser escrito como combinação linear dos demais.
                        </p>
                    </statement>
                    
                    <proof>
                        <p><m>(\Longrightarrow)</m> Se for possível escrever um vetor <m>\vec{x} \in V</m> como combinação linear de <m>\vec{v}_1, \vec{v}_2,  \ldots, \vec{v}_k</m> de duas maneiras distintas, então existem escalares <m>\alpha_1, \alpha_2, \ldots, \alpha_k</m> e <m>\beta_1, \beta_2, \ldots, \beta_k</m>, nem todos iguais (<m>\alpha_i \neq \beta_i</m> para pelo menos algum <m>i \in 1, 2, \ldots, k</m>), tais que</p>
                        <md>
                            <mrow>\vec{x} =\amp \alpha_1\vec{v}_1 + \alpha_2\vec{v}_2 +  \cdots + \alpha_k\vec{v}_k</mrow>
                            <mrow>\vec{x} =\amp \beta_1\vec{v}_1 + \beta_2\vec{v}_2 +  \cdots + \beta_k\vec{v}_k</mrow>
                            <mrow>(\Longrightarrow) \vec{0} =\amp (\alpha_1-\beta_1)\vec{v}_1 + (\alpha_2-\beta_2)\vec{v}_2 +  \cdots + (\alpha_k-\beta_k)\vec{v}_k</mrow>
                        </md>
                        <p>de modo que <m>\vec{v}_1, \vec{v}_2,  \ldots, \vec{v}_k</m> é L.D. (<m>\alpha_i - \beta_i \neq 0</m> para algum <m>i</m>).</p>

                        <p><m>(\Longleftarrow)</m> Sem perda de generalidade<fn>se o vetor que pode ser escrico como combinação linear dos demais não for o último da lista, podemos fazer uma reordenação dos vetores e colocá-lo por último</fn>, se for possível escrever o vetor <m>\vec{v}_{k}</m> como combinação linear de <m>\vec{v}_1,  \ldots, \vec{v}_{k-1}</m>, então existem escalares <m>\alpha_1, \alpha_2, \ldots, \alpha_{k-1}</m>, tais que</p>
                        <md>
                            <mrow>\vec{v}_k = \amp \alpha_1\vec{v}_1 + \alpha_2\vec{v}_2 +  \cdots + \alpha_{k-1}\vec{v}_{k-1}</mrow>
                            <mrow>\Longrightarrow \vec{0} = \amp \alpha_1\vec{v}_1 + \alpha_2\vec{v}_2 +  \cdots + \alpha_{k-1}\vec{v}_{k-1} - \vec{v}_k</mrow>
                            <mrow>\Longrightarrow \vec{0} = \amp \gamma\alpha_1\vec{v}_1 + \gamma\alpha_2\vec{v}_2 +  \cdots + \gamma\alpha_{k-1}\vec{v}_{k-1} - \gamma\vec{v}_k,</mrow>
                        </md>
                        <p> para qualquer escalar <m>\gamma</m>, de modo que</p>
                        <md>
                            <mrow>\vec{x} = \amp \beta_1\vec{v}_1 + \beta_2\vec{v}_2 +  \cdots + \beta_{k-1}\vec{v}_{k-1} + \beta_{k}\vec{v}_{k}</mrow>
                            <mrow>\Longrightarrow \vec{x} = \amp (\beta_1 + \gamma\alpha_1)\vec{v}_1 + (\beta_2 + \gamma\alpha_2)\vec{v}_2 +  \cdots + (\beta_{k-1} + \gamma\alpha_{k-1})\vec{v}_{k-1} + (\beta_{k} - \gamma)\vec{v}_{k}</mrow>
                        </md>
                        <p> para qualquer escalar <m>\gamma</m>.</p>
                    </proof>
                </lemma>

                <p>
                    O Lema acima diz que teremos infinitas formas de escrever um vetor como combinação linear de <m>\vec{v}_1, \vec{v}_2,  \ldots, \vec{v}_k \in V</m>. exatamete quando existirem soluções não nulas de <m>\alpha_1 \vec{v}_1 + \alpha_2 \vec{v}_2 + \cdots + \alpha_k\vec{v}_k = \vec{0}</m>. Assim essa condição é bastante relevante para bases de um espaço vetorial e precisamos referir-nos a ela precisamente, como a seguir.
                </p>


                <definition>
                    <notation>
                    <usage><m>L.I.\,\, \mtext{ou} \,\, L.D.</m></usage>
                    <description>(in)dependência linear</description>
                    </notation>
                
                    <statement>
                    <p>
                        Seja <m>(V, E, \oplus, \odot)</m> um espaço vetorial. Os vetores <m>\vec{v}_1,\vec{v}_2,\ldots,\vec{v}_k \in V</m> são ditos <term>linearmente independentes (L.I.)</term> se a única solução<fn>Note que <m>\alpha_1 = \alpha_2 = \ldots = \alpha_k = 0</m> sempre é uma solução da equação.</fn> de 
                        <me>
                            \alpha_1\vec{v}_1 + \alpha_2\vec{v}_2 +  \cdots + \alpha_{k}\vec{v}_{k} = \vec{0}
                        </me>
                         é <m>\alpha_1 = \alpha_2 = \ldots = \alpha_k = 0</m>. Caso exista alguma solução não nula dessa equação, o conjunto <m>\{\vec{v}_1,\vec{v}_2,\ldots,\vec{v}_k\}</m> é dito <term>linearmente dependente (L.D.)</term>.
                    </p>
                    </statement>
                </definition>

                <example>
                    <statement>
                        Quais dos seguintes conjuntos de vetores são L.I.? Justifique sua resposta analisando se o sistema associado tem solução única, infinitas soluções ou não tem solução?
                        <ol marker="A">
                            <li>
                                <p>Para verificarmos se <m>\{ \vec{e}_1, \vec{e}_2, \vec{e}_3, (1,2,3)^T\}</m> é L.I., precisamos verificar se existe alguma solução não trivial para o sistema </p>
                                <md>
                                    <mrow> \alpha_1 \begin{pmatrix} 1\\ 0 \\ 0 \end{pmatrix} + \alpha_2 \begin{pmatrix} 0\\ 1 \\ 0 \end{pmatrix} + \alpha_3 \begin{pmatrix} 0\\ 0 \\ 1 \end{pmatrix} + \alpha_4 \begin{pmatrix} 1\\ 2 \\ 3 \end{pmatrix} = \begin{pmatrix} 0\\ 0 \\ 0 \end{pmatrix} </mrow>
                                    <mrow> \Leftrightarrow \begin{array}{c} \alpha_1 + \alpha_4 = 0\\ \alpha_2 + 2\alpha_4 = 0 \\ \alpha_3 + 3 \alpha_4 = 0 \end{array} </mrow>
                                    <mrow> \Leftrightarrow \begin{array}{c} \alpha_1 = - \alpha_4\\ \alpha_2 = - 2\alpha_4  \\ \alpha_3 - 3 \alpha_4  \end{array} </mrow>
                                </md>
                                <p> é solução para qualquer <m>\alpha_4 \in \mathbb{R}</m> e o istema é L.D.</p>
                            </li>
                            <li>
                                <p><m>\{ (1,1,1)^T, (1,1,0)^T, (1,0,0)^T\}</m> é L.I. pois </p>
                                <md>
                                    <mrow> \alpha_1 \begin{pmatrix} 1\\ 1 \\ 1 \end{pmatrix} + \alpha_2 \begin{pmatrix} 1\\ 1 \\ 0 \end{pmatrix} + \alpha_3 \begin{pmatrix} 1\\ 0 \\ 0 \end{pmatrix} = \begin{pmatrix} 0\\ 0 \\ 0 \end{pmatrix} </mrow>
                                    <mrow> \Leftrightarrow \begin{array}{c} \alpha_1 + \alpha_2 + \alpha_3 = 0\\ \alpha_1 + \alpha_2 = 0 \\ \alpha_1 = 0 \end{array} \Leftrightarrow \begin{array}{c} \alpha_1 = 0  \\ \alpha_2 = 0 \\ \alpha_3 = 0 </mrow>
                                </md>
                            </li>
                            <li>
                                <m>\{ (1,0,1)^T, (0,1,0)^T\}</m> é L.I.
                            </li>
                            <li>
                                <m>\{ (1,2,4)^T, (3,-1,1)^T, (2,-3,-3)^T\}</m> é L.D.
                            </li>
                        </ol>
                    </statement>
                </example>


                <remark>
                    <p>
                        Para verificar se os vetores <m>\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_k \mathbb{R}^n</m> são L.I. verificamos se o sistema
                    </p>
                    <me>
                        \alpha_1\vec{v}_1 + \alpha_2\vec{v}_2 +  \cdots + \alpha_{k}\vec{v}_{k} = \vec{0},
                    </me>
                    <p>tem solução única. Isso pode ser feito de diversas maneiras! Denotando </p>
                        <m>
                            \vec{v}_i = \begin{pmatrix} v_{1i}\\ v_{2i}\\ \vdots \\v_{ni} \end{pmatrix}\,\,</m> e <m>\,\,A =  \begin{pmatrix} | \amp | \amp \cdots \amp | \\ \vec{v}_1 \amp \vec{v}_2 \amp \cdots \amp \vec{v}_k \\ | \amp | \amp \cdots \amp | \end{pmatrix} = \begin{pmatrix} v_{11} \amp v_{12} \amp \cdots \amp v_{1k} \\ \vdots \amp \vdots \amp \cdots \amp \vdots \\ v_{n1} \amp v_{n2} \amp \cdots \amp v_{nk} \end{pmatrix},
                        </m>
                        <p>o sistema pode ser consderado nas seguintes formas, que são equivalentes à equação acima:</p>
                    <me>
                        \begin{array}{c} 
                        v_{11} \alpha_1 + v_{12} \alpha_2 + \cdots +  v_{1k}\alpha_k = 0 \\ \vdots \amp \vdots \amp \cdots \amp \vdots \\ v_{n1} \alpha_1 + v_{n2} \alpha_2 + \cdots +  v_{nk}\alpha_k = 0
                        \end{array}
                        \Leftrightarrow A \vec{\alpha} = \vec{0}.
                    </me>
                    <p> Analisando o sistema acima para entender se a solução é única, percebemos:</p>

                    <ol>
                        <li> <p>Se <m>k \gt n</m>, então <m>\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_k</m> são L.D. pois o sistema associado tem mais incógnitas do que equações.</p></li>
                        <li> <p>Se <m>k \lt n</m>, então podemos colocar o sistema associado <m>(A|\vec{0})</m> na forma escalonada e verificar se temos <m>k</m> linhas não nulas. Em caso afirmativo a solução do sistema é única e o sistema é L.I. Caso tenhamos menos do que <m>k</m> linhas não nulas, o sistema é L.D.</p></li>
                        <li> <p>Se <m>k = n</m>, então a matriz <m>A</m> é quadrada e o sistema <m>A \vec{\alpha} = \vec{0}</m> tem solução única se, e somente se, a matriz <m>A</m> é inversível, de modo que basta verificar que <m>\det(A) \neq 0</m>. </p></li>
                    </ol>

                </remark>

                <p>O código a seguir pode ser utilizado para encontrar um subconjunto L.I. dentro de um conjunto de vetores.</p>

                <sage>
                    <input>
                        import numpy as np
                        import fractions


                        # add as vectors copying the second line

                        A = np.array([1.,2.,1.,3.])
                        A = np.vstack([A,np.array([1.,2.,1.,3.])])
                        A = np.vstack([A,np.array([1.,2.,-1.,3.])])

                        # store the values
                        C = A.copy()

                        # tranaspose to get vectors on columns

                        A = np.transpose(A)




                        #Step by step Gaussian Elimination:

                        def Gaussian_elimination(A,prin=True):
                            a=0
                            if prin==True:
                                print('A='+str(A))
                            for j in range(A.shape[1]-1): #search pivot in each column
                                b=0
                                for i in range(a,A.shape[0]):
                                    if A[i,j] != 0: #choose row with not null pivot
                                        if a !=i:
                                            A[[a,i]]=A[[i,a]]
                                            if prin==True:
                                                print('~'+str(A))
                                        if A[a,j]!=1:
                                            A[a]=A[a]/A[a,j]
                                            if prin==True:
                                                print('~'+str(A))
                                        a=a+1
                                        b=1
                                        break
                                if b==1:
                                    for i in range(a,A.shape[0]):
                                        if A[i,j] != 0:
                                            A[i]=A[i]-A[a-1]*A[i,j]
                                        if prin==True:
                                            print('~'+str(A))
                            np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
                            return A
                        B = Gaussian_elimination(A, prin = False)

                        print("A na forma escalonada")
                        print(B)

                        a=0

                        for i in range(len(B)):
                            if np.count_nonzero(B[i]) != 0 :
                                a += 1
                                I = np.nonzero(B[i])
                                print(a, "vetor da base ",C[I[0][0]])
                    </input>
                    <output>
                        vectors
                    </output>
                </sage>


                <exercise>
                    <statement>
                        Quais dos seguintes conjuntos de vetores são L.I.? Justifique sua resposta analisando se o sistema associado tem solução única, infinitas soluções ou não tem solução?
                        <ol marker="A">
                            <li>
                                <m>\{ (1,-1,1)^T, (1,2,3)^T\}</m>
                            </li>
                            <li>
                                <m>\{ (1,-2,1)^T, (1,1,1)^T, (1,0,-1)^T\}</m>
                            </li>
                            <li>
                                <m>\{ (3,1,4)^T, (7,1,2)^T, (1,0,1)^T, (1,2,3)^T\}</m>
                            </li>
                            <li>
                                <m>\{ (1,2,-2)^T, (1,-1,3)^T, (5,1,5)^T\}</m>
                            </li>
                        </ol>
                    </statement>
                </exercise>


                <lemma>
                    <statement>
                        Um conjunto de vetores é L.D. se, e somente se, um dos vetores pode ser escrito como combinação linear dos demais.
                    </statement>
                    <prof>
                        A completar.
                    </prof>
                </lemma>




            </subsection>

            <!--  *********************************************************
            *************************************************************** -->
                

            <subsection xml:id="bases_subsection">
                <title>Bases</title>

                <definition>
                    <notation>
                    <usage><m>U</m></usage>
                    <description>base</description>
                    </notation>
                
                    <statement>
                    <p>
                        Sejam <m>(V, E, \oplus, \odot)</m> um espaço vetorial e <m>\vec{v}_1,\vec{v}_2,\ldots,\vec{v}_n \in V</m> vetores. O conjunto <m>\{\vec{v}_1,\vec{v}_2,\ldots,\vec{v}_n\}</m> é uma <term>base</term> para <m>V</m> se, e somente se,
                        <ol>
                            <li><p><m>\vec{v}_1,\vec{v}_2,\ldots,\vec{v}_n</m> são linearmente independentes,</p></li>
                            <li><p><m>\vec{v}_1,\vec{v}_2,\ldots,\vec{v}_n</m> cobrem <m>V</m>.</p></li>
                        </ol>
                         Alternativamente, dizemos que <m>\vec{v}_1,\vec{v}_2,\ldots,\vec{v}_n</m> <term>formam uma base</term> para <m>V</m>.
                    </p>
                    </statement>
                </definition>


                <example>
                    <statement>
                        Para verificarmos que <m>\vec{i}, \vec{j}, \vec{k}</m> formam uma base para <m>\mathbb{R}^3</m>, precisamos verificar que:
                        <ol>
                            <li><p>
                                esses vetores são L.I. Para isso precisamos mostrar que a única solução de
                                <me>
                                    \alpha_1\vec{i} + \alpha_2 \vec{j} + \alpha_3 \vec{k} = \vec{0}
                                </me>
                                é 
                                <m>
                                    \alpha_1 = \alpha_2 = \alpha_3 =0,
                                </m>
                                o que ocorre de fato pois
                                <me>
                                    \alpha_1\vec{i} + \alpha_2 \vec{j} + \alpha_3 \vec{k} = \begin{pmatrix} \alpha_1\\ \alpha_2 \\ \alpha_3 \end{pmatrix} = \begin{pmatrix} 0\\ 0 \\ 0 \end{pmatrix} \,\, \Leftrightarrow\,\, \begin{array}{c} \alpha_1 =0, \\ \alpha_2 = 0, \\ \alpha_3 = 0. \end{array}
                                </me>
                            </p></li>
                            <li><p>
                                esses vetores geram <m>\mathbb{R}^3</m>. Para isso precisamos mostrar que qualquer vetor <m>\vec{x} = (x, y, z)^T \in \mathbb{R}^3</m> pode ser escrito como uma combinação linear de <m>\vec{i}, \vec{j}, \vec{k}</m>, o que ocorre de fato pois
                                <me>\alpha_1\vec{i} + \alpha_2 \vec{j} + \alpha_3 \vec{k} \begin{pmatrix} \alpha_1\\ \alpha_2 \\ \alpha_3 \end{pmatrix} = \begin{pmatrix} x\\ y \\ z \end{pmatrix} \,\, \Leftrightarrow\,\, \begin{array}{c} \alpha_1 =x \\ \alpha_2 = y \\ \alpha_3 = z \end{array} </me>
                            </p></li>
                        </ol>
                        De modo que <m>\{\vec{i},\vec{j},\vec{k}\}</m> é uma base para <m>\mathbb{R}^3</m>.
                    </statement>
                </example>


                <p> Se <m>\vec{u}_1, \vec{u}_2</m> formam uma base para um espaço vetorial, podemos escrever cada vetor desse espaço como combinação linear dos vetores da base de uma única forma. O código a seguir plota uma base {u1, u2}, um vetor v, faz um print das coordenadas de v nessa base e ilustra o produto das coordenadas com os respectivos vetores da base (cuja soma resulta em v).</p>
                <sage>
                    <input>
                        import matplotlib.pyplot as plt
                        import numpy as np

                        zero = np.zeros(2)

                        # vector v
                        v= np.array([2, -3])

                        # basis
                        u1 = np.array([1,2])
                        u2 = np.array([-2, 1])


                        # finding the constants
                        vU = np.linalg.inv(np.transpose(np.vstack((u1,u2)))).dot(v)
                        print('coordenada de v na direção de u1')
                        print('vU1 = ', vU[0])
                        print('coordenada de v na direção de u2')
                        print('vU2 = ', vU[1])

                        #plotting the vectors
                        fig, ax = plt.subplots(figsize=(5, 5))     
                        plt.grid()

                        head_width =0.3
                        head_length = 1.5*head_width

                        def cor(x):
                            x_new = x[0]/(head_length+np.sqrt(x[0]^2+x[1]^2))*np.sqrt(x[0]^2+x[1]^2)
                            y_new = x[1]/(head_length+np.sqrt(x[0]^2+x[1]^2))*np.sqrt(x[0]^2+x[1]^2)
                            return np.array([x_new,y_new])

                        plt.arrow(0,0,cor(u1)[0], cor(u1)[1], head_width =head_width)
                        plt.annotate('u1', cor(u1)/2 + np.array([0.2,-0.2]))

                        plt.arrow(0,0,cor(vU[0]*u1)[0], cor(vU[0]*u1)[1], head_width =head_width, alpha =0.5)
                        plt.annotate('vU1u1', cor(vU[0]*u1)/2, alpha =0.8)

                        plt.arrow(0,0,cor(u2)[0], cor(u2)[1], head_width =head_width, color = 'blue')
                        plt.annotate('u2', cor(u2)/2 + np.array([-0.2,-0.3]))

                        plt.arrow(0,0,cor(vU[1]*u2)[0], cor(vU[1]*u2)[1], head_width =head_width, alpha =0.5, color = 'blue')
                        plt.annotate('vU2u2', cor(vU[1]*u2)/2, alpha =0.8)

                        plt.arrow(0,0,cor(v)[0], cor(v)[1], head_width =head_width, color = 'green')
                        plt.annotate('v', cor(v)/2 + np.array([-0.3,-0.1]))

                        plt.show()
                    </input>
                    <output>
                        plot
                    </output>
                </sage>



                <example>
                    <statement>
                        Para verificarmos que <m>\vec{v}_1 = (1,-1,1)^T, \vec{v}_2 = (1,2,1)^T, \vec{v}_3 = (-1,0,1)^T</m> formam uma base para <m>\mathbb{R}^3</m>, precisamos verificar que:
                        <ol>
                            <li><p>
                                esses vetores são L.I. Para isso precisamos mostrar que a única solução de
                                <me>
                                    \alpha_1\vec{v}_1 + \alpha_2 \vec{v}_2 + \alpha_3 \vec{v}_3 = \alpha_1 \begin{pmatrix} 1\\ -1 \\ 1 \end{pmatrix} + \alpha_2 \begin{pmatrix} 1\\ 2 \\ 1 \end{pmatrix} + \alpha_3 \begin{pmatrix} -1\\ 0 \\ 1 \end{pmatrix} = \vec{0}
                                </me>
                                é 
                                <m>
                                    \alpha_1 = \alpha_2 = \alpha_3 =0,
                                </m>
                                para verificarmos isso, escrevemos o sistema acima na forma matricial
                                <me>
                                    \left(\begin{array}{ccc} 1 \amp 1 \amp -1 \\ -1 \amp 2 \amp 0 \\ 1 \amp 1 \amp 1 \end{array}\right)\begin{pmatrix} \alpha_1 \\ \alpha_2 \\ \alpha_3 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}
                                </me>
                                e verificamos que esse sistema admite solução única pois a matriz 
                                <me>
                                    A = \left(\begin{array}{ccc} 1 \amp 1 \amp -1 \\ -1 \amp 2 \amp 0 \\ 1 \amp 1 \amp 1 \end{array}\right)
                                </me>
                                tem determinante <m>\det(A) = 6 \neq 0</m> e é, portanto inversível.
                            </p></li>
                            <li><p>
                                esses vetores geram <m>\mathbb{R}^3</m>. Para isso precisamos mostrar que qualquer vetor <m>\vec{x} = (x, y, z)^T \in \mathbb{R}^3</m> pode ser escrito como uma combinação linear de <m>\vec{v}_1, \vec{v}_2, \vec{v}_3</m>, o que ocorre de fato pois, escrevendo o sistema acima na forma matricial
                                <me>
                                    \left(\begin{array}{ccc} 1 \amp 1 \amp -1 \\ -1 \amp 2 \amp 0 \\ 1 \amp 1 \amp 1 \end{array}\right)\begin{pmatrix} \alpha_1 \\ \alpha_2 \\ \alpha_3 \end{pmatrix} = \begin{pmatrix} x\\ y \\ z \end{pmatrix},
                                </me>
                                verificamos que esse sistema admite solução (<m>\vec{\alpha} = A^{-1} \vec{x}</m>) para qualquer <m>\vec{x} \in \mathbb{R}^3</m>,  pois a matriz 
                                <me>
                                    A = \left(\begin{array}{ccc} 1 \amp 1 \amp -1 \\ -1 \amp 2 \amp 0 \\ 1 \amp 1 \amp 1 \end{array}\right)
                                </me>
                                é tem determinante <m>\det(A) = 6 \neq 0</m> e é, portanto inversível.
                            </p></li>
                        </ol>
                        De modo que <m>\{\vec{v}_1,\vec{v}_2,\vec{v}_3\}</m> é uma base para <m>\mathbb{R}^3</m>.
                    </statement>
                </example>



                <example>
                    <statement>
                        Para verificarmos que <m>\vec{v}_1 = (\sqrt{2}/2,-\sqrt{2}/2,0)^T, \vec{v}_2 = (\sqrt{3}/3,\sqrt{3}/3,\sqrt{3}/3)^T, \vec{v}_3 = (\sqrt{6}/6,\sqrt{6}/6,-2\sqrt{6}/6)</m> formam uma base para <m>\mathbb{R}^3</m>, observamos que a matriz
                        <me>
                            A = \left(\begin{array}{ccc} | \amp | \amp | \\ \vec{v}_1 \amp \vec{v}_2 \amp \vec{v}_3 \\ | \amp | \amp | \end{array}\right) = \left(\begin{array}{ccc} \sqrt{2}/2 \amp \sqrt{3}/3 \amp \sqrt{6}/6 \\ -\sqrt{2}/2 \amp \sqrt{3}/3 \amp \sqrt{6}/6 \\ 0 \amp \sqrt{3}/3 \amp -2\sqrt{6}/6 \end{array}\right)
                        </me>
                        tem determinante <m>\det(A) = 1</m> e portanto é inversível, de modo que o sistema <m>A\vec{\alpha} = \vec{x}</m> tem solução <m>\alpha = A^{-1} \vec{x}</m> para qualquer <m>\vec{x} \in \mathbb{R}^3</m> e <m>\{\vec{v}_1,\vec{v}_2,\vec{v}_3\}</m> geram <m>\mathbb{R}^3</m>, além disso, a solução é única para qualquer <m>\vec{x} \in \mathbb{R}^3</m>, em particular para <m>\vec{x} = \vec{0}</m>, de modo que os vetores são L.I. Dessa forma, <m>\{\vec{v}_1,\vec{v}_2,\vec{v}_3\}</m> formam uma base para <m>\mathbb{R}^3</m>.
                    </statement>
                </example>



                <exercise>
                    <statement>
                        Verifique que a base do sistema anterior é formada por vetores unitários e ortogonais entre si.
                    </statement>
                </exercise>


                <exercise>
                    <statement>
                        Utilize o código acima para explorar o que ocorre quando os vetores <m>\vec{u}_1, \vec{u}_2</m> formam um ângulo pequeno entre si.
                    </statement>
                </exercise>


                <p>
                    Temos então que é possível encontrar muitas (na verdade infinitas) bases para um espaço vetorial <m>V</m>. Os dois teoremas a seguir garantem que duas bases para um espaço vetorial têm sempre o mesmo número de vetores.
                </p>


                <theorem xml:id = "vetores_demais">
                    <!-- <title>Optional</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    <p>
                      Se <m>\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n</m> geram um espaço vtorial <m>V</m>, então qualquer coleção de <m>m \gt n</m> vetores de <m>V</m>é L.D.
                    </p>
                  </statement>
                
                  <proof>
                    Sejam <m>\vec{u}_1, \vec{u}_2, \ldots, \vec{u}_m \in V</m> vetores. Cada um desses vetores pode ser escrito como combinação linear de <m>\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n</m>, pois estes geram <m>V</m>. Assim, para cada <m>i =1, \ldots, m</m>, existem escalares <m>a_{i1}, a_{i2}, \ldots, a_{in}</m> tais que
                    <me>
                        \vec{u}_i = a_{1i}\vec{v}_1+ a_{2i}\vec{v}_2+ \ldots + a_{ni} \vec{v}_n.
                    </me>
                    Assim, encontrar constantes  <m>\alpha_1, \ldots, \alpha_m</m> tais que <m>\alpha_1\vec{u}_1 + \alpha_2\vec{u}_2 + \cdots \alpha_m\vec{u}_m</m> é o mesmo que resolver o sistema
                    <md>
                        <mrow> \vec{0} =\amp\alpha_1( a_{11}\vec{v}_1+ a_{21}\vec{v}_2+ \ldots + a_{n1} \vec{v}_n) + \alpha_2(a_{12}\vec{v}_1+ a_{22}\vec{v}_2+ \ldots + a_{n2} \vec{v}_n) + \cdots </mrow>
                        <mrow> \amp + \alpha_m(a_{1m}\vec{v}_1+ a_{2m}\vec{v}_2+ \ldots + a_{nm} \vec{v}_n) </mrow>
                        <mrow> =\amp (\alpha_1 a_{11} + \alpha_2 a_{12} + \cdots + \alpha_m a_{1m})\vec{v}_1+ (\alpha_1 a_{21} + \alpha_2 a_{22} + \cdots + \alpha_m a_{2m})\vec{v}_2+ \ldots </mrow>
                        <mrow> \amp + (\alpha_1 a_{n1} + \alpha_2 a_{n2} + \cdots + \alpha_m a_{nm}) \vec{v}_n </mrow>                        
                    </md>
                    e uma solução dessa equação é tomar cada coeficiente dos vetores <m>\vec{v}_i</m> iguais a zero, de modo que para mostrarmos que <m>\vec{u}_1, \vec{u}_2, \ldots, \vec{u}_m</m> é L.D., basta mostrar que o sistema
                    <md>
                        <mrow> \alpha_1 a_{11} + \alpha_2 a_{12} + \cdots + \alpha_m a_{1m} = \amp 0 </mrow>
                        <mrow> \alpha_1 a_{21} + \alpha_2 a_{22} + \cdots + \alpha_m a_{2m} = \amp 0 </mrow>                        
                        <mrow> \vdots \,\,\,\,\,\,\, =\amp \,\,\vdots </mrow>
                        <mrow> \alpha_1 a_{n1} + \alpha_2 a_{n2} + \cdots + \alpha_m a_{nm} = \amp 0 </mrow>                        
                    </md>
                    admite múltiplas soluções, o que ocorre pois o sistema é homogêneo (portanto sempre tem solução) e tem mais variáveis do que equações (portanto admite infinitas soluções).
                    </proof>
                </theorem>


                <theorem>
                    <!-- <title>Optional</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    <p>
                      Se <m>\{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n\}</m> é uma base para um espaço vetorial <m>V</m>, então qualquer coleção de <m>k \lt n</m> vetores de <m>V</m> não gera <m>V</m>.
                    </p>
                  </statement>
                
                  <proof>
                    A completar.
                    </proof>
                </theorem>

                <p>Os teoremas acima garantem que se uma base para um espaço vetorial <m>V</m> tem <m>n</m> vetores, então qualquer outra base para <m>V</m> também tem <m>n</m> vetores. Assim, existe um número "certo" de vetores para cada base, o que nos motiva a definir a dimensão de um espaço vetorial.</p>

                <definition>
                    <notation>
                    <usage><m>n</m></usage>
                    <description>dimensão</description>
                    </notation>
                
                    <statement>
                    <p>
                        Seja <m>(V, E, \oplus, \odot)</m> um espaço vetorial. Se <m>V</m> tem uma base de <m>n</m> vetores, dizemos que <m>V</m> tem <term>dimensão</term> <m>n</m>. O (sub)espaço  <m>\{\vec{0}\}</m> é dito ter dimensão <term>nula</term> ou <m>0</m>. Em ambos os casos dizemos que <m>V</m> tem <term>dimensão finita</term>. Caso não exista um conjunto de vetores que cobre <m>V</m> com um número finito de elementos, dizemos que <m>V</m> tem <term>dimensão infinita</term>.
                    </p>
                    </statement>
                </definition>


                <exercise>
                    <statement>
                        Determine  uma base para os seguintes conjuntos e determine suas dimensões 
                        <ol marker="A">
                            <li>
                                O conjunto das matrizes reais <m>3 \times 3</m> triangulares inferiores.
                            </li>
                            <li>
                                O conjunto dos polinômios de grau 4 (ou seja, polinômios da forma <m>p(x) = ax^4 + bx^3 + cx^2 + dx + e</m>).
                            </li>
                            <li>
                                O espaço nulo da matriz
                                <me>
                                    A = \left(\begin{array}{ccc} 5 \amp 1 \amp  2\\
                                    1 \amp  5 \amp -2\\
                                    2 \amp -2 \amp  2 \end{array} \right).
                                </me>
                            </li>
                        </ol>
                    </statement>
                </exercise>

                <exercise>
                    <statement>
                        Encontre outras<fn>diferentes das apresentadas na solução do exercício anterior</fn> bases para os espaços do exercício anterior.
                    </statement>
                </exercise>

                <p> Se sabemos que um espaço vetorial tem dimensão <m>n</m> e quisermos verificar se um conjunto de <m>n</m> vetores é uma base, basta verificarmos uma das condições (que eles são L.I. ou que geram <m>V</m>), como garante o teorema a seguir.</p>


                <theorem>
                    <!-- <title>Optional</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    <p>
                      Se <m>V</m> é um espaço vetorial de dimensão <m>n \gt 0</m>, então:
                      <ol marker = "i">
                        <li> <p>qualquer conjunto <m>\{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n\}</m>de <m>n</m> vetores linearmente independentes gera <m>V</m>,</p></li>
                        <li> <p>quaisquer <m>n</m> vetores que cobrem <m>V</m> são linearmente independentes</p></li>
                      </ol>
                    </p>
                  </statement>
                
                  <proof>
                    <ol marker = "i">
                        <li> <p>Se <m>V</m> tem dimensão <m>n</m>, então <m>V</m> admite uma base com <m> n</m> vetores (não necessariamente <m>\{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n\}</m>). Então o <xref ref="vetores_demais"></xref> diz que, para qualquer vetor <m>\vec{v} \neq \vec{0} \in V</m>, o conjunto <m>\{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n, \vec{v}\}</m> é L.D. Portanto a equação
                        <me>
                            \alpha_1\vec{v}_1 + \alpha_2\vec{v}_2 + \cdots + \alpha_n \vec{v}_n + \alpha_{n+1} \vec{v} = \vec{0}
                        </me>
                        admite solução não nula. Nessa solução <m>\alpha_{n+1} \neq 0</m>, pois, caso contrário, o  conjunto <m>\{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n\}</m> seria L.D. Portanto
                        <me>
                            \vec{v} = -\alpha_1/\alpha_{i+1}\vec{v}_1 - \alpha_2/\alpha_{i+1}\vec{v}_2 - \cdots - \alpha_n/\alpha_{i+1} \vec{v}_n
                        </me>
                        e <m>\{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n\}</m> gera <m>V</m>.
                        </p></li>
                        <li> <p>Seja <m>\{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n, \vec{v}\}</m> um conjunto de vetores que gera <m>V</m>. Se este conjunto é L.D., então um dos vetores pode ser escrito como combinação dos demais. Sem perda de generalidade, digamos que seja <m>\vec{v}_n</m>:
                        <me>
                            \vec{v}_n = \alpha_1\vec{v}_1 + \alpha_2\vec{v}_2 + \cdots + \alpha_{n-1} \vec{v}_{n-1},
                        </me>
                        então <m>\{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_{n-1}\}</m> também gera <m>V</m>, pois qualquer vetor <m>\vec{v} \in V</m> pode ser escrito como
                        <md>
                            <mrow> \vec{v} =\amp v_1\vec{v}_1 + v_2\vec{v}_2 + \cdots + v_{n-1} \vec{v}_{n-1} + v_{n} \vec{v}_{n} </mrow>
                            <mrow> =(\amp v_1+v_n\alpha_1)\vec{v}_1 + (v_2+v_n\alpha_2)\vec{v}_2 + \cdots + (v_{n-1}+v_n\alpha_{n-1}) \vec{v}_{n-1}. </mrow>
                        </md>
                        Assim <m>\{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_{n-1}\}</m> é um conjunto de geradores para <m>V</m> e o <xref ref="vetores_demais"></xref> implica que qualquer conjunto com <m>n</m> vetores é L.D. e <m>V</m> não tem base com <m>n</m> vetores, o que contradiz <m>V</m> ter dimensão <m>n</m>.
                        </p> </li>
                      </ol>
                  </proof>
                </theorem>


            </subsection>



            <!--  *********************************************************
            *************************************************************** -->
                

            <subsection xml:id="mudanca_base">
                <title>Mudança de base</title>


                <p>
                    Temos a situação que existem muitas (infinitas) bases para cada espaço vetorial. Precisamos então ter uma maneira de passar vetores de uma base para outra.
                </p>

                <definition>
                    <notation>
                    <usage><m>\vec{v}^\mathcal{U} = (v_1^\mathcal{U}, v_2^\mathcal{U}, \ldots, v_n^\mathcal{U})^T</m></usage>
                    <description>coordenadas na base <m>\mathcal{U}</m></description>
                    </notation>
                
                    <statement>
                    <p>
                        Seja <m>(V,E,\oplus, \odot)</m> um espaço vetorial e <m>\mathcal{U} = \{\vec{u}_1, \vec{u}_2, \ldots, \vec{u}_n\}</m> uma base para <m>V</m>. A <m>n</m>-upla de escalares <m>(v_1^\mathcal{U}, v_2^\mathcal{U}, \ldots, v_n^\mathcal{U})</m> tal que
                        <me>
                            \vec{v} = v_1^\mathcal{U}\vec{u}_1 + v_2^\mathcal{U}\vec{u}_2 + \ldots + v_n^\mathcal{U} \vec{u}_n
                        </me>
                        é chamada de (conjunto de) <term>coordenadas de</term> <m>\vec{v}</m> na base <m>\mathcal{U}</m> e escrevemos
                        <me>
                            \vec{v}^\mathcal{U} = (v_1^\mathcal{U}, v_2^\mathcal{U}, \ldots, v_n^\mathcal{U})^T.
                        </me>
                        Normalmente omitimos a referência à base sobrescrita quando nos referimos à base canônica.
                    </p>
                    </statement>
                </definition>

                <remark>
                    As coordenadas de um vetor em uma base são únicas, pois, caso existissem mais de um conjunto de coordenadas correspondente a um único vetor, obteríamos uma contradição com a independencia linear dos vetores da base. Deixamos a verificação disso ao leitor.
                </remark>

                <example xml:id = "base_u_canon">
                    <statement>
                        Considere a base <m>\mathcal{U} = \{ \vec{u}_1, \vec{u}_2, \vec{u}_3 \} = \{(1,-1,1)^T, (0,1,1)^T, (2,1,-1)^T \}</m> para <m>\mathbb{R}^3</m> (note que as coordenadas mostradas para os vetores da base <m>U</m> são as representações dos vetores na base canônica). O vetor <m>\vec{v}^\mathcal{U} = (3, 4, -7)^T</m> é, na base canônica,
                        <me>
                            \vec{v} = 3\begin{pmatrix} 1 \\ -1 \\ 1 \end{pmatrix} + 4\begin{pmatrix} 0 \\ 1 \\ 1 \end{pmatrix} -7 \begin{pmatrix} 2 \\ 1 \\ -1 \end{pmatrix} = \begin{pmatrix} -11 \\ -6 \\ 14 \end{pmatrix}
                        </me>
                        note que o cálculo realizado acima pode ser escrito como um produto matricial <m>U \vec{v}^\mathcal{U}</m>
                        <me>
                            \vec{v} = \begin{pmatrix} 1 \amp  0 \amp 2 \\ -1 \amp 1 \amp 1 \\ 1 \amp 1 \amp -1 \end{pmatrix} \begin{pmatrix} 3 \\ 4 \\ -7 \end{pmatrix} = \begin{pmatrix} | \amp  | \amp | \\ \vec{u}_1 \amp \vec{u}_2 \amp \vec{u}_3 \\ | \amp | \amp | \end{pmatrix} \vec{v}^\mathcal{U}.
                        </me>
                        A matrix
                        <me>
                            U = \begin{pmatrix} 1 \amp  0 \amp 2 \\ -1 \amp 1 \amp 1 \\ 1 \amp 1 \amp -1 \end{pmatrix}
                        </me>
                        é a <term>matriz de mudança de base</term> da base <m>U</m> para a base canônica.
                    </statement>
                </example>


                <example xml:id = "base_canon_u">
                    <statement>
                        Considere a base <m>U = \{ \vec{u}_1, \vec{u}_2, \vec{u}_3 \} = \{(1,-1,1)^T, (0,1,1)^T, (2,1,-1)^T \}</m> para <m>\mathbb{R}^3</m> e o vetor <m>\vec{v} = (1, -1, 3)^T</m> (na base canônica). As coordenadas de <m>\vec{v}</m> na base <m>U</m> são encontradas resolvendo o sistema
                        <me>
                            \begin{pmatrix} 1 \\ -1 \\ 3 \end{pmatrix} = v^\mathcal{U}_1\begin{pmatrix} 1 \\ -1 \\ 1 \end{pmatrix} + v^\mathcal{U}_2\begin{pmatrix} 0 \\ 1 \\ 1 \end{pmatrix} + v^\mathcal{U}_3 \begin{pmatrix} 2\\ 1 \\ -1 \end{pmatrix}= \begin{pmatrix} 1 \amp  0 \amp 2 \\ -1 \amp 1 \amp 1 \\ 1 \amp 1 \amp -1 \end{pmatrix} \begin{pmatrix} v^\mathcal{U}_1 \\ v^\mathcal{U}_2 \\ v^\mathcal{U}_3 \end{pmatrix}.
                        </me>
                        Dessa forma
                        <md>
                            <mrow>
                                \vec{v}^\mathcal{U}  =\amp \begin{pmatrix} | \amp  | \amp | \\ \vec{u}_1 \amp \vec{u}_2 \amp \vec{u}_3 \\ | \amp | \amp | \end{pmatrix}^{-1} \vec{v} = \begin{pmatrix} 1 \amp  0 \amp 2 \\ -1 \amp 1 \amp 1 \\ 1 \amp 1 \amp -1 \end{pmatrix}^{-1} \begin{pmatrix} 1 \\ -1 \\ 3 \end{pmatrix}
                            </mrow>
                            <mrow>
                                =\amp \begin{pmatrix} 1/3 \amp  -1/3 \amp 1/3 \\ 0 \amp 1/2 \amp 1/2 \\ 1/3 \amp 1/6 \amp -1/6 \end{pmatrix} \begin{pmatrix} 1 \\ -1 \\ 3 \end{pmatrix} = \begin{pmatrix} 5/3 \\ 1 \\ -1/3 \end{pmatrix}.
                            </mrow>
                        </md>
                        A matrix
                        <me>
                            U^{-1} = \begin{pmatrix} | \amp  | \amp | \\ \vec{u}_1 \amp \vec{u}_2 \amp \vec{u}_3 \\ | \amp | \amp | \end{pmatrix}^{-1} = \begin{pmatrix} 1/3 \amp  -1/3 \amp 1/3 \\ 0 \amp 1/2 \amp 1/2 \\ 1/3 \amp 1/6 \amp -1/6 \end{pmatrix}
                        </me>
                        é a <term>matriz de mudança de base</term> da base canônica para a base <m>\mathcal{U}</m>.
                    </statement>
                </example>


                <p>O exemplo a seguir complementa os anteriores.</p>

                <example xml:id = "base_canoninca_na_u">
                    <statement>
                        Considere a base <m>\mathcal{U} = \{ \vec{u}_1, \vec{u}_2, \vec{u}_3 \} = \{(1,-1,1)^T, (0,1,1)^T, (2,1,-1)^T \}</m> para <m>\mathbb{R}^3</m> e os vetores <m>\vec{e}_1, \vec{e}_2, \vec{e}_3</m> da base canônica. As coordenadas de <m>\vec{e}_1, \vec{e}_2, \vec{e}_3</m> são
                        <md>
                            <mrow>
                                \vec{e}_1^\mathcal{U}  =\amp \begin{pmatrix} | \amp  | \amp | \\ \vec{u}_1 \amp \vec{u}_2 \amp \vec{u}_3 \\ | \amp | \amp | \end{pmatrix}^{-1} \vec{e}_1 = \begin{pmatrix} 1/3 \amp  -1/3 \amp 1/3 \\ 0 \amp 1/2 \amp 1/2 \\ 1/3 \amp 1/6 \amp -1/6 \end{pmatrix} \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix} = \begin{pmatrix} 1/3 \\ 0 \\ 1/3 \end{pmatrix},
                            </mrow>
                            <mrow>
                                \vec{e}_2^\mathcal{U}  =\amp \begin{pmatrix} | \amp  | \amp | \\ \vec{u}_1 \amp \vec{u}_2 \amp \vec{u}_3 \\ | \amp | \amp | \end{pmatrix}^{-1} \vec{e}_2 = \begin{pmatrix} 1/3 \amp  -1/3 \amp 1/3 \\ 0 \amp 1/2 \amp 1/2 \\ 1/3 \amp 1/6 \amp -1/6 \end{pmatrix} \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix} = \begin{pmatrix} -1/3 \\ 1/2 \\ 1/6 \end{pmatrix},
                            </mrow>
                            <mrow>
                                \vec{e}_3^\mathcal{U}  =\amp \begin{pmatrix} | \amp  | \amp | \\ \vec{u}_1 \amp \vec{u}_2 \amp \vec{u}_3 \\ | \amp | \amp | \end{pmatrix}^{-1} \vec{e}_3 = \begin{pmatrix} 1/3 \amp  -1/3 \amp 1/3 \\ 0 \amp 1/2 \amp 1/2 \\ 1/3 \amp 1/6 \amp -1/6 \end{pmatrix} \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} = \begin{pmatrix} 1/3 \\ 1/2 \\ -1/6 \end{pmatrix}.
                            </mrow>
                        </md>
                        Note que as colunas da matriz <m>U^{-1}</m> são as coordenadas dos vetores <m>\vec{e}_1, \vec{e}_2, \vec{e}_3</m> na base <m>\mathcal{U}</m>.
                    </statement>
                </example>


                <definition>
                    <notation>
                    <usage><m>A</m></usage>
                    <description>matriz de mudança de base</description>
                    </notation>
                
                    <statement>
                    <p>
                        Sejam <m>(V,E,\oplus, \odot)</m> um espaço vetorial e <m>\mathcal{U}= \{\vec{u}_1, \vec{u}_2, \ldots, \vec{u}_n\}</m> e <m>\mathcal{V}= \{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n\}</m> bases para <m>V</m>. Cada vetor da base <m>\mathcal{U}</m> tem coordenadas na base <m>\mathcal{V}</m>, <m>\vec{u}_i^\mathcal{V} = (a_{1i}, a_{2i}, \ldots, a_{ni})^T</m>. A <term>matriz de mudança de base</term> da base <m>\mathcal{U}</m> para a base <m>\mathcal{V}</m> é a matriz
                        <me>
                            A = \begin{pmatrix} | \amp  | \amp  \amp | \\ \vec{u}_1^\mathcal{V} \amp \vec{u}_2^\mathcal{V} \amp \cdots \amp \vec{u}_n^\mathcal{V} \\ | \amp | \amp  \amp | \end{pmatrix} = \begin{pmatrix} a_{11} \amp  a_{12} \amp \cdots \amp a_{1n} \\ a_{21} \amp a_{22} \amp \cdots \amp a_{2n} \\ \vdots \amp \vdots \amp \ddots \amp \vdots \\ a_{n1} \amp a_{n2} \amp \cdots \amp a_{nn} \end{pmatrix}.
                        </me>
                    </p>
                    </statement>
                </definition>

                <exercise>
                    <statement>
                        Sejam <m>(V,E,\oplus, \odot)</m> um espaço vetorial e <m>\mathcal{U}= \{\vec{u}_1, \vec{u}_2, \ldots, \vec{u}_n\}</m> uma base para <m>V</m>. Quais as coordenadas de <m>\vec{u}_i</m> na base <m>\mathcal{U}</m>. 
                    </statement>
                </exercise>

                <remark>
                    Sejam <m>\mathcal{U}= \{\vec{u}_1, \vec{u}_2, \ldots, \vec{u}_n\}</m> e <m>\mathcal{V}= \{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n\}</m> bases para <m>\mathbb{R}^n</m>. Se um vetor <m>\vec{v}</m> tem coordenadas <m>\vec{v}^U</m> e <m>\vec{v}^V</m> nas bases <m>U</m> e <m>V</m> nas respectivas bases e <m>U</m> e <m>V</m> são as matrizes de mudança de base das bases <m>\mathcal{U}</m> e <m>\mathcal{V}</m> para a base canônica, temos que
                    <me>
                        U\vec{v}^U = \vec{v} = V\vec{v}^V,
                    </me>
                    de modo que
                    <me>
                        \vec{v}^V = V^{-1}U\vec{v}^U,
                    </me>
                    ou seja, a matriz de mudança de base da base <m>\mathcal{U}</m> para a base <m>\mathcal{V}</m> é <m>V^{-1}U</m>.
                </remark>

                <sage>
                    <caption>RNA Codons Table, by Florian Hollandt</caption>
                    <input>
                        import matplotlib.pyplot as plt
                        import numpy as np

                        fig, ax = plt.subplots()
                        plt.xlim( (-4.1, 1) )  # set the xlim to xmin, xmax
                        plt.ylim((-0.1,2.5))    # set the xlim to xmin, xmax

                        fig.patch.set_visible(False)
                        ax.axis('off')


                        plt.annotate('U', [-0.1,0.1], fontsize=20, style= 'italic' )
                        plt.arrow(0,0.3,0,1.7, head_width =0.1)
                        plt.annotate('E', [-0.1,2.2], fontsize=20, style= 'italic' )
                        plt.arrow(-0.2,2.3,-3.5,0, head_width =0.1)
                        plt.annotate('V', [-4.1,2.2], fontsize=20, style= 'italic' )
                        plt.arrow(-0.2,0.3,-3.5,1.8, head_width =0.1)

                        plt.annotate('U', [0.1,1.2], fontsize=20)
                        plt.annotate('V', [-2,2.4], fontsize=20)
                        plt.annotate('-1', [-1.8,2.5], fontsize=10)

                        plt.annotate('V', [-2.9,1.2], fontsize=20)
                        plt.annotate('-1', [-2.7,1.3], fontsize=10)
                        plt.annotate('U', [-2.55,1.2], fontsize=20)


                        plt.show()
                    </input>
                    <output>
                        image
                    </output>
                </sage>

                <remark>
                    A matriz de mudança de base sempre é inversível, pois, caso não fosse, o sistema <m>A\vec{x}=\vec{0}</m> admitiria soluções não nulas, de modo que
                    <me>
                        \vec{0} = A\vec{x} = x_1 \vec{u}_1^\mathcal{V} + x_2 \vec{u}_2^\mathcal{V} + \cdots + x_n \vec{u}_n^\mathcal{V}, 
                    </me>
                    (a completar).
                </remark>


                <remark>
                    Sejam <m>(V,E,\oplus, \odot)</m> um espaço vetorial e <m>\mathcal{U}= \{\vec{u}_1, \vec{u}_2, \ldots, \vec{u}_n\}</m> <m>\mathcal{V}= \{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n\}</m> bases para <m>V</m> e A = <m>(a_{ij})</m> a matriz de mudança de base da base <m>\mathcal{U}</m> para a base <m>\mathcal{V}</m>, de modo que <m>\vec{u}_i^{\mathcal{V}} = a_{1i}\vec{v}_1 + a_{2i} \vec{v}_2 + \cdots + a_{ni} \vec{v}_n</m>
                </remark>


                <exercise>
                    <statement>
                        Encontre as matrizes de mudança de base da base <m>\mathcal{U}</m> para a base <m>\mathcal{V}</m> para as de <m>\mathbb{R}^n</m>bases a seguir:
                        <ol>
                            <li><m>\mathcal{U} = \{(1,-1)^T, (3,-2)^T\}</m>, <m>\mathcal{V} = \mathcal{E} =\{(5,2)^T, (-1,3)^T \}</m></li>
                            <li><m>\mathcal{U} = \{(1,-1,1)^T, (1,-2,1)^T, (2,-1,-1)^T \}</m>, <m>\mathcal{V} = \mathcal{E} =\{\vec{i},\vec{j},\vec{k} \}</m></li>
                            <li><m>\mathcal{U} = \mathcal{E} =\{\vec{i},\vec{j},\vec{k} \}</m>, <m>\mathcal{V} = \{(1,-1,1)^T, (1,-2,1)^T, (2,-1,-1)^T \}</m></li>
                            <li><m>\mathcal{U} = \{(1,-1,1)^T, (1,-2,1)^T, (2,-1,-1)^T \}</m>, <m>\mathcal{V} = \mathcal{E} =\{\vec{i},\vec{j},\vec{k} \}</m></li>
                            <li><m>\mathcal{U} = \{(1,-1,1, -1)^T, (1,1,-1, -1)^T, (0,1,1, 0)^T, (1,0,0, 1)^T \}</m>, <m>\mathcal{V} = \{(-1,1,1, 1)^T, (1,1,1, -1)^T, (0,1,-1, 0)^T, (1,0,0, 1)^T \}</m></li>
                        </ol> 
                    </statement>
                </exercise>

                <p>utilize o código a seguir para verificar as respostas obtidas no exercício anterior.</p>


                <sage>
                    <input>
                        # Python program to calculate the base change matrix using numpy
                        
                        # Import required package
                        import numpy as np
                        import fractions #for fractions (comment the line below, for decimals)
                        np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
                        
                        # Base change matrix of U to E
                        U = np.array([[1, 1, -1],
                                    [1, -1, -1],
                                    [1, 0, 2]])

                        # Base change matrix of V to E
                        V = np.array([[0, 2, -1],
                                    [1, 1, 1],
                                    [-1, 1, 1]])
                        
                        # printing the base change matrix
                        print(np.linalg.inv(V).dot(U))
                    </input>
                    <output>
                        Base change matrix
                    </output>
                </sage>



            </subsection>


            <!--  *********************************************************
            *************************************************************** -->
                

            <subsection xml:id="esp_linha">
                <title>Espaço Linha e Espaço Coluna</title>


                <definition>
                    <notation>
                      <usage><m>V</m></usage>
                      <description>espaço vetorial</description>
                    </notation>
                  
                    <statement>
                        <p>
                            Seja <m>A</m> uma matriz <m>m \times n</m>. O subespaço de <m>\mathbb{R}^{1 \times n}</m> coberto pelos vetores linha de <m>A</m> é chamado de de <term>espaço linha</term> de <m>A</m>. O subespaço de <m>\mathbb{R}^m</m> coberto pelos vetores coluna de <m>A</m> é chamado de <term>espaço coluna</term> de <m>A</m>.
                        </p>
                    </statement>
                </definition>


                <example>
                    <statement>
                        Para a matriz
                        <me>
                            A = \begin{pmatrix} 1 \amp 0 \amp 0 \\
                            0 \amp 1 \amp 0\end{pmatrix}
                        </me>,
                        o espaço linha é formado pelas triplas da forma:
                        <me>
                            \alpha_1 (1, 0, 0) + \alpha_2 (0, 1, 0) = (\alpha_1, \alpha_2, 0)
                        </me>,
                        ou seja, é igual ao <m>Span((1, 0, 0),(0, 1, 0))</m>.

                        O espaço coluna é formado pelos vetores da forma:
                        <me>
                            \alpha_1 \begin{pmatrix} 1 \\ 0 \end{pmatrix} + \alpha_2 \begin{pmatrix} 0 \\ 1 \end{pmatrix} = \begin{pmatrix} \alpha_1 \\ \alpha_2 \end{pmatrix}
                        </me>,
                        ou seja, é igual ao <m>Span\left(\begin{pmatrix} 1 \\ 0 \end{pmatrix}, \begin{pmatrix} 0 \\ 1 \end{pmatrix} \right)</m>.
                    </statement>
                </example>


                <example>
                    <statement>
                        Para a matriz
                        <me>
                            A = \begin{pmatrix} 1 \amp 1 \amp 1 \amp 0\\
                            1 \amp 0 \amp -1 \amp 1\\
                            1 \amp 1 \amp 1 \amp 0\\
                            1 \amp 0 \amp -1 \amp 1\end{pmatrix}
                        </me>,
                        temos que há duas linhas que são iguais as outras duas e o espaço linha é formado pelas quadruplas da forma:
                        <me>
                            \alpha_1 (1, 1, 1, 0) + \alpha_2 (1, 0, -1, 1) = (\alpha_1 + \alpha_2, \alpha_1, \alpha_1 - \alpha_2, \alpha_@)
                        </me>,
                        ou seja, é igual ao <m>Span((1, 1, 1, 0),(1, 0, -1, 1))</m>.

                        Denotando <m>\vec{a}_1,\vec{a}_2,\vec{a}_3,\vec{a}_4</m> para as colunas de <m>A</m>, observamos que <m>\vec{a}_3 = -\vec{a}_1 + 2 \vec{a}_2</m> e <m>\vec{a}_4 = \vec{a}_1 - \vec{a}_2</m> e o espaço coluna é formado pelos vetores da forma:
                        <me>
                            \alpha_1 \begin{pmatrix} 1 \\ 1 \\ 1 \\ 1 \end{pmatrix} + \alpha_2 \begin{pmatrix} 1 \\ 0 \\ 1 \\ 0 \end{pmatrix} = \begin{pmatrix} \alpha_1 + \alpha_2 \\ \alpha_1 \\ \alpha_1 + \alpha_2 \\ \alpha_1 \end{pmatrix}
                        </me>,
                        ou seja, é igual ao <m>Span\left(\begin{pmatrix} 1 \\ 1 \\ 1 \\ 1 \end{pmatrix}, \begin{pmatrix} 1 \\ 0 \\ 1 \\ 0 \end{pmatrix} \right)</m>.
                    </statement>
                </example>

                <theorem>
                    <!-- <title>Optional</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    Duas matrizes equivalentes por linhas têm o mesmo espaço linha.
                  </statement>
                
                  <proof>
                    A completar.
                  </proof>
                </theorem>


                <definition>
                    <notation>
                      <usage><m>\mbox{rank}</m></usage>
                      <description>posto</description>
                    </notation>
                  
                    <statement>
                        <p>
                            O <term>posto</term> (<it>rank</it> em inglês) de uma matriz <m>A</m>, denotado <m>\mbox{posto}(A)</m> ou <m>\mbox{rank}(A)</m>, é a dimensão do espaço linha<fn>ou do espaço coluna, pois, ambas são iguais</fn> de <m>A</m>.
                        </p>
                    </statement>
                </definition>


                <remark>
                    O posto de uma matriz <m>A</m> é igual ao número de linhas não nulas na sua forma escalonada e as linhas não nulas da forma escalonada formam uma base para o espaço linha de <m>A</m>.
                </remark>

                <theorem>
                    <!-- <title>Optional</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    A dimensão do espaço linha de uma matriz <m>A^{m \times n}</m> é igual à dimensão do seu espaço coluna.
                  </statement>
                
                  <proof>
                    A completar.
                  </proof>
                </theorem>

                <remark>
                    As colunas da matriz <m>A</m> na forma escalonada <term>não formam uma base para o espaço coluna de</term> <m>A</m>, apesar de terem a mesma dimensão. Todavia os pivôs da matriz escalonada indicam as colunas que formam uma base para o espaço coluna de <m>A</m>.
                </remark>

                <remark>
                    O espaço linha de <m>A</m> é igual ao espaço coluna de <m>A^T</m> (se transpormos os vetores).
                </remark>

                <exercise>
                    <statement>
                        Determine o posto da matriz
                        <me>
                            A = \begin{pmatrix} 1 \amp 1 \amp 1 \amp 0 \amp 1\\
                            1 \amp 1 \amp -1 \amp 1 \amp 2\\
                            1 \amp 1 \amp 1 \amp 0 \amp -2\\
                            1 \amp 1 \amp -1 \amp 1 \amp 2\end{pmatrix}
                        </me>
                        e bases para seu espaço linha e espaço coluna.
                    </statement>
                </exercise>

                <exercise>
                    <statement>
                        Determine o posto da matriz
                        <me>
                            A = \begin{pmatrix} 1 \amp 1 \amp 1 \amp 0 \amp 1\\
                            1 \amp -1 \amp -1 \amp 1 \amp 2\\
                            1 \amp 1 \amp 1 \amp 2 \amp -2\\
                            1 \amp -1 \amp -1 \amp 1 \amp 2\end{pmatrix}
                        </me>
                        e bases para seu espaço linha e espaço coluna.
                    </statement>
                </exercise>


                <p>
                    O código abaixo permite colocar uma matriz na forma escalonada.
                </p> 

                <sage>
                    <input>
                        # Write an array representing the augmented matrix
                        import numpy as np
                        import fractions
                        A= np.array([[1.,1.,1.,0.,1],[1.,1.,-1.,1.,2],[1.,1.,1.,0.,-2.],[1.,1.,-1.,1.,2.]])


                        #Step by step Gaussian Elimination:

                        def Gaussian_elimination(A,prin=True):
                            a=0
                            if prin==True:
                                print('A='+str(A))
                            for j in range(A.shape[1]): #search pivot in each column
                                b=0
                                for i in range(a,A.shape[0]):
                                    if A[i,j] != 0: #choose row with not null pivot
                                        if a !=i:
                                            A[[a,i]]=A[[i,a]]
                                            if prin==True:
                                                print('~'+str(A))
                                        if A[a,j]!=1:
                                            A[a]=A[a]/A[a,j]
                                            if prin==True:
                                                print('~'+str(A))
                                        a=a+1
                                        b=1
                                        break
                                if b==1:
                                    for i in range(a,A.shape[0]):
                                        if A[i,j] != 0:
                                            A[i]=A[i]-A[a-1]*A[i,j]
                                        if prin==True:
                                            print('~'+str(A))
                            np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})
                            return A
                        Gaussian_elimination(A)
                    </input>
                    <output>
                        solution
                    </output>
                </sage>


                <remark>
                    Um sistema linear <m>A\vec{x} = \vec{b}</m> tem solução se, e somente se, <m>\vec{b}</m> está no espaço coluna de <m>A</m>.
                </remark>

                <definition>
                    <notation>
                      <usage><m>\mbox{nul}</m></usage>
                      <description>nulidade</description>
                    </notation>
                  
                    <statement>
                        <p>
                            A <term>nulidade</term> de uma matriz <m>A</m>, denotado <m>\mbox{nul}(A)</m>, é a dimensão do seu espaço nulo.
                        </p>
                    </statement>
                </definition>


                <theorem>
                    <title> do núcleo e da imagem</title>
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    Para qualquer matriz <m>A^{m \times n}</m> vale:
                    <me>
                        \mbox{posto} (A) + \mbox{nul}(A) = n.
                    </me>
                  </statement>
                
                  <proof>
                    A completar.
                  </proof>
                </theorem>






            </subsection>


        </section>


        <!--  *********************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        *************************************************************** -->                                                                                                    



        <section xml:id="produto_interno">
            <title>Produto interno e ortogonalidade em <m>\mathbb{R}^n</m>.</title>
           
            <intro>
               <p>
                Ao tomarmos uma base para um espaço vetorial, buscamos, com frequência, uma base formada por vetores ortogonais (perpendiculares) entre si ou temos apenas alguns vetores e desejamos adicionar outros vetores para "completar" a base. Nessa seção construíremos os conceitos e teoremas necessários para fazer isso em <m>\mathbb{R}^n</m>.
               </p>
           </intro>
           
            <subsection xml:id="inner_prod">
            
               <title>Produto Interno (ou escalar) em <m>\mathbb{R}^n</m></title>


               <definition>
                    <notation>
                    <usage><m>\langle \vec{x}, \vec{y} \rangle \,\, \mbox{ ou }\,\, \vec{x} \cdot \vec{y}  \,\, \mbox{ ou } \,\, \vec{x}^T\vec{y}</m></usage>
                    <description>produto interno</description>
                    </notation>
                
                    <statement>
                        <p>
                            Dados <m>\vec{x}, \vec{y} \in \mathbb{R}^n</m>, <m>\vec{x}=(x_1, x_2, \ldots, x_n)</m>, <m>\vec{y}=(y_1, y_2, \ldots, y_n)</m>, definimos o <term>produto interno</term> (ou <term>produto escalar</term>) de <m>\vec{x}</m> e <m>\vec{y}</m> como
                            <me>
                                \langle \vec{x}, \vec{y}\rangle = x_1y_1+x_2y_2 + \cdots +x_ny_n.
                            </me>
                            O produto interno também é denotado por <m>\vec{x} \cdot \vec{y}</m> ou <m>\vec{x}^T \vec{y}</m>.
                        </p>
                    </statement>
                </definition>


                <example>
                    <statement>
                        Dados <m>\vec{x} = (2, -1, 4)^T </m> e <m>\vec{y} = (3, 2, -1)^T </m>,
                        <me>
                            \langle \vec{x}, \vec{y}\rangle = 6 -2 -4 = 0
                        </me>.
                    </statement>
                </example>


                <example>
                    <statement>
                        Dados <m>\vec{x} = (3, -1, 2)^T </m> e <m>\vec{y} = (1, 2, 6)^T </m>,
                        <me>
                            \vec{x} \cdot \vec{y} = 3 -2 +12 = 13
                        </me>.
                    </statement>
                </example>


                <example>
                    <statement>
                        Dados <m>\vec{x} = (1, -1, 2)^T </m> e <m>\vec{y} = (-1, 3, 3)^T </m>,
                        <me>
                            \vec{x}^T\vec{y} = (1, -1, 2)\begin{pmatrix} -1\\ 3\\ 3\end{pmatrix} = -1-3+6 = 2
                        </me>.
                    </statement>
                </example>


                <theorem>
                    <title> Propriedades do produto interno</title>
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    Se <m>\vec{x}, \vec{y}, \vec{z} \in \mathbb{R}^n</m> e <m>\alpha</m> é um escalar, então
                    <ol>
                        <li><m>\vec{x} \cdot \vec{y} = \vec{y} \cdot \vec{x}</m></li>
                        <li><m>\alpha(\vec{x} \cdot \vec{y}) = (\alpha\vec{x}) \cdot \vec{y} = \vec{x} \cdot (\alpha\vec{y})</m>.</li>
                        <li><m>\vec{x} \cdot (\vec{y}+\vec{z}) = \vec{x} \cdot \vec{y} + \vec{x} \cdot \vec{z}</m></li>
                    </ol>
                  </statement>
                
                  <proof>
                    Exercício.
                  </proof>
                </theorem>



                <definition>
                    <notation>
                    <usage><m>\| \vec{x}\|</m></usage>
                    <description>comprimento</description>
                    </notation>
                
                    <statement>
                        <p>
                            O <term>comprimento (euclidiano)</term> (ou <term>norma</term>) de um vetor <m>\vec{x}\in \mathbb{R}^n</m> é 
                            <me>
                                \| \vec{x}\|  = \sqrt{\vec{x} \cdot \vec{x}} = \sqrt{x_1^2+x_2^2 + \cdots +x_n^2}.
                            </me>
                        </p>
                    </statement>
                </definition>


                <p>Em particular a distância entre os pontos finais de dois vetores <m>\vec{x} \mbox{ e } \vec{y} \in \mathbb{R}^n</m> é igual a <m>\|\vec{x} - \vec{y}\| = \|\vec{y} - \vec{x}\|</m>.</p>

                <example>
                    <statement>
                        Dados <m>\vec{x} = (3, 4)^T </m> e <m>\vec{y} = (-1, 7)^T </m>,
                        <me>
                            \|\vec{x} - \vec{y}\| = \sqrt{4^2+3^2} = \sqrt{25} = 5 
                        </me>.
                    </statement>
                </example>


                <sage>
                    <input>
                        import matplotlib.pyplot as plt
                        import numpy as np

                        zero = np.zeros(2)

                        x = np.array([3,4])
                        y = np.array([-1, 7])


                        #plotting the vectors
                        fig, ax = plt.subplots(figsize=(5, 5))     
                        ax.set_xlim(xmin=-3, xmax=7)
                        ax.set_ylim(ymin=-3, ymax=7)
                        ax.xaxis.set_ticks([-2,-1,0,1,2,3,4,5,6])
                        ax.yaxis.set_ticks([-2,-1,0,1,2,3,4,5,6])
                        plt.grid()

                        head_width =0.3
                        head_length = 1.5*head_width

                        def cor(x):
                            x_new = x[0]/(head_length+np.sqrt(x[0]^2+x[1]^2))*np.sqrt(x[0]^2+x[1]^2)
                            y_new = x[1]/(head_length+np.sqrt(x[0]^2+x[1]^2))*np.sqrt(x[0]^2+x[1]^2)
                            return np.array([x_new,y_new])

                        plt.arrow(0,0,cor(x)[0], cor(x)[1], head_width =head_width)
                        plt.annotate('x', cor(x)/2 + np.array([0.2,-0.2]))

                        plt.arrow(0,0,cor(y)[0], cor(y)[1], head_width =head_width, color = 'blue')
                        plt.annotate('y', cor(y)/2 + np.array([-0.2,-0.3]))

                        plt.arrow(x[0],x[1],-cor(y)[0], -cor(y)[1], head_width =head_width, color = 'red')
                        plt.annotate('-y', x/2+ cor(x-y)/2 + np.array([0.2,+0.1]))

                        plt.arrow(0,0,cor(x-y)[0], cor(x-y)[1], head_width =head_width, color = 'pink')
                        plt.annotate('x-y', cor(x-y)/2 + np.array([0.1,-0.1]))

                        plt.arrow(y[0], y[1],cor(x-y)[0], cor(x-y)[1], head_width =head_width, color = 'pink')
                        plt.annotate('x-y', cor(x-y)/2 + np.array([0.1,-0.1])+y)

                        plt.show()
                    </input>
                    <output>
                        plot
                    </output>
                </sage>


                <theorem>
                    <!-- <title> do núcleo e da imagem</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    Se <m>\vec{x}, \vec{y} \in \mathbb{R}^n</m>, <m> n =2\,\, \mbox{ ou }\,\, 3</m> são vetores não nulos e <m>\theta</m> é o ângulo entre eles, então
                    <me>
                        \vec{x}\cdot \vec{y} = \|\vec{x}\| \|\vec{y}\| \cos \theta.
                    </me>
                  </statement>
                
                  <proof>
                    Pela Lei dos cossenos
                    <me>
                        \|\vec{x} - \vec{y}\|^2 = \|\vec{x}\|^2 + \|\vec{y}\|^2 - 2\|\vec{x}\| \|\vec{y}\| \cos \theta.
                    </me>
                     Por outro lado,
                     <md>
                        <mrow>\|\vec{x} - \vec{y}\|^2 =\amp  \langle \vec{x} - \vec{y}, \vec{x} - \vec{y}\rangle</mrow>
                        <mrow>  =\amp  \langle \vec{x}, \vec{x} \rangle + \langle \vec{y}, \vec{y}\rangle  -\langle \vec{x}, \vec{y}\rangle -\langle \vec{y}, \vec{x}\rangle </mrow>
                        <mrow> =\amp \|\vec{x}\|^2 + \|\vec{y}\|^2 -2 \langle \vec{x}, \vec{y}\rangle.</mrow>
                     </md>
                     Como as expressões são iguais à <m>\|\vec{x} - \vec{y}\|^2</m>, elas são iguais entre si e
                     <md>
                        <mrow>\|\vec{x}\|^2 + \|\vec{y}\|^2 -\amp 2\|\vec{x}\| \|\vec{y}\| \cos \theta = \|\vec{x}\|^2 + \|\vec{y}\|^2 -2 \langle \vec{x}, \vec{y}\rangle</mrow>
                        <mrow>\amp  \Leftrightarrow \|\vec{x}\| \|\vec{y}\| \cos \theta = \langle \vec{x}, \vec{y}\rangle</mrow>
                     </md>
                  </proof>
                </theorem>



                <p>Podemos utilizar o teorema acima como um método para definir o ângulo entre dois vetores para <m>\mathbb{R}^n</m>, <m>n</m> qualquer.</p>

                <remark>
                    Se <m>\vec{x}, \vec{y} \in \mathbb{R}^n</m> são vetores não nulos, suas direções são os vetores unitários
                    <me>
                        \vec{u} = \frac{1}{\|\vec{x}\|}\vec{x}, \,\,\, \vec{v} = \frac{1}{\|\vec{y}\|}\vec{y},
                    </me>
                    e o ângulo entre eles é definido através de
                    <me>
                        \cos \theta = \frac{\vec{x}^T\vec{y}}{\|\vec{x}\| \|\vec{y}\|} = \vec{u}^T\vec{v} \Longrightarrow \theta = \mbox{arccos}\left( \frac{\vec{x}^T\vec{y}}{\|\vec{x}\| \|\vec{y}\|} \right).
                    </me>
                    Em  particular, dizemos que <m>\vec{x}</m> e <m>\vec{y}</m> são ortogonis se <m>\vec{x}^T\vec{y}=0</m>.
                </remark>


                <example>
                    <statement>
                        O ângulo entre os vetores
                        <me>
                            \vec{x} = \begin{pmatrix} -1\\ 3\\ 3\end{pmatrix}, \,\,\, \vec{y} = \begin{pmatrix} 2\\ -1\\ 2\end{pmatrix}
                        </me>
                        e seus vetores unitários é...
                    </statement>
                </example>



            </subsection>


        


            <!--  *********************************************************
            *************************************************************** -->
                

            <subsection xml:id="projecoes">
                <title>Projeções escalares e vetoriais</title>

                <p>
                    A projeção vetorial de um vetor <m>\vec{x} \neq \vec{0}</m> na direção do vetor <m>\vec{y} \neq \vec{0}</m> é um vetor <m>\vec{p}</m>, múltiplo de <m>\vec{y}</m> tal que <m>(\vec{x}-\vec{p}) \perp \vec{y}.</m>.   
                </p>

                <sage>
                    <input>
                        import matplotlib.pyplot as plt
                        import numpy as np

                        zero = np.zeros(2)

                        x = np.array([1.5,3])
                        y = np.array([3, 1])

                        alpha = x.dot(y)/np.linalg.norm(y)

                        p = alpha*y/np.linalg.norm(y)

                        z = x-p

                        #plotting the vectors
                        fig, ax = plt.subplots(figsize=(5, 5))     
                        ax.set_xlim(xmin=-3, xmax=5)
                        ax.set_ylim(ymin=-3, ymax=5)
                        ax.xaxis.set_ticks([-2,-1,0,1,2,3,4])
                        ax.yaxis.set_ticks([-2,-1,0,1,2,3,4])
                        plt.grid()

                        head_width =0.3
                        head_length = 1.5*head_width

                        def cor(x):
                            x_new = x[0]/(head_length+np.sqrt(x[0]^2+x[1]^2))*np.sqrt(x[0]^2+x[1]^2)
                            y_new = x[1]/(head_length+np.sqrt(x[0]^2+x[1]^2))*np.sqrt(x[0]^2+x[1]^2)
                            return np.array([x_new,y_new])

                        plt.arrow(0,0,cor(x)[0], cor(x)[1], head_width =head_width)
                        plt.annotate('x', cor(x)/2 + np.array([0.2,-0.2]))

                        plt.arrow(0,0,cor(y)[0], cor(y)[1], head_width =head_width, color = 'blue')
                        plt.annotate('y', cor(y)/1.1 + np.array([0.1,-0.2]))

                        plt.arrow(0,0,cor(p)[0], cor(p)[1], head_width =head_width, color = 'purple')
                        plt.annotate('p', cor(p)/2 + np.array([-0.,-0.2]))

                        plt.arrow(p[0],p[1],cor(z)[0], cor(z)[1], head_width =head_width, color = 'red')
                        plt.annotate('z', cor(z)/2 + p + np.array([-0.2,-0.3]))

                        plt.show()

                        print('alpha = ', alpha)
                        print('p = ', p)
                    </input>
                    <output>
                        plot
                    </output>
                </sage>

                <p>
                    Dados vetores <m>\vec{x}, \vec{y} \in \mathbb{R}^n</m>, queremos escrever
                    <me>
                        \vec{x} = \alpha \vec{u} +\vec{z}, \,\,\, \vec{u} = \frac{1}{\|\vec{y}\|}\vec{y}, \,\,\, \vec{p} = \alpha \vec{u},
                    </me>
                    com <m>\vec{z} \perp \vec{y}</m>. Ou seja, vamos decompor <m>\vec{x}</m> na soma de um vetor na direção de <m>\vec{y}</m> com um vetor perpendicular a <m>\vec{y}</m>.
                </p>


                <p>
                    Note que <m>\alpha = \| \vec{p} \| = \|\vec{x}\|\cos \theta </m>, mas <m>\cos \theta = \vec{x}^T\vec{y}/(\|\vec{x}\|\|\vec{y}\|)</m>
                    <md>
                        <mrow>\Longrightarrow \amp \alpha = \|\vec{x}\|\frac{\vec{x}^T\vec{y}}{\|\vec{x}\|\|\vec{y}\|} =\frac{\vec{x}^T\vec{y}}{\|\vec{y}\|}</mrow>
                        <mrow>\Longrightarrow \amp p = \alpha  \vec{u} = \alpha \frac{\vec{y}}{\|\vec{y}\|} = \frac{\vec{x}^T\vec{y}}{\|\vec{y}\|^2}\vec{y}.</mrow>
                    </md>
                </p>

                <p><m>\alpha</m> é a <term>projeção escalar</term> de <m>\vec{x}</m> sobre <m>\vec{y}</m>.</p>

                <p><m>\mbox{proj}_{\vec{y}}\vec{x} = \vec{p}</m> é a <term>projeção vetorial</term> de <m>\vec{x}</m> sobre <m>\vec{y}</m>.</p>

                <exercise>
                    <statement>
                        Encontre as projeções escalares e vetoriais dos vetores <m>\vec{x}</m> e <m>\vec{y}</m> na direção do vetor <m>\vec{z}</m> para
                        <me>
                            \vec{x} = \begin{pmatrix} 1 \\ -1 \\ 2\end{pmatrix}, \,\,\, \vec{y} = \begin{pmatrix} 2 \\ 1 \\ 0\end{pmatrix}, \,\,\, \vec{z} = \begin{pmatrix} 3 \\ -1 \\-2\end{pmatrix}.
                        </me>
                    </statement>
                </exercise>

            </subsection>



            <!--  *********************************************************
            *************************************************************** -->
                

            <subsection xml:id="Gram-Schmidt">
                <title>Conjuntos ortogonais e ortogonalização de Gram-Schmidt</title>


                <definition>
                    <notation>
                    <!-- <usage><m>\| \vec{x}\|</m></usage> -->
                    <description>conjuntos ortonormais</description>
                    </notation>
                
                    <statement>
                        <p>
                            Sejam <m>\{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n\}</m> um conjunto de vetores em um espaço vetorial <m>V</m> munido com produto interno. Se <m>\langle \vec{v}_i, \vec{v}_j \rangle = 0</m> sempre que <m>i \neq j</m>, então o conjunto é dito <term>ortogonal</term>. Além disso, se <m>\langle \vec{v}_i, \vec{v}_i \rangle = 1</m> para todo <m>i = 1, \ldots, n</m>, o conjunto é dito <term>ortonormal</term>.
                        </p>
                    </statement>
                </definition>


                <example>
                    <statement>
                        O conjunto formado pelos pelos vetores
                        <me>
                            \vec{v}_1 = \begin{pmatrix} 1 \\ 1 \\1 \end{pmatrix}, \,\,\vec{v}_2 = \begin{pmatrix} -1 \\ 0 \\1 \end{pmatrix}, \,\,\vec{v}_3 = \begin{pmatrix} 1 \\ -2 \\1 \end{pmatrix},
                        </me>
                        é ortogonal pois <m>\langle \vec{v}_1, \vec{v}_2\rangle =-1+1 = 0 </m>, <m>\langle \vec{v}_1, \vec{v}_3\rangle = 1-2+1=0</m> e <m>\langle \vec{v}_2, \vec{v}_3\rangle = -1 +1 = 0</m>. Todavia, o conjunto não é ortonormal pois <m>\langle \vec{v}_1, \vec{v}_1\rangle =1+1+1 = 3 </m>. Podemos obter um conjunto ortonormal a partir de um conjunto ortogonal, se dividirmos cada um dos vetores por sua norma. Assim, é ortonormal o conjunto formado pelos vetores:
                        <me>
                            \vec{u}_1 = \begin{pmatrix} 1/\sqrt{3} \\ 1/\sqrt{3} \\1/\sqrt{3} \end{pmatrix}, \,\,\vec{u}_2 = \begin{pmatrix} -1/\sqrt{2} \\ 0 \\ 1/\sqrt{2} \end{pmatrix}, \,\,\vec{u}_3 = \begin{pmatrix} 1/\sqrt{6} \\ -2/\sqrt{6} \\1/\sqrt{6} \end{pmatrix}.
                        </me>
                    </statement>
                </example>


                <theorem>
                    <!-- <title> do núcleo e da imagem</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    Se <m>\{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n\}</m> é um conjunto ortogonal de vetores não nulos em um espaço vetorial <m>V</m> com produto interno, então <m>\{\vec{v}_1, \vec{v}_2, \ldots, \vec{v}_n\}</m> é Linearmente Independente.
                  </statement>
                
                  <proof>
                    <md>
                        <mrow>\amp \alpha_1\vec{v}_1 + \alpha_2 \vec{v}_2 + \cdots + \alpha_n\vec{v}_n = \vec{0}</mrow>
                        <mrow>\Longrightarrow \amp \langle \alpha_1\vec{v}_1 + \alpha_2 \vec{v}_2 + \cdots + \alpha_n\vec{v}_n, \vec{v}_i\rangle = \langle \vec{0}, \vec{v}_i\rangle =0</mrow>
                        <mrow>\Longrightarrow \amp 0 = \langle \alpha_1\vec{v}_1 , \vec{v}_i\rangle + \langle\alpha_2 \vec{v}_2, \vec{v}_i\rangle + \cdots + \langle\alpha_n\vec{v}_n, \vec{v}_i\rangle = \alpha_i \| \vec{v}_i\|^2</mrow>
                        <mrow> \Longrightarrow \amp \alpha_i =0.</mrow>
                    </md>
                    Isso vale para qualquer <m>i = 1, \ldots, n</m>, de modo que a única solução de <m>\alpha_1\vec{v}_1 + \alpha_2 \vec{v}_2 + \cdots + \alpha_n\vec{v}_n = \vec{0}</m> é <m>\alpha_1=\alpha_2= \cdots = \alpha_n = 0</m>.
                  </proof>
                </theorem>


                <theorem xml:id = "coord_prod_int">
                    <!-- <title> do núcleo e da imagem</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    Seja <m>\{\vec{u}_1, \vec{u}_2, \ldots, \vec{u}_n\}</m> é uma base ortonormal para um espaço vetorial <m>V</m> com produto interno. Se <m>\vec{v} = \sum v_i \vec{u}_i</m>, então <m>v_i = \langle \vec{v}, \vec{u}_i \rangle</m>.
                  </statement>
                
                  <proof>
                    <me>
                        \langle \vec{v}, \vec{u}_i\rangle = \sum v_i\rangle \vec{u}_i, \vec{u}_i \rangle = v_i.
                    </me>
                  </proof>
                </theorem>

                <p>
                    O <xref ref= "coord_prod_int"></xref> pode ser utilizado como um método para calcular as coordenadas de um vetor em uma base ortonormal de um espaço vetorial com produto interno.
                </p>


                <exercise>
                    <statement>
                        Calcule as coordenadas do vetor <m>\vec{v} = (2, 3, -4)^T</m> na base formada pelos vetores
                        <me>
                            \vec{u}_1 = \begin{pmatrix} 1/\sqrt{3} \\ 1/\sqrt{3} \\1/\sqrt{3} \end{pmatrix}, \,\,\vec{u}_2 = \begin{pmatrix} -1/\sqrt{2} \\ 0 \\ 1/\sqrt{2} \end{pmatrix}, \,\,\vec{u}_3 = \begin{pmatrix} 1/\sqrt{6} \\ -2/\sqrt{6} \\1/\sqrt{6} \end{pmatrix}.
                        </me>
                    </statement>
                </exercise>


                <p>
                    Suponha que temos dois vetores <m>\vec{x}_1, \vec{x}_2 \in \mathbb{R}^2</m> L.I. e buscamos uma base ortonormal <m>\vec{u}_1, \vec{u}_2</m> que contenha um vetor  na direção de <m>\vec{x}_1</m>. Podemos fazer isso do através dos seguintes vetores:
                    <ol>
                        <li><m>\vec{u}_1 = \vec{x}_1/(\|\vec{x}_1\|)</m>,</li>
                        <li><m>\vec{p}_1 = \mbox{proj}_{\vec{u}_1}\vec{x}_2 = \langle \vec{x}_2, \vec{u}_1 \rangle \vec{u}_1 </m>,</li>
                        <li><m>\vec{u}_2 = (\vec{x}_2 - \vec{p}_1)/(\|\vec{x}_2 - \vec{p}_1\|)</m>.</li>
                    </ol>
                </p>

                <sage>
                    <input>
                        import matplotlib.pyplot as plt
                        import numpy as np


                        x1 = np.array([1.5,3])
                        x2 = np.array([3, 1])

                        u1 = x1/np.linalg.norm(x1)


                        p1 = (u1.dot(x2))*u1

                        z = x2-p1

                        u2= z/np.linalg.norm(z)


                        #plotting the vectors
                        fig, ax = plt.subplots(figsize=(5, 5))     
                        ax.set_xlim(xmin=-3, xmax=5)
                        ax.set_ylim(ymin=-3, ymax=5)
                        ax.xaxis.set_ticks([-2,-1,0,1,2,3,4])
                        ax.yaxis.set_ticks([-2,-1,0,1,2,3,4])
                        plt.grid()

                        head_width =0.3
                        head_length = 1.5*head_width

                        def cor(x):
                            x_new = x[0]/(head_length+np.sqrt(x[0]^2+x[1]^2))*np.sqrt(x[0]^2+x[1]^2)
                            y_new = x[1]/(head_length+np.sqrt(x[0]^2+x[1]^2))*np.sqrt(x[0]^2+x[1]^2)
                            return np.array([x_new,y_new])

                        plt.arrow(0,0,cor(x1)[0], cor(x1)[1], head_width =head_width)
                        plt.annotate('x1', cor(x1)/2 + np.array([-0.3,0.6]))

                        plt.arrow(0,0,cor(x2)[0], cor(x2)[1], head_width =head_width, color = 'blue')
                        plt.annotate('x2', cor(x2)/1.1 + np.array([0.1,-0.2]))

                        plt.arrow(0,0,cor(p1)[0], cor(p1)[1], head_width =head_width, color = 'purple')
                        plt.annotate('p1', cor(p1)/2 + np.array([0.2,0.2]))

                        plt.arrow(0,0,cor(u1)[0], cor(u1)[1], head_width =head_width, color = 'red')
                        plt.annotate('u1', cor(p1)/2 + np.array([-0.7,-0.3]))

                        plt.arrow(p1[0],p1[1],cor(z)[0], cor(z)[1], head_width =head_width, color = 'red')

                        plt.arrow(0,0,cor(u2)[0], cor(u2)[1], head_width =head_width, color = 'red')
                        plt.annotate('u2', cor(u2)/2 + np.array([-0.2,-0.3]))

                        plt.show()
                    </input>
                    <output>
                        plot
                    </output>
                </sage>

                <p>
                    Note que a base obtida pelo processo acima é, de fato, ortonormal, pois <m>\|\vec{u}_1\|  = \|\vec{u}_2\| = 1</m>  e
                    <md>
                        <mrow>\langle \vec{u}_1, \vec{u}_2 \rangle =\amp \left\lt \vec{u}_1, \frac{\vec{x}_2 - \vec{p}_1}{\|\vec{x}_2 - \vec{p}_1\|}  \right\gt = \frac{1}{\|\vec{x}_2 - \vec{p}_1\|} (\langle \vec{u}_1, \vec{x}_2 \rangle - \langle \vec{u}_1, \vec{p}_1\rangle) </mrow>
                        <mrow> =\amp \frac{1}{\|\vec{x}_2 - \vec{p}_1\|} (\langle \vec{u}_1, \vec{x}_2 \rangle - \langle \vec{u}_1,  \langle \vec{x}_2, \vec{u}_1 \rangle \vec{u}_1\rangle) = 0.</mrow>
                    </md>   
                </p>



                <p>
                    Suponha, agora, que temos três vetores <m>\vec{x}_1, \vec{x}_2, \vec{x}_3 \in \mathbb{R}^3</m> L.I. e buscamos uma base ortonormal <m>\vec{u}_1, \vec{u}_2, \vec{u}_3</m> que contenha um vetor  na direção de <m>\vec{x}_1</m>. Podemos fazer isso do através dos seguintes vetores:
                    <ol>
                        <li><m>\vec{u}_1 = \vec{x}_1/(\|\vec{x}_1\|)</m>,</li>
                        <li><m>\vec{p}_1 = \mbox{proj}_{\vec{u}_1}\vec{x}_2 = \langle \vec{x}_2, \vec{u}_1 \rangle \vec{u}_1 </m>,</li>
                        <li><m>\vec{u}_2 = (\vec{x}_2 - \vec{p}_1)/(\|\vec{x}_2 - \vec{p}_1\|)</m>,</li>
                        <li><m>\vec{p}_2 = \mbox{proj}_{\vec{u}_1}\vec{x}_3 + \mbox{proj}_{\vec{u}_2}\vec{x}_3 = \langle \vec{x}_3, \vec{u}_1 \rangle \vec{u}_1 + \langle \vec{x}_3, \vec{u}_2 \rangle \vec{u}_2 </m>,</li>
                        <li><m>\vec{u}_3 = (\vec{x}_3 - \vec{p}_2)/(\|\vec{x}_3 - \vec{p}_2\|)</m>.</li>
                    </ol>
                </p>

                <sage>
                    <input>
                        import matplotlib.pyplot as plt
                        import numpy as np


                        x1 = np.array([1.5,3, 2])
                        x2 = np.array([3, 1, -1])
                        x3 = np.array([0, -2, 1])

                        u1 = x1/np.linalg.norm(x1)
                        p1 = (u1.dot(x2))*u1
                        z1 = x2-p1
                        u2 = z1/np.linalg.norm(z1)
                        q2 = (u1.dot(x3))*u1
                        r2 = (u2.dot(x3))*u2
                        p2 = q2 + r2
                        z2 = x3 - p2
                        u3 = z2/np.linalg.norm(z2)
                        import pandas as pd
                        import plotly.graph_objects as go


                        df = pd.DataFrame(dict(
                            X=[0,x1[0],0,x2[0], 0,x3[0], 0,u1[0], 0, u2[0], 0, u3[0], p1[0], x2[0], p2[0], x3[0]], 
                            Y=[0,x1[1],0,x2[1], 0,x3[1], 0,u1[1], 0, u2[1], 0, u3[1], p1[1], x2[1], p2[1], x3[1]],
                            Z=[0,x1[2],0,x2[2], 0,x3[2], 0,u1[2], 0, u2[2], 0, u3[2], p1[2], x2[2], p2[2], x3[2]],
                            color=["x1", "x1", "x2", "x2", "x3", "x3", "u1", "u1", "u2", "u2", "u3", "u3", "z1", "z1", "z2", "z2"]
                        ))

                        df1 = pd.DataFrame(dict(
                            X=[x1[0],x2[0],x3[0], u1[0], u2[0], u3[0]], 
                            Y=[x1[1],x2[1],x3[1], u1[1], u2[1], u3[1]],
                            Z=[x1[2],x2[2],x3[2], u1[2], u2[2], u3[2]],
                            color=["x1", "x2", "x3", "u1", "u2", "u3"],
                            text=["x1", "x2", "x3", "u1", "u2", "u3"]
                        ))

                        import plotly.express as px

                        fig1 = px.line_3d(df, x='X', y='Y', z='Z', color="color", markers=False)
                        fig2 =px.line_3d(df1, x='X', y='Y', z='Z', color="color", markers=True, symbol_sequence=['diamond'], text="text")
                        fig3 = go.Figure(data=fig1.data + fig2.data)
                        fig3.update_layout(showlegend=False,font = dict(size = 30),
                                        scene = dict(xaxis_title='', yaxis_title='', zaxis_title='',
                                            xaxis = dict(tickfont=dict(size=12,) ),
                                            yaxis = dict(tickfont=dict(size=12,) ),
                                            zaxis = dict(tickfont=dict(size=12,) ),))
                        fig3.write_html("yourfile.html")
                        print("u1 = ", u1)
                        print("u2 = ", u2)
                        print("u3 = ", u3)
                    </input>
                    <output>
                        plot
                    </output>
                </sage>

                <exercise>
                    <statement>
                        Utilize o processo descrito acima para encontrar uma base para <m>\mathbb{R}^3</m> a partir de <m>\vec{x}_1 = (1, -2, 3)^T</m>, <m>\vec{x}_2 = (1, -2, -1)^T</m>, <m>\vec{x}_3 = (-1, -2, 1)^T</m>.
                    </statement>
                </exercise>

                <p><it>Processo de ortogonalização de Gram-Schmidt.</it></p>

                <p>Definimos agora o processo de ortogonalização de Gram-Schmidt em geral.</p>

                <p>Seja <m>\{\vec{x}_1, \vec{x}_2, \ldots, \vec{x}_n\}</m> uma base para um espaço com produto interno <m>V</m>. Obtemos uma base <it>ortonormal</it> para <m>V</m> definindo:</p>
                <me>
                    \vec{u}_1 = \frac{\vec{x}_1}{\|\vec{x}_1\|}
                </me>
                <p>e definindo <m>\vec{u}_2, \ldots, \vec{u}_n</m> recursivamente por</p>
                <me>
                    \vec{p}_{k} = \langle \vec{x}_{k+1}, \vec{u}_{1} \rangle \vec{u}_{1} + \langle \vec{x}_{k+1}, \vec{u}_{2} \rangle \vec{u}_{2} + \cdots + \langle \vec{x}_{k+1}, \vec{u}_{k} \rangle \vec{u}_{k}, 
                </me>
                <me>
                    \vec{u}_{k+1}= \frac{\vec{x}_{k+1} - \vec{p}_{k}}{\| \vec{x}_{k+1} - \vec{p}_{k} \|}
                </me>

                <exercise>
                    <statement>
                        Encontre uma base ortonormal para o espaço coluna de
                        <me>
                            A = \begin{pmatrix}
                            1 \amp 1 \amp 5 \amp 1 \\
                            -1 \amp -2 \amp -8 \amp 0 \\
                            0 \amp 0 \amp 0 \amp 1 \\
                            0 \amp 1 \amp 3 \amp 1  
                            \end{pmatrix}
                        </me>
                    </statement>
                </exercise>

                <remark>O processo de ortogonalizaçã de Gram-Schmidt tem a propriedade que <m>\{\vec{u}_1, \vec{u}_2, \ldots, \vec{u}_k\}</m> é uma base ortonormal para <m>\mbox{Span} (\vec{x}_1, \vec{x}_2, \ldots, \vec{x}_k)</m> para qualquer <m>k = 1,2,\ldots,n</m>. Deixamos para o leitor a verificação dessa propriedade.</remark>

                <remark>Se <m>\mathcal{U} = \{\vec{u}_1, \vec{u}_2, \ldots, \vec{u}_n\}</m> é uma base ortonormal para <m>\mathbb{R}^n</m>, então a matriz de mudança de base da base <m>\mathcal{U}</m> para a base canônica
                    <me>
                        U = \begin{pmatrix} | \amp | \amp \cdots \amp |\\
                        \vec{u}_1 \amp \vec{u}_2 \amp \cdots \amp \vec{u}_n\\
                        | \amp | \amp \cdots \amp |\\\end{pmatrix}
                    </me> tem inversa <m>U^{-1} = U^T</m>. Deixamos para o leitor a verificação dessa propriedade.</remark>


            </subsection>


        </section>


        <!--  *********************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        *************************************************************** -->                                                                                                    



        <section xml:id="Transformacoes_lineares">
            <title>Transformações Lineares</title>
           
            <intro>
               <p>
                Muitos problemas de interesse nas ciências e na engenharia são aplicações lineares. Para aplicações lineares podemos utilizar os conhecimentos adquiridos nas seções anteriores sobre bases e matrizes para estudar e resolver problemas desse tipo de maneira conveniente.
               </p>
           </intro>
           
            <subsection xml:id="trans_lin">
                <title>Transformações Lineares</title>
                <definition>
                    <notation>
                    <usage><m>L</m></usage>
                    <description>transformação linear</description>
                    </notation>
                
                    <statement>
                        <p>
                            Um mapeamento<fn>uma função</fn>  <m>L : V \to W</m>, de um espaço vetorial <m>(V,E,\cdot, +)</m> para um espaço vetorial <m>(W,E,\odot,\oplus)</m> é dita uma <term>transformação linear</term> <fn>também chamado de <term>mapeamento</term> linear, <term>operador linear</term> ou <term>função linear</term> (dependendo do contexto)</fn> se 
                            <me>
                                L(\alpha \cdot \vec{u} + \beta \vec{v}) = \alpha \odot L(\vec{u}) \oplus \beta \odot L(\vec{v}).
                            </me>
                        </p>
                    </statement>
                </definition>




                <example>
                    <statement>
                        Seja <m>L: \mathbb{R}^2 \to \mathbb{R}^2</m> a função definida por
                        <me>
                            L\begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} -x_2 \\ x_1 \end{pmatrix}
                        </me>
                        é uma transformação linear, pois <m>\ldots</m>
                    </statement>
                </example>


                <example>
                    <statement>
                        Seja <m>L: \mathbb{R}^2 \to \mathbb{R}^2</m> a função definida por
                        <me>
                            L\begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} x_1^2 \\ x_2 \end{pmatrix}
                        </me>
                        não é uma transformação linear, pois <m>\ldots</m>
                    </statement>
                </example>

                <example>
                    <statement>
                        O mapeamento <m>L: \mathbb{R}^3 \to \mathbb{R}^2</m> definido por
                        <me>
                            L\begin{pmatrix} x_1 \\ x_2 \\ x_3 \end{pmatrix} = \begin{pmatrix} x_1 \\ x_2 \end{pmatrix}
                        </me>
                        é uma transformação linear, pois <m>\ldots</m>

                        Podemos notar que
                        <me>
                            L\begin{pmatrix} x_1 \\ x_2 \\x_3 \end{pmatrix} = \begin{pmatrix} 1 \amp 0 \amp 0 \\ 0 \amp 1 \amp 0 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\x_3 \end{pmatrix}.
                        </me>
                        Essa transformação linear é a projeção do espaço <m>\mathbb{R}^3</m> em <m>\mathbb{R}^2</m>.
                    </statement>
                </example>

                <p>O código abaixo faz um plot da projeção do exemplo acima.</p>

                <sage>
                    <input>
                        import matplotlib.pyplot as plt
                        import numpy as np


                        x1 = np.array([1,0, 0])
                        x2 = np.array([0, 1, 0])
                        x3 = np.array([0.5, 0.5, 1])

                        q2 = (x1.dot(x3))*x1
                        r2 = (x2.dot(x3))*x2
                        p2 = q2 + r2
                        z2 = x3 - p2

                        import pandas as pd
                        import plotly.graph_objects as go


                        df = pd.DataFrame(dict(
                            X=[0,x1[0],0,x2[0], 0,x3[0], p2[0], x3[0]], 
                            Y=[0,x1[1],0,x2[1], 0,x3[1], p2[1], x3[1]],
                            Z=[0,x1[2],0,x2[2], 0,x3[2], p2[2], x3[2]],
                            color=["x1", "x1", "x2", "x2", "x3", "x3", "z2", "z2"]
                        ))

                        df1 = pd.DataFrame(dict(
                            X=[x1[0],x2[0],x3[0],p2[0]], 
                            Y=[x1[1],x2[1],x3[1],p2[1]],
                            Z=[x1[2],x2[2],x3[2],p2[2]],
                            color=["x1", "x2", "x3","z2"],
                            text=["x", "y", "v","p"]
                        ))

                        import plotly.express as px

                        fig1 = px.line_3d(df, x='X', y='Y', z='Z', color="color", markers=False)
                        fig2 =px.line_3d(df1, x='X', y='Y', z='Z', color="color", markers=True, symbol_sequence=['diamond'], text="text")
                        fig3 = go.Figure(data=fig1.data + fig2.data)
                        fig3.update_layout(showlegend=False,font = dict(size = 30),
                                        scene = dict(xaxis_title='', yaxis_title='', zaxis_title='',
                                            xaxis = dict(tickfont=dict(size=12,) ),
                                            yaxis = dict(tickfont=dict(size=12,) ),
                                            zaxis = dict(tickfont=dict(size=12,) ),))
                        fig3.write_html("yourfile.html")
                    </input>
                    <output>
                        plot
                    </output>
                </sage>




                <example>
                    <statement>
                        O mapeamento <m>L: \mathbb{R}^2 \to \mathbb{R}^3</m> definido por
                        <me>
                            L\begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} x_2 \\ x_1 \\x_1 + x_2 \end{pmatrix}
                        </me>
                        é uma transformação linear, pois <m>\ldots</m>

                        Podemos notar que
                        <me>
                            L\begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 0 \amp 1 \\ 1 \amp 0 \\ 1 \amp 1 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix}.
                        </me>
                    </statement>
                </example>


                <exercise>
                    <statement>
                        Seja <m>A</m> é uma matriz <m>n \times m</m>. Mostre que a função
                        <md>
                            <mrow>L: \amp \mathbb{R}^m \to \mathbb{R}^n,</mrow>
                            <mrow>\amp L(\vec{v}) = A\vec{v}</mrow>
                        </md>
                        é uma transformação linear.
                    </statement>
                </exercise>


                <example>
                    <title>Rotação no plano</title>
                    <statement>
                        Seja <m>R_\theta: \mathbb{R}^2 \to \mathbb{R}^2</m> a operação que os vetores do plano em <m>\theta</m> radianos no sentido anti horário. Para compreendermos seu efeito, colocamos os vetores do plano em sua forma polar:
                        <me>
                            \vec{v} = (r \mbox{cos}(\alpha), r \mbox{sen}(\alpha))^T
                        </me>
                        e percebemos que rodar <m>\theta</m> no sentido anti-horário significa somar <m>\theta</m> ao ângulo, de modo que
                        <me>
                            R_\theta(\vec{v}) = \begin{pmatrix} r \mbox{cos}(\alpha+\theta)\\ r \mbox{sen}(\alpha+\theta)\end{pmatrix} = \begin{pmatrix} r(\mbox{cos}(\alpha)^2 -\mbox{sen}(\theta)^2)\\ r (2\mbox{sen}(\alpha)\mbox{cos}(\theta))\end{pmatrix} = \begin{pmatrix} \mbox{cos}(\theta) \amp -\mbox{sen}(\theta)\\ \mbox{sen}(\theta) \amp \mbox{cos}(\theta) \end{pmatrix}\begin{pmatrix} r \mbox{cos}(\alpha)\\ r \mbox{sen}(\alpha)\end{pmatrix}
                        </me>
                        Pelo exercício anterior, a rotação é uma transformação linear.
                    </statement>
                </example>


                <lemma xml:id = "linear_trans_prop">
                    <!-- <title> do núcleo e da imagem</title> -->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    Se <m>L: V \to W</m> é uma transformação linear e <m>\vec{v}, \vec{v}_1, \ldots, \vec{v}_n \in V</m>, então
                    <ol>
                        <li><m>L(\vec{0}_V) = \vec{0}_W;</m></li>
                        <li><m> L(\alpha_1 \vec{v}_1 +  \cdots + \alpha_n \vec{v}_n) = \alpha_1 L(\vec{v}_1) +  \cdots + \alpha_n L(\vec{v}_n);</m></li>
                        <li><m>L(-\vec{v}) = -L(\vec{v});</m></li>
                    </ol>
                  </statement>
                
                  <proof>
                    <ol>
                        <li><m>L(\vec{0}_V) = L(0\vec{v}) = 0L(\vec{v}) = \vec{0}_W;</m></li>
                        <li><md>
                            <mrow>L(\alpha_1 \vec{v}_1 +  \cdots + \alpha_n \vec{v}_n)  =\amp L(\alpha_1 \vec{v}_1 +  \cdots + \alpha_{n-1} \vec{v}_{n-1}) +\alpha_n L(\vec{v}_n) = \cdots </mrow>
                            <mrow> =\amp \alpha_1 L(\vec{v}_1) +  \cdots + L(\alpha_n \vec{v}_n);</mrow>
                            </md></li>
                        <li><m> L(\vec{v}) + L(-\vec{v}) = L(\vec{v})-  L(\vec{v}) = \vec{0};</m></li>
                    </ol>
                  </proof>
                </lemma>


                <example>
                    <statement>
                        Seja <m>V</m> um espaço vetorial. O operador identidade <m>I: V \to V</m> definido por
                        <me>
                            I(\vec{v}) = \vec{v}, \,\,\, \forall \vec{v} \in V
                        </me>
                        é uma transformação linear, pois <m>\ldots</m>
                    </statement>
                </example>


                <example>
                    <statement>
                        O mapeamento <m>D:C^1(a,b) \to C(a,b)</m>, que associa a cada função a sua derivada é um operador linear
                        <me>
                            D(f) = f'
                        </me>
                        pois, para quaisquer <m>\alpha, \beta \in \mathbb{R}</m> e <m>f,g \in C^1(a,b)</m>,
                        <me>
                            D(\alpha f + \beta g) = (\alpha f + \beta g)' = \alpha f' + \beta g'.
                        </me>
                    </statement>
                </example>


                <example>
                    <statement>
                        Seja <m>P^3</m> o conjunto dos polinômios de grau 3. Ele é um espaço vetorial e <m>\mathcal{U} = \{x^3, x^2, x, 1\}</m> é uma base para esse espaço. O operador <m>D:P^3 \to P^3</m> definido por <m>D(p) = 2 p'' - 3p' + p</m> é um operador linear, pois ...
                        
                        Se <m>p(x) = ax^3 + bx^2 + cx + d</m>, então suas coordenadas na base <m>\mathcal{U}</m> são <m>(a, b, c, d)^T</m> e <m>D(p) = a x^3 + (-9a+b)x^2 + (12a-6b+c)x + (4b-3c+d)</m>, de modo que as suas coordenadas na base <m>\mathcal{U}</m> são iguais a
                        <me>
                            D(p) = \begin{pmatrix}
                            1 \amp 0 \amp 0 \amp 0  \\
                            -9 \amp 1 \amp 0 \amp 0  \\
                            12 \amp -6 \amp 1 \amp 0 \\
                            0 \amp 4 \amp -3 \amp 1 
                            \end{pmatrix}
                            \begin{pmatrix}
                            a \\
                            b \\
                            c \\
                            d
                            \end{pmatrix}
                        </me>
                    </statement>
                </example>





            </subsection>


            <!--  *********************************************************
            *************************************************************** -->
                

            <subsection xml:id="matriz_lin_trans">
                <title>Representação Matricial de Transformações Lineares</title>


                <theorem xml:id = "rep_matricial">
                    <title> da Representação Matricial</title>
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    Sejam <m>L:U \to V</m> uma transformação linear entre dois espaços vetoriais <m>U</m> e <m>V</m> e <m>\mathcal{U} = \{\vec{u}_1, \ldots, \vec{u}_n\}</m>, <m>\mathcal{V} = \{\vec{v}_1, \ldots, \vec{v}_m\}</m> bases para esses espaços vetoriais, respectivamente. Se um vetor <m>\vec{u}</m> tem coordenadas <m>\vec{u}^\mathcal{U} = (u_1^{\mathcal{U}}, u_2^{\mathcal{U}}, \ldots, u_n^{\mathcal{U}})</m>, então existe uma matriz <m>A=(a_{ij})</m>, <m>m \times n</m>, tal que as coordenadas de <m>L(\vec{u})</m> na base <m>\mathcal{V}</m> são dadas por
                    <me>
                        L(\vec{u})^\mathcal{V} = A\vec{u}^\mathcal{U}.
                    </me>
                    As colunas dessa matriz são obtidas calculando <m>\vec{a}_j = L(\vec{u}_j)^\mathcal{V}</m>, <m>j=1,\ldots, n</m>, de modo que <m>a_{ij} = L(\vec{u}_j)^\mathcal{V}_i</m>.
                  </statement>
                
                  <proof>
                    <md>
                        <mrow>L(\vec{u}) =\amp u_1^{\mathcal{U}}L(\vec{u}_1) + u_2^{\mathcal{U}}L(\vec{u}_2) + \cdots + u_n^{\mathcal{U}} L(\vec{u}_n)</mrow>
                        <mrow>= \amp u_1^{\mathcal{U}}(L(\vec{u}_1)^\mathcal{V}_1 \vec{v}_1 + \cdots + L(\vec{u}_1)^\mathcal{V}_m \vec{v}_m) + \cdots + u_n^{\mathcal{U}} (L(\vec{u}_n)^\mathcal{V}_1 \vec{v}_1 + \cdots + L(\vec{u}_n)^\mathcal{V}_m \vec{v}_m) </mrow>
                        <mrow>= \amp (u_1^{\mathcal{U}}L(\vec{u}_1)^\mathcal{V}_1 + \cdots + u_n^{\mathcal{U}} (L(\vec{u}_n)^\mathcal{V}_1))\vec{v}_1 + \cdots + (u_1^{\mathcal{U}}L(\vec{u}_1)^\mathcal{V}_m  + \cdots +  u_n^{\mathcal{U}}L(\vec{u}_n)^\mathcal{V}_m)\vec{v}_m </mrow>
                        <mrow> = \amp (L(\vec{u}_1)^\mathcal{V}_1, \ldots,  (L(\vec{u}_n)^\mathcal{V}_1)) \begin{pmatrix} u_1^{\mathcal{U}} \\ \vdots \\ u_n^{\mathcal{U}}\end{pmatrix} \vec{v}_1 + \cdots + (L(\vec{u}_1)^\mathcal{V}_m, \ldots,  (L(\vec{u}_n)^\mathcal{V}_m)) \begin{pmatrix} u_1^{\mathcal{U}} \\ \vdots \\ u_n^{\mathcal{U}}\end{pmatrix} \vec{v}_m </mrow>,
                    </md>
                    de modo que as coordenadas de <m>L(\vec{u})</m> na base <m>\mathcal{V}</m> são
                    <me>
                        L(\vec{u})^{\mathcal{V}} = \begin{pmatrix} L(\vec{u}_1)^\mathcal{V}_1 \amp \cdots \amp  L(\vec{u}_n)^\mathcal{V}_1\\ \vdots \amp \ddots \amp \vdots \\ L(\vec{u}_1)^\mathcal{V}_m \amp \cdots \amp  L(\vec{u}_n)^\mathcal{V}_m \end{pmatrix} \begin{pmatrix} u_1^{\mathcal{U}} \\ \vdots \\ u_n^{\mathcal{U}}\end{pmatrix} = \begin{pmatrix} | \amp \cdots \amp  | \\ L(\vec{u}_1)^\mathcal{V} \amp \cdots \amp  L(\vec{u}_n)^\mathcal{V}\\ | \amp \cdots \amp  | \end{pmatrix} \begin{pmatrix} u_1^{\mathcal{U}} \\ \vdots \\ u_n^{\mathcal{U}}\end{pmatrix}.
                    </me>
                  </proof>
                </theorem>

                <p>Dizemos que <m>A</m> representa <m>L</m> nas bases <m>\mathcal{U}</m> e <m>\mathcal{V}</m>.</p>


                <example>
                    <statement>
                        Seja  <m>L: \mathbb{R}^3 \to \mathbb{R}^4</m>, a transformação linear definida por
                        <me>
                            L \begin{pmatrix} x_1\\ x_2\\ x_3 \end{pmatrix} = \begin{pmatrix} x_1 - x_3 \\ -x_2\\ -x_1 - x_2 + x_3 \\ x_2 - x_3 \end{pmatrix}.
                        </me>
                        A matriz que representa <m>L</m> nas bases canônicas de <m>\mathbb{R}^3</m> e <m>\mathbb{R}^4</m> é 
                        <me>
                            A = \begin{pmatrix}
                            1 \amp 0 \amp -1  \\
                            0 \amp -1 \amp 0  \\
                            -1 \amp -1 \amp 1 \\
                            0 \amp 1 \amp -1 
                            \end{pmatrix},
                        </me>
                        de modo que <m>L(\vec{x}) = A\vec{x}</m>.
                    </statement>
                </example>


                <example>
                    <statement>
                        A matriz que representa a transformação linear do exemplo anterior nas bases <m>\mathcal{U} = \{(1,0,1)^T, (0,-1,1)^T, (-1,1,1)^T\}</m> e na base canônica <m>\mathbb{R}^4</m> é 
                        <me>
                            A = \begin{pmatrix}
                            0 \amp -1 \amp -2 \\
                            0 \amp 1 \amp -1  \\
                            0 \amp 2 \amp 1 \\
                            -1 \amp -2 \amp 0 
                            \end{pmatrix},
                        </me>
                        de modo que <m>L(\vec{x}) = A\vec{x}^\mathcal{U}</m>.
                    </statement>
                </example>


                <example>
                    <statement>
                        A matriz que representa a transformação linear do exemplo anterior nas bases <m>\mathcal{U} = \{(1,0,1)^T, (0,-1,1)^T, (-1,1,1)^T\}</m> e <m>\mathcal{V} = \{(1,0,0,-1)^T, (0,1,1,0)^T, (1,0,0,1)^T, (0,-1,1,0)^T\}</m> tem colunas <m>V^{-1} (0,0,0,-1)^T</m>, <m>V^{-1} (-1,1,2,-2)^T</m> e <m>V^{-1} (0,-1,1,0)^T</m>, nessa ordem.
                    </statement>
                </example>


                <example xml:id="ex_proj">
                    <statement>
                        Seja <m>P: \mathcal{R}^3 \to \mathcal{R}^3</m> a projeção no plano que passa pela origem e têm vetores diretores <m>\vec{u}_2 = (0,1,1)^T, \vec{u}_3 = (2,-1,1)^T</m>. Para representá-la na base <m>\mathcal{U} = \{\vec{u}_1 = (1,1,-1)^T, \vec{u}_2 = (0,1,1)^T, \vec{u}_3 = (2,-1,1)^T\}</m> notamos que <m>\vec{u}_2 \perp \vec{u}_3 </m> e
                        <md>
                            <mrow>\mbox{proj}_{\vec{u}_2 \vec{u}_3} \vec{u}_1 =\amp \mbox{proj}_{\vec{u}_2} \vec{u}_1 + \mbox{proj}_{\vec{u}_3} \vec{u}_1 = \vec{0}</mrow>,
                            <mrow>\mbox{proj}_{\vec{u}_2 \vec{u}_3} \vec{u}_2 =\amp \mbox{proj}_{\vec{u}_2} \vec{u}_2 + \mbox{proj}_{\vec{u}_3} \vec{u}_2 = \vec{u}_2</mrow>,
                            <mrow>\mbox{proj}_{\vec{u}_2 \vec{u}_3} \vec{u}_3 =\amp \mbox{proj}_{\vec{u}_2} \vec{u}_3 + \mbox{proj}_{\vec{u}_3} \vec{u}_3 = \vec{u}_3</mrow>,
                        </md>
                        de modo que, nessa base, a <m>P</m> é representada pela matriz
                        <me>
                            A^{\mathcal{U}} = \begin{pmatrix} 0 \amp 0 \amp 0 \\ 0 \amp 1 \amp 0 \\ 0 \amp 0 \amp 1\end{pmatrix}.
                        </me>

                    </statement>
                </example>

                <p>Como representar a matriz do exemplo anterior na base canônica?</p>

                <sage>
                    <input>
                        import matplotlib.pyplot as plt
                        import numpy as np
                        
                        
                        v = np.array([0.2,0.5,0.4])
                        
                        x1 = np.array([1,0, 1])
                        x2 = np.array([0, -1, 1])
                        x3 = np.array([-1, 1, 1])
                        
                        u1 = x1/x1.dot(x1)
                        u2 = x2/x2.dot(x2)
                        u3 = x3/x3.dot(x3)
                        
                        q2 = (u3.dot(v))*u3
                        r2 = (u2.dot(v))*u2
                        p2 = q2 + r2
                        z2 = v - p2
                        
                        import pandas as pd
                        import plotly.graph_objects as go
                        
                        
                        df = pd.DataFrame(dict(
                            X=[0,x3[0],0,x2[0], 0,v[0], p2[0], v[0]], 
                            Y=[0,x3[1],0,x2[1], 0,v[1], p2[1], v[1]],
                            Z=[0,x3[2],0,x2[2], 0,v[2], p2[2], v[2]],
                            color=["x1", "x1", "x2", "x2", "x3", "x3", "z2", "z2"]
                        ))
                        
                        df1 = pd.DataFrame(dict(
                            X=[x3[0],x2[0],v[0],p2[0]], 
                            Y=[x3[1],x2[1],v[1],p2[1]],
                            Z=[x3[2],x2[2],v[2],p2[2]],
                            color=["x1", "x2", "x3","z2"],
                            text=["x", "y", "v","p"]
                        ))
                        
                        import plotly.express as px
                        
                        fig1 = px.line_3d(df, x='X', y='Y', z='Z', color="color", markers=False)
                        fig2 =px.line_3d(df1, x='X', y='Y', z='Z', color="color", markers=True, symbol_sequence=['diamond'], text="text")
                        fig3 = go.Figure(data=fig1.data + fig2.data)
                        fig3.update_layout(showlegend=False,font = dict(size = 30),
                                        scene = dict(xaxis_title='', yaxis_title='', zaxis_title='',
                                            xaxis = dict(tickfont=dict(size=12,) ),
                                            yaxis = dict(tickfont=dict(size=12,) ),
                                            zaxis = dict(tickfont=dict(size=12,) ),))
                        fig3.write_html("yourfile.html")
                    </input>
                    <output>
                        plot
                    </output>
                </sage>



                <theorem xml:id = "mud_base">
                    <title> da Mudança de Base</title>
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    Sejam <m>\mathcal{U}</m> e <m>\mathcal{V}</m> bases para um espaço vetorial <m>V</m>, <m>S</m> a matriz de mudança de base da base <m>\mathcal{U}</m> para a base <m>\mathcal{V}</m>. Se <m>L</m> é um operador linear em <m>V</m> representado pela matriz <m>A^{\mathcal{U}}</m> na base <m>\mathcal{U}</m>, então a matriz que representa <m>L</m> na base <m>\mathcal{V}</m> é
                    <me>
                        A^{\mathcal{V}} = SA^{\mathcal{U}}S^{-1}.
                    </me>
                  </statement>
                
                  <proof>
                    A completar.
                  </proof>
                </theorem>

                <p>Esse teorema é frequentemente utilizado com <m>\mathcal{V}</m> sendo a base canônica, e <m>S=U</m> sendo a matriz de mudança de base da base <m>\mathcal{U}</m> para a base canônica.</p>

                <sage>
                    <input>
                        import matplotlib.pyplot as plt
                        import numpy as np

                        fig, ax = plt.subplots()
                        plt.xlim( (-4.6, 1) )  # set the xlim to xmin, xmax
                        plt.ylim((-0.1,2.5))    # set the xlim to xmin, xmax

                        fig.patch.set_visible(False)
                        ax.axis('off')


                        plt.annotate('E', [-0.1,0.1], fontsize=20, style= 'italic' )
                        plt.arrow(0,2.15,0,-1.7, head_width =0.1)
                        plt.annotate('U', [-0.1,2.2], fontsize=20, style= 'italic' )
                        plt.arrow(-3.75,2.3,3.5,0, head_width =0.1)
                        plt.annotate('U', [-4.1,2.2], fontsize=20, style= 'italic' )
                        plt.arrow(-3.8,0.2,3.4,0, head_width =0.1)
                        plt.annotate('E', [-4.1,0.1], fontsize=20, style= 'italic' )
                        plt.arrow(-4,0.3,0,1.7, head_width =0.1)

                        plt.annotate('U', [0.1,1.2], fontsize=20)
                        plt.annotate('L', [-2,2.4], fontsize=20)
                        plt.annotate('U', [-1.85,2.5], fontsize=10)

                        plt.annotate('L', [-2.3,-0.1], fontsize=20)
                        plt.annotate('U', [-2.1,0], fontsize=10)
                        plt.annotate('U', [-1.95,-0.1], fontsize=20)
                        plt.annotate('-1', [-1.72,0], fontsize=10)
                        plt.annotate('U', [-2.6,-0.1], fontsize=20)

                        plt.annotate('-1', [-4.2,1.3], fontsize=10)
                        plt.annotate('U', [-4.4,1.2], fontsize=20)


                        plt.show()
                    </input>
                    <output>
                        diagram
                    </output>
                </sage>

                <example>
                    <statement>
                        Para calcularmos a matriz que representa a projeção do <xref ref="ex_proj"></xref> na base canônica, precisamos da matriz de mudança de base e sua inversa
                        <me>
                            U = \begin{pmatrix}
                            1\amp 0 \amp 2 \\
                            1\amp 1 \amp -1 \\
                            -1\amp 1 \amp  1
                            \end{pmatrix}
                            \,\,\,\,\,\,
                            U^{-1} = \begin{pmatrix}
                            1/3\amp  1/3 \amp  -1/3\\
                            0 \amp  1/2 \amp  1/2\\
                            1/3\amp  -1/6 \amp 1/6 
                            \end{pmatrix}
                        </me>
                        de modo que
                        <me>
                            A = \begin{pmatrix}
                            1\amp 0 \amp 1 \\
                            1\amp 1 \amp -1 \\
                            -1\amp 1 \amp  1
                            \end{pmatrix} 
                            \begin{pmatrix} 0 \amp 0 \amp 0 \\ 0 \amp 1 \amp 0 \\ 0 \amp 0 \amp 1\end{pmatrix}
                            \begin{pmatrix}
                            1/3\amp  1/3 \amp  -1/3\\
                            0 \amp  1/2 \amp  1/2\\
                            1/3\amp  -1/6 \amp 1/6 
                            \end{pmatrix}
                            = \cdots
                        </me>
                    </statement>
                </example>





                <exercise>
                    <statement>
                        Determine a matriz da rotação de <m>\theta</m> radianos em torno do eixo <m>(1,1,-1)^T</m>, no sentido anti-horário, na base <m>\mathcal{U} = \{\vec{u}_1 = (1,1,-1)^T, \vec{u}_2 = (0,1,1)^T, \vec{u}_3 = (2,-1,1)^T\}</m>.
                    </statement>
                </exercise>

                <exercise>
                    <statement>
                        Determine a matriz da rotação de <m>\theta</m> radianos em torno do eixo <m>(1,1,-1)^T</m>, no sentido anti-horário, na base canônica.
                    </statement>
                </exercise>

                <p>Temos a situação que se duas matrizes <m>A</m> e <m>B</m> representam a mesma transformação linear, em bases <m>\mathcal{U}</m> e  <m>\mathcal{V}</m>, respectivamente, e <m>S</m> é a matriz de mudança de base da base <m>\mathcal{U}</m> para a base <m>\mathcal{V}</m>, então <m>B = S A S^{-1}</m>. Isso nos motiva a introduzir a seguinte definição:</p>


                <definition>
                    <notation>
                    <usage><m>B = S A S^{-1}</m></usage>
                    <description>matrizes similares</description>
                    </notation>
                
                    <statement>
                        <p>
                            Duas matrizes <m>n \times n</m>, <m>A</m> e <m>B</m>, são ditas similares se existe uma matriz <m>n \times n</m> inversível <m>S</m> tal que
                            <me>
                                B = S A S^{-1}.
                            </me>
                        </p>
                    </statement>
                </definition>



            </subsection>


            <!--  *********************************************************
            *************************************************************** -->
                

            <subsection xml:id="trans_lineares_prob">
                <title>Problemas envolvendo transformações Lineares</title>


                <p>Utilize o código abaixo para testar as respostas de seus exercícios</p>
                <sage>
                    <input>
                        import matplotlib.pyplot as plt
                        import numpy as np
                        
                        
                        
                        x1 = np.array([0,0, 0])
                        x2 = np.array([0, 1, 0])
                        x3 = np.array([0, 1, 1])
                        x4 = np.array([1, 1, 1])
                        
                        A = np.array([[1,2,2],[3,1,1],[-1,2,-1]])
                        
                        y1 = A.dot(x1)
                        y2 = A.dot(x2)
                        y3 = A.dot(x3)
                        y4 = A.dot(x4)
                        
                        import pandas as pd
                        import plotly.graph_objects as go
                        
                        
                        df = pd.DataFrame(dict(
                            X=[x1[0],x2[0],x3[0],x4[0], y1[0],y2[0], y3[0], y4[0]], 
                            Y=[x1[1],x2[1],x3[1],x4[1], y1[1],y2[1], y3[1], y4[1]],
                            Z=[x1[2],x2[2],x3[2],x4[2], y1[2],y2[2], y3[2], y4[2]],
                            color=["x1", "x1", "x1", "x1", "x2", "x2", "x2", "x2"]
                        ))
                        
                        
                        import plotly.express as px
                        
                        fig1 = px.line_3d(df, x='X', y='Y', z='Z', color="color", markers=False)
                        fig1.write_html("yourfile.html")
                    </input>
                    <output>
                        plot
                    </output>
                </sage>

                <exercise>
                    <statement>
                        Encontre uma matriz que representa uma rotação de ângulo <m>\theta</m> no sentido anti-horário em torno do eixo y.
                    </statement>

                </exercise>


                <exercise>
                    <statement>
                        Encontre uma matriz que representa uma rotação de ângulo <m>\theta</m> no sentido anti-horário em torno do eixo <m>(1/\sqrt{6}, -1/\sqrt{6}, 2/\sqrt{6})^T</m>.
                    </statement>

                </exercise>


                <exercise>
                    <statement>
                        Encontre uma matriz que dilata a direção x por 2, a direção y por 0.5 e a direção z por 3.
                    </statement>
                </exercise>


                <exercise>
                    <statement>
                        Encontre uma matriz que dilata a direção <m>(1/\sqrt{6}, -1/\sqrt{6}, 2/\sqrt{6})^T</m> por 2, a direção <m>(1/\sqrt{2}, 1/\sqrt{2}, 0)^T</m> por 0.5 e a direção <m>(-1/\sqrt{3}, 1/\sqrt{3}, 1/\sqrt{3})^T</m> por 3.
                    </statement>
                </exercise>

                <sage>
                    <input>
                        import matplotlib.pyplot as plt
                        import numpy as np
                        import scipy as sci



                        x1 = np.array([0,0, 0])
                        x2 = np.array([1, -1, 2])
                        x3 = np.array([0, 1, 1])
                        x4 = np.array([1, 1, 1])

                        theta = np.pi/4

                        A = np.array([[1,0,0],[0,np.cos(theta),-np.sin(theta)],[0,np.sin(theta),np.cos(theta)]])

                        U = np.array([[1/np.sqrt(6),-1/np.sqrt(6),2/np.sqrt(6)],[1/np.sqrt(2),1/np.sqrt(2),0],[-1/np.sqrt(3),1/np.sqrt(3),1/np.sqrt(3)]])
                        U = np.transpose(U)
                        B = U.dot(A.dot(sci.linalg.inv(U)))
                    </input>
                    <output>
                        plot
                    </output>
                </sage>

                

                <p>Translações não são transformações lineares, contudo podemos representá-las como matrizes utilizando uma dimensão adicional. Dado um ponto no plano <m>x = (x1,x2)^T</m>, podemos transladá-lo por <m>a</m>, <m>b</m>, através das duas primeiras coordenadas do vetor:</p>
                <me>
                    T_{a,b}(x) = \begin{pmatrix} 1 \amp 0 \amp a \\ 0 \amp 1 \amp b\\ 0 \amp 0 \amp 1\end{pmatrix} \begin{pmatrix} x1 \\ x2 \\ 1 \end{pmatrix}.
                </me>

                <p>Verifique isso com o código a seguir:</p>
                <sage>
                    <input>
                        # credits: https://bvanderlei.github.io/jupyter-guide-to-linear-algebra/Applications_LT.html

                        %matplotlib inline  
                        import matplotlib.pyplot as plt
                        import numpy as np

                        coords = np.array([[0,0],[0,3],[1,3],[1,1],[2,1],[2,0],[0,0]])
                        coords = coords.transpose()
                        x = coords[0,:]
                        y = coords[1,:]

                        # Form a matrix of coordinates with rows x, y, 1
                        Ones = np.ones((1,7))
                        coords = np.vstack((x,y,Ones))
                        
                        # Define the matrix for the transfomation L
                        A = np.array([[1,0,3],[0,1,1],[0,0,1]])
                        
                        ## Compute translation by matrix multiplication
                        coords_translated = A@coords
                        
                        ## Slice off the first and second rows.  These are the coords of the translated points
                        x_translated = coords_translated[0,:]
                        y_translated = coords_translated[1,:]
                        
                        # Create the figure and axes objects
                        fig, ax = plt.subplots()
                        
                        # Plot the points.
                        ax.plot(x,y,'ro')
                        ax.plot(x_translated,y_translated,'bo')
                        
                        # Connect the points by lines
                        ax.plot(x,y,'r',ls="--")
                        ax.plot(x_translated,y_translated,'b')
                        
                        # Edit some settings 
                        ax.axvline(x=0,color="k",ls=":")
                        ax.axhline(y=0,color="k",ls=":")
                        ax.grid(True)
                        ax.axis([-1,6,-1,6])
                        ax.set_aspect('equal')
                        ax.set_title("Translation");                        
                    </input>
                    <output>
                        plot
                    </output>
                </sage>




            </subsection>


        </section>

        <!--  *********************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        ***************************************************************
        *************************************************************** -->                                                                                                    



        <section xml:id="auto_val">
            <title>Autovalores e autovetores</title>
           
            <intro>
               <p>
                Temos visto que, muitas vezes, é mais fácil compreender uma transformação linear em uma base adaptada para o problema em questão. Todavia encontrar uma base natural para o problema nem sempre é fácil. Nesse capítulo vamos nos ocupar com o problema no outro sentido: se temos uma transformação linear (representada por uma matriz na base canônica, por exemplo), quais são as direções mais naturais a se escolher para uma base?
                </p>
                <p>
                Responderemos a essa pergunta passa por entender quais direções a transformação linear é mais simples, tendo o efeito de apenas multiplicar vetores naquela direção por uma constante. A constante pela qual o vetor é multiplicado é chamada de autovalor e a direção é chamada de autovetor. Veremos que as rotações também serão incluídas nesse caso naturalmente, com autovalores complexos. 
               </p>
           </intro>
           
            <subsection xml:id="auto_val_sub">
                <title>Autovalores e autovetores</title>

                <definition>
                    <notation>
                    <usage><m>\lambda</m></usage>
                    <description>autovalor</description>
                    </notation>
                
                    <statement>
                    <p>
                        Seja <m>A</m> uma matriz <m>n \times n</m>. Um número (real ou complexo) <m>\lambda</m> é dito um <term>autovalor</term> de <m>A</m> se existe um vetor não nulo <m>\vec{x}</m> tal que <m>A\vec{x} = \lambda \vec{x}</m>. <m>\vec{x}</m> é dito um <term>autovetor</term> associado ao autovalor <m>\lambda</m>.
                    </p>
                    </statement>
                </definition>


                <example>
                    <statement>
                        A matriz,
                        <me>
                            A = \begin{pmatrix} 2 \amp 4 \\ 1 \amp 2  \end{pmatrix},
                        </me>
                        admite <m>4</m> como autovalor porque o vetor <m>\vec{x} = (2, 1)^T</m> satisfaz <m>A\vec{x} = (8, 4)^T = 4(2,1)^T = 4\vec{x}</m>. Outro autovalor dessa matrix é 0 pois o vetor <m>\vec{x} = (2, -1)^T</m> satisfaz <m>A\vec{x} = (0, 0)^T = 0(2,-1)^T = 0\vec{x}</m>.
                    </statement>
                </example>

                <p> Nesse exemplo os autovalores e autovetores foram dados, mas como fazemos para encontrar os autovalores de uma matriz qualquer? A observação a seguir nos dá um método para isso.</p>

                <remark>
                    Se existe um vetor não nulo <m>\vec{x}</m> tal que <m>A\vec{x} = \lambda \vec{x}</m>, temos que <m>A\vec{x} - \lambda \vec{x} = \vec{0}</m> e, portanto, <m>(A - \lambda I) \vec{x} = \vec{0}</m>, ou seja, essa equação tem solução não nula e a matriz <m>(A - \lambda I)</m> não é inversível. Desse modo, encontrar autovalores é descobrir para que escalares temos <m>Det(A - \lambda I) = 0</m>. O polinômio <m>p(\lambda) = Det(A - \lambda I)</m> é chamado de polinômio característico e os autovalores são as raízes desse polinômio. Uma vez encontrados os autovalores, resolvemos o sistema <m>(A - \lambda I) \vec{x} = \vec{0}</m> para cada autovalor encontrado para determinar os autovetores associados a cada autovalor.
                </remark>

                <example>
                    <statement>
                        A matriz,
                        <me>
                            A = \begin{pmatrix} 1 \amp 3 \\ 1 \amp -1  \end{pmatrix},
                        </me>
                        tem polinômio característico
                        <me>
                            p(\lambda) = Det \left(\begin{pmatrix} 1 \amp 3 \\ 1 \amp -1  \end{pmatrix} -\lambda \begin{pmatrix} 1 \amp 0 \\ 0 \amp 1  \end{pmatrix}\right) = Det \begin{pmatrix} 1-\lambda \amp 3 \\ 1 \amp -1-\lambda  \end{pmatrix} = \lambda^2 -4,
                        </me>
                        que têm raízes 2 e -2.

                        Os autovetores associados ao autovalor 2 são encontrados resolvendo
                        <me>
                            \begin{pmatrix} -1 \amp 3 \\ 1 \amp -3  \end{pmatrix} \begin{pmatrix}x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix}0 \\ 0 \end{pmatrix} \,\,\, \Longrightarrow \,\,\, \begin{pmatrix}x_1 \\ x_2 \end{pmatrix} = \alpha \begin{pmatrix} 3 \\ 1 \end{pmatrix}.
                        </me>

                        Os autovetores associados ao autovalor -2 são encontrados resolvendo
                        <me>
                            \begin{pmatrix} 3 \amp 3 \\ 1 \amp 1  \end{pmatrix} \begin{pmatrix}x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix}0 \\ 0 \end{pmatrix} \,\,\, \Longrightarrow \,\,\, \begin{pmatrix}x_1 \\ x_2 \end{pmatrix} = \alpha \begin{pmatrix} 1 \\ -1 \end{pmatrix}.
                        </me>
                    </statement>
                </example>

                <exercise>
                    Encontre os autovalores e autovetores associados para matriz
                    <me>
                        A = \begin{pmatrix} 1/3 \amp -4/3 \amp -1/3 \\ -4/3 \amp 1/3 \amp 1/3 \\ -1/3 \amp 1/3 \amp 4/3 \end{pmatrix}
                    </me>
                </exercise>

                <p>
                    Confira a sua resposta com o código abaixo.
                </p>

                <sage>
                    <input>
                        import scipy as sci
                        import numpy as np

                        A = np.array([[3,0,1],[0,2,0],[0,0,2]])

                        sci.linalg.eig(A)
                    </input>
                    <output>
                        eigenvalues and eigenvectors
                    </output>
                </sage>


                <remark>Podemos pensar na matriz <m>A</m> como uma transformação linear da base canônica para a base canônica. Se representarmos essa transformação linear na base de autovetores (supondo que exista uma), temos que ela será representada por uma matriz diagonal, com os autovalores na diagonal. Desse modo temos que:
                <me>
                    A = P D P^{-1}
                </me>
                Encontrar matrizes <m>P</m> (de autovetores) e <m>D</m> (com autovalores na diagonal) é conhecido como a diagonalização da matriz A.</remark>

                <p>Infelizmente nem sempre é possível encontrar uma base de autovetores para uma matriz.</p>

                <exercise>
                    Diagonalize a matriz
                    <me>
                        A = \begin{pmatrix} 1/3 \amp -4/3 \amp -1/3 \\ -4/3 \amp 1/3 \amp 1/3 \\ -1/3 \amp 1/3 \amp 4/3 \end{pmatrix}
                    </me>
                </exercise>

                <p> O código abaixo pode ser utilizado para verificar se o produto das matrizes encontradas retorna a matriz original.</p>

                <sage>
                    <input>
                        import scipy as sci
                        import numpy as np
                        
                        A = np.array([[3,0,1],[0,2,0],[0,0,2]])
                        
                        B = sci.linalg.eig(A)
                        
                        print('D = ', np.diag(B[0]))
                        
                        print('P = ', B[1])
                        
                        print('A = ?', B[1].dot(np.diag(B[0]).dot(np.linalg.inv(B[1]))))
                    </input>
                    <output>
                        matrix
                    </output>
                </sage>

                <p>Esse processo é particularmente útil quando precisamos aplicar uma transformação linear multiplas vezes, pois</p>
                <me>
                    A^2 = (P D P^{-1})(P D P^{-1}) = P D^2 P^{-1} \,\,\,\, A^n = (P D P^{-1})\cdots(P D P^{-1}) = P D^n P^{-1} 
                </me>
                <p>e, para uma matriz diagonal,</p>
                <me>
                    D = \begin{pmatrix}
                    \lambda_1 \amp 0 \amp 0 \amp \cdots \amp 0 \\
                    0 \amp \lambda_2 \amp 0 \amp \cdots \amp 0 \\
                    \vdots \amp \vdots \amp \ddots \amp \cdots \amp \vdots \\
                    0 \amp 0 \amp 0 \amp \cdots \amp \lambda_n                    
                    \end{pmatrix}, \,\,\,\,\,
                    D^m = \begin{pmatrix}
                    \lambda_1^m \amp 0 \amp 0 \amp \cdots \amp 0 \\
                    0 \amp \lambda_2^m \amp 0 \amp \cdots \amp 0 \\
                    \vdots \amp \vdots \amp \ddots \amp \cdots \amp \vdots \\
                    0 \amp 0 \amp 0 \amp \cdots \amp \lambda_n^m                    
                    \end{pmatrix}
                </me>

                <exercise>
                    <statement>
                        Suponha que uma cidade tem 100000 homens separados em dois grupos: não comprometidos e comprometidos; e que, a cada ano, <m>30\%</m> dos não comprometidos passam a ser comprometidos e <m>20\%</m> dos comprometidos passam a ser não comprometidos. Se no primeiro ano, temos 50000 comprometidos e 50000 não comprometidos, quais os números de comprometidos e não comprometidos após 1, 10 e 50 anos?
                    </statement>
                </exercise>


            </subsection>

            <!--  *********************************************************
            *************************************************************** -->
                

            <subsection xml:id="autoval_teormas">
                <title>Resultados e dificuldades relacionados a autovetores e autovalores.</title>

                <p>Nessa seção discutimos quando é possível diagonalizar uma matriz e quais as opções quando isso não é possível.</p>

                <theorem xml:id = "autovetores_LI">
                    <!--<title> </title>-->
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                   Seja <m>A</m> uma matriz <m>n \times n</m>. Autovetores associados a autovalores distintos são linearmente independentes. 
                  </statement>
                  <proof>
                    A completar.
                  </proof>
                </theorem>

                <p>O <xref ref="autovetores_LI"></xref> garante que se o polinômio característico tem <m>n</m> raízes distintas, teremos <m>n</m> autovetores LI. Todavia esses autovalores e autovetores ainda podem ser complexos, o que pode não permite diagonalizar a matriz, se buscamos uma matriz real.</p>

                <theorem xml:id = "matriz_simetrica">
                    <title></title>
                    <!-- <creator>I. Newton</creator> -->
                  <statement>
                    Seja <m>A</m> uma matriz real<fn>Na qual todos os coeficientes são reais</fn> <m>n \times n</m> simétrica. Então, seus autovalores e autovetores são reais e a matriz <m>A</m> tem <m>n</m> autovetores distintos. Além disso, <m>A</m> admite uma base de autovetores ortonormais.
                  </statement>
                  <proof>
                    A completar.
                  </proof>
                </theorem>
                
                <p>Isso significa que uma matriz simétrica sempre é diagonalizável (A matriz <m>P</m> é a matriz de mudança de base da base de autovetores para a base canônica). Se uma matriz não é simétrica essa pode não ser a situação.</p>

                <remark>Para analisar o que ocorre no caso de autovalores múltiplos, precisamos de números complexos e recorro a um resultado de variável complexa, que diz que um polinômio real ou complexo de grau <m>n</m> sempre pode ser decomposto no produto de monômios de grau <m>n</m>. Em particular
                <me>
                    p(\lambda) = \pm (\lambda^n + a_{n-1} \lambda^{n-1} + \cdots + a_1 \lambda + a_0) = \pm(\lambda-\lambda_n)(\lambda-\lambda_{n-1})\cdots(\lambda-\lambda_1),
                </me>
                onde <m>\lambda</m> é a variável complexa, <m>\lambda_i</m>, <m>i = 1, 2, \ldots, n</m> são as raízes (possivelmente complexas) e <m>a_i</m> os coeficientes, <m>i = 1, 2, \ldots, n</m>.
                </remark>


                <definition>
                    <notation>
                    <!-- <usage><m>\lambda</m></usage> -->
                    <description>multiplicidades algébrica e geométrica</description>
                    </notation>
                
                    <statement>
                    <p>
                        Seja <m>p(\lambda)</m> o polinômio característico de uma matriz real <m>A</m>, <m> n \times n </m>. O número de vezes que um autovalor aparece na decomposição no produto de monômios de <m>p(\lambda)</m> é chamada de multiplicidade algébrica desse autovalor. A dimensão do espaço nulo de <m>A - \lambda_k I</m>, <m>N(A - \lambda_k I)</m> é a multiplicidade geométrica do autovalor <m>\lambda_k</m>.
                    </p>
                    </statement>
                </definition>

                <example>
                    <statement>
                        <me>A = \begin{pmatrix} 1 \amp 3 \\ 0 \amp 1 \end{pmatrix}</me>
                    </statement>
                </example>


                <example>
                    <statement>
                        <me>A = \begin{pmatrix} 2 \amp 3 \amp 0\\ 0 \amp 2 \amp -4 \\ 0 \amp 0 \amp 1 \end{pmatrix}</me>
                    </statement>
                </example>

                <p>Uma matriz real é diagonalizável exatamente quando tem autovalores reais e a multiplicidade geométrica é igual a multiplicidade algébrica para cada autovalor.</p>

                <example>
                    <statement>
                        Diagonalize a matriz
                        <me>A = \begin{pmatrix} 0 \amp 2 \amp -1\\ 2 \amp 3 \amp -2 \\ -1 \amp -2 \amp 0 \end{pmatrix}</me>
                    </statement>
                </example>


                <p>Se uma matriz <m>A</m> tem autovalores complexos, então não é possível colocá-la na forma diagonal usual utilizando matrizes reais. Todavia os autovalores complexos sempre vem em pares conjugados <m>\lambda_k, \overline{\lambda}_k</m>, com autovetores complexos <m>\vec{x}_k, \overline{\vec{x}}_k</m>. Vejamos em detalhe o que ocorre com as partes reais e complexas do autovetor <m>\vec{x}_k = \mbox{Re}(\vec{x}_k) + i \mbox{Im}(\vec{x}_k)</m> associado ao autovalor <m>\lambda_k = r \mbox{cos} (\theta) + i r \mbox{sen} (\theta)</m> (escrito na forma polar)</p>.
                    
                <md>
                    <mrow>A \vec{x}_k =\amp \lambda_k \vec{x}_k = (r \mbox{cos} (\theta) + i r \mbox{sen} (\theta))( \mbox{Re}(\vec{x}_k) + i \mbox{Im}(\vec{x}_k))</mrow>
                    <mrow> =\amp (r \mbox{cos} (\theta) \mbox{Re}(\vec{x}_k) - r \mbox{sen} (\theta)\mbox{Im}(\vec{x}_k)) + i( r \mbox{sen} (\theta)\mbox{Re}(\vec{x}_k) +  r \mbox{cos} (\theta)\mbox{Im}(\vec{x}_k)),</mrow>
                    <mrow>A \bar{\vec{x}_k} =\amp \bar{\lambda_k}\bar{ \vec{x}_k} = (r \mbox{cos} (\theta) - i r \mbox{sen} (\theta))( \mbox{Re}(\vec{x}_k) - i \mbox{Im}(\vec{x}_k))</mrow>
                    <mrow> =\amp (r \mbox{cos} (\theta) \mbox{Re}(\vec{x}_k) - r \mbox{sen} (\theta)\mbox{Im}(\vec{x}_k)) - i( r \mbox{sen} (\theta)\mbox{Re}(\vec{x}_k) +  r \mbox{cos} (\theta)\mbox{Im}(\vec{x}_k)).</mrow>
                </md>

                <p>Assim, lembrando que <m>2 \mbox{Re}(\vec{x}_k) = \vec{x}_k + \bar{\vec{x}_k}</m> e <m>2 \mbox{Im}(\vec{x}_k) = -i\vec{x}_k + i \bar{\vec{x}_k}</m>, temos</p>
                <me>
                    A \mbox{Re}(\vec{x}_k) =  r \mbox{cos} (\theta) \mbox{Re}(\vec{x}_k) - r \mbox{sen} (\theta)\mbox{Im}(\vec{x}_k)
                </me>
                <me>
                    A \mbox{Im}(\vec{x}_k) =  r \mbox{sen} (\theta)\mbox{Re}(\vec{x}_k) +  r \mbox{cos} (\theta)\mbox{Im}(\vec{x}_k)
                </me>


                <p>Desse modo, se <m>\vec{u} = a \mbox{Re}(\vec{x}_k) + b \mbox{Im}(\vec{x}_k)</m>, com <m>a,b</m> reais, temos:</p>
                <md>
                    <mrow>A \vec{u} = \amp a(r \mbox{cos} (\theta) \mbox{Re}(\vec{x}_k) - r \mbox{sen} (\theta)\mbox{Im}(\vec{x}_k)) + b(r \mbox{sen} (\theta)\mbox{Re}(\vec{x}_k) +  r \mbox{cos} (\theta)\mbox{Im}(\vec{x}_k))</mrow>
                    <mrow> =\amp (r \mbox{cos} (\theta), r \mbox{sen} (\theta))\begin{pmatrix} a \\ b \end{pmatrix} \mbox{Re}(\vec{x}_k) + (-r \mbox{sen} (\theta), r \mbox{cos} (\theta))\begin{pmatrix} a \\ b \end{pmatrix} \mbox{Im}(\vec{x}_k),</mrow>
                </md>
                <p>e é possível escrever um bloco <m>2 \times 2</m> na diagonal da forma:</p>
                <me>
                    \begin{pmatrix} r\mbox{cos}(\theta) \amp r\mbox{sen}(\theta) \\ -r\mbox{sen}(\theta) \amp r\mbox{cos}(\theta) \end{pmatrix},
                </me>
                <p>de modo que autovalores complexos indicam a rotações no plano definido por <m>\mbox{Re}(\vec{x}_k)</m> e <m>\mbox{Im}(\vec{x}_k)</m>. Deixamos ao leitor a verificação do fato que <m>\mbox{Re}(\vec{x}_k)</m> e <m>\mbox{Im}(\vec{x}_k)</m> são linearmente independentes.</p>

                <example>
                    <statement>
                        <me>A = \begin{pmatrix} 4/5 \amp -3/5 \amp 0 \\ 3/5 \amp 4/5 \amp 0 \\ 1 \amp 2 \amp 2 \end{pmatrix}</me>
                    </statement>
                </example>

                <p>Para mais informações sobre esse processo, ver <url href="https://pt.wikipedia.org/wiki/Forma_can%C3%B4nica_de_Jordan" visual="wikipedia.org">Forma de Jordan</url>.</p>



            </subsection>



        <!--  *********************************************************
        *************************************************************** -->
            

        <subsection xml:id="aplicacoes">
            <title>Aplicações: sistemas de EDOs lineares de primeira ordem.</title>

            <p>As leis que descrevem muitos processos na natureza são dadas por equações diferenciais. Por exemplo, vamos considerar a radioatividade. Suponha que uma amostra de material contém <m>y_0</m> átomos radioativos. É natural pensar que o número de átomos, <m>y(t)</m>, que decai a cada segundo é proporcional ao número de átomos que ainda não decairam. Em linguagem matemática, isso significa que:</p>
            <me>
                \frac{dy}{dt}(t) = \lambda y(t), \,\,\,\, y(0) = y_0. 
            </me>
            <p> Um problema assim é chamado de uma equação diferencial ordinária e sua solução é <m>y(t) = y_0 e^{\lambda t}</m>.</p>

            <p>Em outros problemas pode-se ter múltiplas funções simultaneamente.</p>

            <example>
                <statement>
                    Uma amostra formada por dois isótopos radioativos com quantidades iniciais <m>y_1 = 3\times 10^{5}</m> e <m>y_2 = 2\times 10^{4}</m>  e a fração dos átomos que decai a cada segundo é 0.1% e 0.2%. Então o número de átomos radioativos na amostra de cada um dos tipos é ... 
                </statement>
            </example>


            <example>
                <statement>
                    Alguns isótopos decaem em outros isótopos que também são radioativos. Suponha que um isótopo <m>A</m> decai no isótopo <m>B</m>, que decai no isótopo <m>C</m>. Uma amostra formada pelos isótopos <m>A</m>, <m>B</m> e <m>C</m> com quantidades iniciais <m>y_1 = 3\times 10^{5}</m> e <m>y_2 = 2\times 10^{4}</m> e <m>y_3 = 4\times 10^{4}</m> e a fração dos átomos que decai a cada segundo do isótopo A para o isótopo B é 0.1%, do isótopo B para o isótopo C é 0.2% e do isótopo B para material não radioativo é de 0.3%. Então o número de átomos radioativos na amostra de cada um dos tipos é ... 
                </statement>
            </example>

            <p>Consideremos o sistema de equações diferenciais (com condições iniciais associadas):</p>
            <md>
                <mrow>y_1' =\amp a_{11}y_1 + a_{12}y_2 + \cdots + a_{1n} y_n, \,\,\, y_1(0) = y^*_1,</mrow>
                <mrow>y_2' =\amp a_{21}y_1 + a_{22}y_2 + \cdots + a_{2n} y_n, \,\,\, y_2(0) = y^*_2,</mrow>
                <mrow> \vdots \amp</mrow>
                <mrow>y_n' =\amp a_{n1}y_1 + a_{n2}y_2 + \cdots + a_{nn} y_n, \,\,\, y_n(0) = y^*_n,</mrow>
            </md>
            <p>que pose ser escrito na forma</p>
            <me>
                \vec{y}'(t) = A\vec{y}(t), \,\,\, \vec{y}(0) = \vec{y^*}.
            </me>

            <p>Se a matriz A tem <m>n</m> autovalores reais, <m>\lambda_1, \ldots, \lambda_n</m>,(não necessariamente distintos) e  a eles estão associados <n>n</n> autovetores LI, <m>\vec{x}_1, \ldots, \vec{x}_n</m>, então a solução do sistema de EDOs é</p>
            <me>
                \vec{y}'(t) = c_1e^{\lambda_1 t}\vec{x}_1 + c_2e^{\lambda_2 t}\vec{x}_2 + \cdots + c_ne^{\lambda_n t}\vec{x}_n, \,\, \mbox{ onde } \,\, \vec{y^*} = c_1\vec{x}_1 + c_2\vec{x}_2 + \cdots + c_ne^\vec{x}_n.
            </me>

            <exercise>
                <statement>
                    Resolva o sistema
                    <md>
                        <mrow>y_1' =\amp 3y_1 + 2y_2 - 3y_3, \,\,\, y_1(0) = 1,</mrow>
                        <mrow>y_2' =\amp 2y_1 + 3y_2 - 3y_3, \,\,\, y_2(0) = 2,</mrow>
                        <mrow>y_3' =\amp 3y_1 + 3y_2 - 4y_3, \,\,\, y_n(0) = -1,</mrow>
                    </md>
                </statement>
            </exercise>

        </subsection>

                <!--  *********************************************************
        *************************************************************** -->
            

        <subsection xml:id="aplicacoes_2">
            <title>Aplicações: sistemas de EDOs lineares de segunda ordem.</title>

            <p>As leis que descrevem muitos processos na natureza são dadas por equações diferenciais. Muitas vezes essas leis envolvem derivadas de segunda ordem. Por exemplo a segunda lei de Newton, <m>F = m a</m>, ao lembrarmos que a aceleração é a taxa de variação da velocidade e a velocidade é a taxa de variação da posição: <m>F = ma = mv' = mx''</m>. Vejamos como resolver uma EDO linear de segunda ordem num exemplo.</p>

            <example>
                <statement>
                    Consideremos o PVI
                    <me>
                        3y'' + 2y' - y = 0, \,\,\, y(0) = 1, \,\,\, y'(0) = 2.
                    </me>
                    Podemos definir variáveis <m>y_1 (t) = y(t)</m>, <m>y_2 (t) = y'(t)</m>, de modo que obtemos o sistema
                    <me>
                        \begin{array}{l}
                        y_1'(t) = y_2(t), \,\,\, y_1(0) =1,\\
                        y_2'(t) = -\frac{2}{3} y_2(t)+\frac{1}{3} y_1(t) , \,\,\, y_2(0) =2,
                        \end{array} \,\,\, \Longleftrightarrow  \begin{pmatrix} y_1 \\ y_2 \end{pmatrix}' = \begin{pmatrix} 0 \amp 1 \\ 1/3 \amp -2/3 \end{pmatrix} \begin{pmatrix} y_1 \\ y_2 \end{pmatrix}
                    </me>
                    Autovalores, autovetores, ...
                </statement>
            </example>


            <example>
                <statement>
                    Consideremos o PVI
                    <me>
                        y'' + 2y' + 2y = 0, \,\,\, y(0) = 1, \,\,\, y'(0) = 2.
                    </me>
                    Podemos definir variáveis <m>y_1 (t) = y(t)</m>, <m>y_2 (t) = y'(t)</m>, de modo que obtemos o sistema
                    <me>
                        \begin{array}{l}
                        y_1'(t) = y_2(t), \,\,\, y_1(0) =1,\\
                        y_2'(t) = -2 y_2(t) - 2y_1(t) , \,\,\, y_2(0) =2,
                        \end{array} \,\,\, \Longleftrightarrow  \begin{pmatrix} y_1 \\ y_2 \end{pmatrix}' = \begin{pmatrix} 0 \amp 1 \\ -2 \amp -2 \end{pmatrix} \begin{pmatrix} y_1 \\ y_2 \end{pmatrix}
                    </me>
                    Autovalores, autovetores, ...
                </statement>
            </example>

            <p> Podemos ter um sistema de equações lineares de segunda ordem.</p>

            <example>
                <statement>
                    Consideremos o PVI
                    <md>
                        <mrow>\amp y_1'' = 2y_1 + y_2 + y_1' + y_2', \,\,\, y_1(0) = 1, \,\,\, y_2(0) = 0.</mrow>
                        <mrow>\amp y_2'' = -5y_1 +2y_2 +5 y_1' -y_2', \,\,\, y_1'(0) = 4, \,\,\, y_2'(0) = -2,</mrow>
                    </md>
                    que pode ser escrito como
                    <me>
                        \vec{y}'' = \begin{pmatrix} 1\amp 1\\ 5\amp -1\end{pmatrix} \vec{y}' + \begin{pmatrix} 2 \amp 1 \\ -5 \amp 2 \end{pmatrix} \vec{y}
                    </me>
                    Podemos definir variáveis <m>y_3 (t) = y_1'(t)</m>, <m>y_4 (t) = y_2'(t)</m>, de modo que obtemos o sistema
                    <me>
                        \begin{pmatrix} y_1 \\ y_2 \\ y_3 \\ y_4 \end{pmatrix}' = \left(\begin{array}{cc|cc} 0 \amp 0 \amp 1 \amp 0\\ 0\amp 0\amp 0 \amp 1\\ \hline 2\amp 1\amp 1 \amp 1 \\ -5\amp 2\amp 5\amp -1\\ \end{array} \right) \begin{pmatrix} y_1 \\ y_2 \\ y_3 \\ y_4 \end{pmatrix}, \,\,\,\, \begin{pmatrix} y_1(0) \\ y_2(0) \\ y_3(0) \\ y_4(0) \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \\ 4 \\ -2 \end{pmatrix}
                    </me>
                    Autovalores, autovetores, ...
                </statement>
            </example>

            <p>Consideremos o sistema de equações diferenciais (com condições iniciais associadas), escrito na forma matricial, denotando <m>\vec{y} = (y_1, y_2, \ldots, y_n)^T</m>, como:</p>
            <me>
                \vec{y}'' = A_1 \vec{y} + A_2 \vec{y}', \,\,\,\, \vec{y}(0) = \vec{y}^*_0, \,\, \vec{y}'(0) = \vec{y}^{**}_0.
            </me>
            <p>Podemos definir as variáveis <m>y_{n+1} = y_1', y_{n+2} =y_2', \ldots, y_{2n} = y_n'</m> e, denotando, <m>\vec{y}_1 = \vec{y} = (y_1, y_2, \ldots, y_n)^T</m> e <m>\vec{y}_2 = (y_{n+1}, y_{n+2}, \ldots, y_{2n})^T</m>, temos o problema linear </p>
            <me>
                \begin{pmatrix} \vec{y}_1 \\ \vec{y}_2\end{pmatrix}' = \left(\begin{array}{c|c} 0 \amp I \\ \hline A_1 \amp A_2\end{array}\right) \begin{pmatrix} \vec{y}_1 \\ \vec{y}_2\end{pmatrix}, \,\,\, \begin{pmatrix} \vec{y}_1(0) \\ \vec{y}_2(0) \end{pmatrix} = \begin{pmatrix} \vec{y}^{*}_0 \\ \vec{y}^{**}_0\end{pmatrix}
            </me>

            <p>Que pode ser resolvido pelo método de autovalores e autovetores.</p>

        </subsection>

        </section>

    </article>

</pretext>
